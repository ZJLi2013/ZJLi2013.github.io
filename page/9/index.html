<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="what I don&apos;t know">
<meta property="og:type" content="website">
<meta property="og:title" content="Serious Autonomous Vehicles">
<meta property="og:url" content="http://yoursite.com/page/9/index.html">
<meta property="og:site_name" content="Serious Autonomous Vehicles">
<meta property="og:description" content="what I don&apos;t know">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Serious Autonomous Vehicles">
<meta name="twitter:description" content="what I don&apos;t know">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/9/"/>





  <title>Serious Autonomous Vehicles</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Serious Autonomous Vehicles</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/31/无迹卡尔曼滤波/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/31/无迹卡尔曼滤波/" itemprop="url">无迹卡尔曼滤波</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-31T10:29:26-04:00">
                2019-03-31
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/31/无迹卡尔曼滤波/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/31/无迹卡尔曼滤波/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>非线性系统：</p>
<pre><code>x = f(x, w)         （1）

z = h(x) + v                 （2）
</code></pre><p>随机信号 <code>w</code>, <code>v</code>分别是过程噪声和观测噪声    </p>
<h2 id="CTRV-状态方程"><a href="#CTRV-状态方程" class="headerlink" title="CTRV 状态方程"></a>CTRV <a href="https://winfriedauner.de/projects/" target="_blank" rel="external">状态方程</a></h2><p>对于const turn rate and velocity magnitude (<a href="https://fevemania.github.io/blog/mathematic-formula-note-of-unscented-kalman-filter/" target="_blank" rel="external">CTRV</a> )场景：</p>
<pre><code>x = (px, py, v, phi, \dot{phi})
</code></pre><p>固定速度和转动速率约束，即：</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=\dot{x}&space;=&space;(\dot{p_x},&space;\dot{p_y},&space;\dot{v},&space;\dot{\psi},&space;\ddot{\psi})&space;=&space;(vcos(\psi&space;),&space;vsin(\psi),&space;0,&space;\dot{\psi},&space;0)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\dot{x}&space;=&space;(\dot{p_x},&space;\dot{p_y},&space;\dot{v},&space;\dot{\psi},&space;\ddot{\psi})&space;=&space;(vcos(\psi&space;),&space;vsin(\psi),&space;0,&space;\dot{\psi},&space;0)" title="\dot{x} = (\dot{p_x}, \dot{p_y}, \dot{v}, \dot{\psi}, \ddot{\psi}) = (vcos(\psi ), vsin(\psi), 0, \dot{\psi}, 0)"></a>  </p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=x_{k&plus;1}&space;=&space;x_k&space;&plus;&space;\int_{t_k}^{t_{k&plus;1}}&space;\dot{x}&space;dt&space;&plus;&space;v" target="_blank"><img src="https://latex.codecogs.com/gif.latex?x_{k&plus;1}&space;=&space;x_k&space;&plus;&space;\int_{t_k}^{t_{k&plus;1}}&space;\dot{x}&space;dt&space;&plus;&space;v" title="x_{k+1} = x_k + \int_{t_k}^{t_{k+1}} \dot{x} dt + w"></a>      </p>
<p>考虑 <code>dv/dt == 0</code> , <code>dphi^2\dt^2==0</code> 且<code>\psi</code>是时间的函数, 上述第一项即：</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=px_{k&plus;1}&space;=&space;px_k&space;&plus;&space;\int_{t_k}^{t_{k&plus;1}}&space;v&space;cos\psi)&space;dt&space;&plus;&space;v&space;\\&space;=&space;px_k&space;&plus;&space;{\frac{sin\psi}{\dot{\psi}}}_{t_k}^{t_{k&plus;1}}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?px_{k&plus;1}&space;=&space;px_k&space;&plus;&space;\int_{t_k}^{t_{k&plus;1}}&space;v&space;cos\psi)&space;dt&space;&plus;&space;v&space;\\&space;=&space;px_k&space;&plus;&space;{\frac{sin\psi}{\dot{\psi}}}_{t_k}^{t_{k&plus;1}}" title="px_{k+1} = px_k + \int_{t_k}^{t_{k+1}} v cos\psi) dt + w \\ = px_k + {\frac{sin\psi}{\dot{\psi}}}_{t_k}^{t_{k+1}}"></a>     </p>
<p>从原状态空间到预测空间，由方程（1),（2）可见，过程噪声<code>w</code>是状态<code>x</code>的非线性项；而<code>z</code>关于观测噪声<code>v</code>是线性的。ukf实际采用增广状态变量<code>sigmax = [x, w]</code>. 过程噪声<code>w</code>包括径向加速度和角加速度 <code>[w_a, w_phi]</code>， 且<code>w</code>不是时间的函数 , 对上述第一项可展开：</p>
<p><a href="https://www.codecogs.com/eqnedit.php?latex=px_{k&plus;1}&space;=&space;px_k&space;&plus;&space;\int_{t_k}^{t_{k&plus;1}}&space;\dot{px}&space;dt&space;&plus;&space;\int_{0}^{\Delta&space;t}&space;w_a&space;\Delta&space;t&space;\cos{\psi}dt&space;=&space;px_k&space;&plus;&space;\frac{sin{\psi}}{\dot{\psi}}_{t_{k&plus;1}}^{t_k}&space;&plus;&space;0.5&space;w_a&space;cos{\psi}&space;\Delta&space;t^2" target="_blank"><img src="https://latex.codecogs.com/gif.latex?px_{k&plus;1}&space;=&space;px_k&space;&plus;&space;\int_{t_k}^{t_{k&plus;1}}&space;\dot{px}&space;dt&space;&plus;&space;\int_{0}^{\Delta&space;t}&space;w_a&space;\Delta&space;t&space;\cos{\psi}dt&space;=&space;px_k&space;&plus;&space;\frac{sin{\psi}}{\dot{\psi}}_{t_{k&plus;1}}^{t_k}&space;&plus;&space;0.5&space;w_a&space;cos{\psi}&space;\Delta&space;t^2" title="px_{k+1} = px_k + \int_{t_k}^{t_{k+1}} \dot{px} dt + \int_{0}^{\Delta t} w_a \Delta t \cos{\psi}dt = px_k + \frac{sin{\psi}}{\dot{\psi}}_{t_{k+1}}^{t_k} + 0.5 w_a cos{\psi} \Delta t^2"></a></p>
<h2 id="预测空间"><a href="#预测空间" class="headerlink" title="预测空间"></a>预测空间</h2><p>对比<a href="https://zjli2013.github.io/2019/03/30/卡尔曼滤波/" target="_blank" rel="external">扩展卡尔曼</a> ekf采用一阶线性化近似。无迹卡尔曼ukf，将原状态空间的特征采样点(sigmax)映射到预测空间，采用预测空间里的状态变量<code>f(sigmax)</code>的均值、方差的加权推广作为先验状态估计<code>x^-</code> 和先验误差<code>P^-</code>。</p>
<p>其中权值表述：</p>
<pre><code>$$ w = lamda / ( lamda + ns) when i==1 $$ 
$$ w_i = 0.5/(lamba + ns)       when i!=1 $$

$$ X^- =  sum(w_i * f(sigmax) ) $$
$$ P^- =  sum(w_i * (f(sigmax) - x).^2) $$  
</code></pre><h2 id="观测空间"><a href="#观测空间" class="headerlink" title="观测空间"></a>观测空间</h2><p>将原状态空间的特征采样点(sigmax)映射到观测空间，采用观测空间里的状态变量<code>h(sigmax)</code>的均值、方差的加权作为先验观测值<code>Z^-</code> 和观测值先验误差<code>S^-</code>，使用与预测空间同样的权值。</p>
<pre><code>$$ Z^- =  sum(w_i * h(sigmax) ) $$
$$ S^- =  sum(w_i * (Z^- - z).^2) + R $$  
</code></pre><p>卡尔曼滤波表示： 后验估计（真实状态变量值）与先验估计（预测空间的状态变量值）的差异，可表示为真实观测值与观测空间里的先验观测值的差异的增益 K。</p>
<pre><code>$$ x - x^-  = K (z - Z^-) $$   （3）
</code></pre><p>可见，卡尔曼增益<code>K</code>在衡量状态误差与观测误差之间的相关性。定义预测空间与观测空间的相关系数：</p>
<pre><code>T =  sum(w_i * (X^- - x)(Z^- - z))
K =  T /  S^-                   （4）
</code></pre><h2 id="ukf算法"><a href="#ukf算法" class="headerlink" title="ukf算法"></a>ukf算法</h2><p>有（4）， （3） 分别更新卡尔曼增益和状态变量， 预测空间里的先验误差更新由：</p>
<pre><code>P = P - KSK^t
</code></pre><p>ps: 在非线性的处理上，线性化或者布点采样都是常用的思路。也是ekf与ukf的区别。 </p>
<p><a href="https://starsmydestination.github.io/2017/05/09/UKF/" target="_blank" rel="external">link1</a></p>
<p><a href="https://blog.csdn.net/Young_Gy/article/details/78542754" target="_blank" rel="external">link2</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/31/CarND-term2-Extended-Kalman-Filter/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/31/CarND-term2-Extended-Kalman-Filter/" itemprop="url">CarND(term2): Extended Kalman Filter</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-31T01:49:50-04:00">
                2019-03-31
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/31/CarND-term2-Extended-Kalman-Filter/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/31/CarND-term2-Extended-Kalman-Filter/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="sensor-measurement"><a href="#sensor-measurement" class="headerlink" title="sensor measurement"></a>sensor measurement</h2><h3 id="Radar"><a href="#Radar" class="headerlink" title="Radar"></a>Radar</h3><p>radio detection andranging, using radio waves to measure the distance to objects as well as their velocity and angle. Radar used a lot in preventing collions, parking assistance, cruise control. and Radar isn’t affected by weather conditions. </p>
<p>while Radar can’t tell an object’s shape correctly. and Radar can’t detect objects if they are out of their line of sight.</p>
<p>the Radar measurement data in EKF proejcct is 3D position and velocity vector <code>(ro, theta, ro_dot)</code> in polar coordinates.</p>
<h3 id="Lidar"><a href="#Lidar" class="headerlink" title="Lidar"></a>Lidar</h3><p>light detection and ranging, using near-infrared light to scan objects and create 3D map of the enviroment. it’s 360-degree view and can track movements and their directions. but it also depends on weather conditions and can’t detecting the speed of other vehicles well. </p>
<p>the Lidar measurement data in EKF proeject is 2D position vector <code>(x,y)</code> in Cartesian coordinate system.  </p>
<p><a href="https://www.intellias.com/the-ultimate-sensor-battle-lidar-vs-radar/" target="_blank" rel="external">compare Radar vs Lidar</a></p>
<h2 id="server-client-network"><a href="#server-client-network" class="headerlink" title="server - client network"></a>server - client network</h2><p><a href="https://github.com/udacity/CarND-Extended-Kalman-Filter-Project" target="_blank" rel="external">Udacity simulator</a> communicate with EKF controller through websocket. </p>
<p>in simulators(Udacity carsim, Carla) running time, the message channel between simulator server and external controller need to be open all the time. so the simulator feed the controller with sensor data, and the controller feedback simulator with controlling data. </p>
<h3 id="uwebSocket"><a href="#uwebSocket" class="headerlink" title="uwebSocket"></a>uwebSocket</h3><p>built once <a href="https://zjli2013.github.io/2018/06/29/gnu-make/" target="_blank" rel="external">uwebSocket</a>, <a href="https://en.wikipedia.org/wiki/WebSocket" target="_blank" rel="external">webSocket</a> protocol providing full-duplex communication channel between server and client through a singlt TCP connection. it allows the server to send content ot the client without being first requested by the client, and allowing messages to be passed back and forth while keeping the conenction open. </p>
<h3 id="sensor-raw-data"><a href="#sensor-raw-data" class="headerlink" title="sensor raw data"></a>sensor raw data</h3><p>every data slice includes a either Lidar or Radar raw measurement and a ground truth measurement. </p>
<p>The state variable <code>x</code> is described in Cartesian coord, so for Radar measurement processing, there is a coordinate transfer from Cartesian to polar, and which lead it nonlinear, requiring Extended Karman Filter.</p>
<h3 id="EKF-controller"><a href="#EKF-controller" class="headerlink" title="EKF controller"></a>EKF controller</h3><p>the client side is the EKF controller, which process the sensor measurement.</p>
<p>define </p>
<pre><code>system state `x_` ,

  state priori covariance `P_`,

   state transition matrix `F`, 

process covariance `Q_`, 

measurement gain matrix  &apos;H&apos;

measurement covariance &apos;R_&apos; 

kalman filter gain &apos;K&apos;
</code></pre><p> as discussed in <a href="https://zjli2013.github.io/2019/03/30/卡尔曼滤波/" target="_blank" rel="external">previous blog</a>: </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"> </div><div class="line"><span class="keyword">void</span> KalmanFilter::Predict()</div><div class="line">&#123;</div><div class="line">	x_ = F * x_ ;   </div><div class="line">	P_ = F * P_ * F.transpose() + Q_ ;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="keyword">void</span> KalmanFilter::Update(<span class="keyword">const</span> Vector &amp; measurement)</div><div class="line">&#123;</div><div class="line">	<span class="keyword">if</span>(EKF)</div><div class="line">		h = toPolar(x_); </div><div class="line">		y = measurement - h ;</div><div class="line">	<span class="keyword">else</span></div><div class="line">		y = measurement - H * x_ ;</div><div class="line">		 </div><div class="line">	K = P_ * Ht / (H * P_ * Ht + R_);  </div><div class="line">	x_ = x_ + K * y ; </div><div class="line">	P_ = (I - K*H) * P_ ;</div><div class="line"> &#125;</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/30/卡尔曼滤波/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/卡尔曼滤波/" itemprop="url">卡尔曼滤波</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-30T10:21:09-04:00">
                2019-03-30
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/30/卡尔曼滤波/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/30/卡尔曼滤波/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="状态方程"><a href="#状态方程" class="headerlink" title="状态方程"></a>状态方程</h2><p>状态变量 <code>$x$</code> 满足, 其中 <code>u</code>为控制变量：</p>
<pre><code>$$ x = A x_prev + B u_prev + w_prev $$    (1) 
</code></pre><p>观测变量 <code>$z</code> 满足：</p>
<pre><code>$$ z = H x + v $$                    (2)
</code></pre><p>随机信号 $<code>w</code>$ 和 $<code>v</code>$ 分别表示过程激励噪声和观测噪声，假定相互独立，且服从正态分布。</p>
<p>定义状态变量的先验估计 $<code>x^-</code>$， 即基于之前状态对当前状态的预测值； 定义后验估计 $<code>x^</code>$，即已知当前观测值所计算的当前状态变量。 定义先验误差 $<code>e^-</code>$, 后验误差 $<code>e^</code>$, 满足： </p>
<pre><code>$$ e^- = x - x^- $$                     (3)

$$ e^ = x - x^ $$                         (4)
</code></pre><p>卡尔曼滤波表示： 后验估计（观测值所推导的状态变量值）与先验估计（预测的状态变量值）的差异，可表示为观测值与以先验估计为输入的观测值的差异的增益 <code>K</code>。</p>
<pre><code>$$ x^ -  x^- =  K ( z - H x^- ) $$     (5)
</code></pre><p><code>K</code>可由先验误差的协方差 <code>P</code>、观测噪声的协方差<code>R</code> 和观测增益<code>H</code>表示: </p>
<pre><code>$$ K = P^- H^t /  (  HP^-H^t + R ) $$   (6)
</code></pre><p>可见：</p>
<p>1） 当<code>R</code> 趋于0时， <code>k</code> 趋近于 <code>h</code> 的逆，此时 <code>x^ = x</code>。即当观测误差很小，观测值趋近真实值。</p>
<p>2） 当<code>P</code>趋于0时，即预测值趋近真实值。  </p>
<h2 id="算法设计"><a href="#算法设计" class="headerlink" title="算法设计"></a>算法设计</h2><p>卡尔曼滤波器用反馈控制估计过程状态（变量）：  滤波器估计某一时刻的状态（时间更新/预估），然后以（含噪声的）测量变量获得反馈（测量更新/校政）。</p>
<p>时间更新，当前时步状态先验估计 <code>x^-</code> 及先验误差协方差近似<code>P^-</code>:</p>
<pre><code>$$ x^- =  A x^-_prev + B u_prev $$  (7.1)

$$ P^- = A P^_prev A^t + Q $$         (7.2)
</code></pre><p>其中 $ P(w) ~ N(0, Q) $ </p>
<p>测量更新，使用(6)更新卡尔曼增益<code>K</code>, 使用（5)更新后验状态变量<code>x^</code>和当前步先验误差协方差值 <code>P^</code>： </p>
<pre><code>$$ P = ( I  - KH ) P^-  $$            (8)
</code></pre><h2 id="控制器调参"><a href="#控制器调参" class="headerlink" title="控制器调参"></a>控制器调参</h2><p>测量误差一般可观测得到；而过程误差q需要通过与一个已知误差的在线滤波器对比调整系数。调参一般是离线过程。一般当过程误差和卡尔曼增益会快速收敛并保持常数。但测量误差受环境影响不易保持不变。</p>
<h2 id="扩展卡尔曼"><a href="#扩展卡尔曼" class="headerlink" title="扩展卡尔曼"></a>扩展卡尔曼</h2><p>当观测值与系统状态变量 或 系统本身是非线性关系，方程(1), (2)变非线性函数。</p>
<pre><code>$$  x = f(x_prev, u_prev, w) $$  (1.2) 
$$  z =  h(x, v)    $$            (2.2) 
</code></pre><p><a href="https://www.cs.unc.edu/~welch/kalman/media/pdf/kalman_intro_chinese.pdf" target="_blank" rel="external">link</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/30/paper-reading-Carla-an-open-urban-driving-simulator/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/30/paper-reading-Carla-an-open-urban-driving-simulator/" itemprop="url">paper reading-Carla an open urban driving simulator</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-30T03:32:25-04:00">
                2019-03-30
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/30/paper-reading-Carla-an-open-urban-driving-simulator/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/30/paper-reading-Carla-an-open-urban-driving-simulator/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="http://carla.org" target="_blank" rel="external">CARLA</a> used to support training, prototyping, validation of self-driving models, including perception and control. CARLA is usded to study the performance of three approaches, 1)  classic modular pipeline that comprises a vision-based perception module, a rule-based planner, and a maneuver controller; 2)a deep network that maps sensory input to driving commands via imitaion learning;  3) end-to-end reinforcment learning.</p>
<p>all approaches make use of a high-level topological planner. the planner takes the current position of the agent and the location of the goal as input, and use A* algorithm to provide a high-level plan.  this plan advises the agent to turn left/right, or keep straight at intersections, but not provide a trajectory neither geometric info. which is a weaker form of common GPS.</p>
<h2 id="simulation-engine"><a href="#simulation-engine" class="headerlink" title="simulation engine"></a>simulation engine</h2><p>CARLA simulates a dynamic world and provide a simple interface between the world and an agent that interacts with the world. CARLA is designed as a server-client system, where the server runs the simulation and renders the scene, the client API is responsible for interaction between the agent and the server via sockets.</p>
<p>the client send commands and meta-commands to the server and receives sensor readings in return. the comands control the vehicle and includes steering, accelerating, and braking. meta-commands controls the behavior of hte server, e.g. resetting hte simulation, modifying the sensor suite.</p>
<h3 id="environment"><a href="#environment" class="headerlink" title="environment"></a>environment</h3><p>the static 3D world, such as buildings, traffic signs,  and the dynamic objects such as vehicles, pedestrains. the behavior of non-player characters is based on standard UE4 vehicle model(PhysXVehicles), and extended with a basic controller to govern NPC’s behavior: lane following, respecting traffic lights, speed limits, and decision making at intersections.</p>
<h3 id="pedestrains"><a href="#pedestrains" class="headerlink" title="pedestrains"></a>pedestrains</h3><p>pedestrains navigate the streets according to a town-specific navigation map, which conveys a location-based cost, which is designed to encourage pedestrains to walk along sidewalkd and marked road crossing, but allows them to cross road at any point.</p>
<h3 id="sensors"><a href="#sensors" class="headerlink" title="sensors"></a>sensors</h3><p>camera parameters include 3D location, 3D orientation with respect to the vehicle’s coordinate system, field of view, and depth of field.</p>
<p>the semantic segmentation pseudo-sensor provides 12 semantic classes:  road, land-marking, traffic sign, sidewalk, fence, pole, wall, building, vegetation, vehicle, pedestrain, and other.</p>
<p>a range of measurements associated with the state of the agent.  ? </p>
<p>measurements concerning traffic rules include the percentage of vehicle’s footprint that impinges on wrong-way lanes or sidewalks, as well as states of the traffic lights and speed limit at the current location of the vehicle. </p>
<p>CARLA provides access to exact location and bounding boxes of all dynamic objects. </p>
<h2 id="autonomous-driving"><a href="#autonomous-driving" class="headerlink" title="autonomous driving"></a>autonomous driving</h2><p>the agent interacts with the environment over discrete time steps. at each time step, the agent gets an observation, which is a tuple of sensory inputs, and must produce an action, which represents steering, throttle, brake. </p>
<h3 id="modular-pipeline"><a href="#modular-pipeline" class="headerlink" title="modular pipeline"></a>modular pipeline</h3><p>the pipeline includes:  perception, planning, continuous control. local planning is critical based on visual perception.</p>
<h4 id="perception"><a href="#perception" class="headerlink" title="perception"></a>perception</h4><p>using semantic segmentation network based on RefineNet to estimate lanes, road limits, and dynamic objects. and a classification model is used to determine proximity to intersections. </p>
<h4 id="the-local-planner"><a href="#the-local-planner" class="headerlink" title="the local planner"></a>the local planner</h4><p>coordinates low-level navigation by generating a set of waypoints, near-term goal states that represents the desired position and orientation of the car in near future.  the rule-based state:  1) road-following,  2) left-turn, 3) right-turn, 4) intersection-forward, 5) hazard-stop. transitions between states are performed based on estimates provided by the perception module and on topological info provided by the global planner.</p>
<h4 id="continuous-controller"><a href="#continuous-controller" class="headerlink" title="continuous controller"></a>continuous controller</h4><p>using PID controller, which inputs current pose, speed, a list of waypoints, and outputs steering, throttle, and brake.</p>
<h2 id="carla-release"><a href="#carla-release" class="headerlink" title="carla release"></a>carla release</h2><h3 id="9-1"><a href="#9-1" class="headerlink" title="9.1"></a>9.1</h3><p>1)   enable client to detect collisions and determine lane changes :  <code>sensor.other.collision</code>, <code>sensor.other.lane_detector</code>, </p>
<p>2)  access to the road network, waypoints nearby current vehicle and define user navigation algorithms: <code>Map</code></p>
<p>3) support new map created from external RoadRunner/VectorZero, in OpenDriven map standard </p>
<h3 id="9-2"><a href="#9-2" class="headerlink" title="9.2"></a>9.2</h3><p>1) simulation of traffic scenarios by <a href="https://github.com/carla-simulator/scenario_runner" target="_blank" rel="external"><code>Scenario Runner</code></a>. e.g.  following leading vehicle,  stationary object crossing, dynamic object crossing, opposite vehicle running red light, vehicle turn right/left etc</p>
<p>2)upgraded ROS bridge </p>
<p>3) vehicle navigation from client side: <code>BasicAgent</code>, navigate to a point given location while dealing with other vehicles and traffic lights safely;  <code>RoamingAgent</code>, drives around making random choices when presented to multiple options</p>
<h3 id="9-3"><a href="#9-3" class="headerlink" title="9.3"></a>9.3</h3><p>1) new town and new pedestrains </p>
<p>2) no rendering mode, a 2D map visualization tool that display vehicles, traffic lights, speed limits, pedestrains, road, etc. help to improve the server framerate</p>
<p>3) traffic light class in client <code>TrafficLightState</code> </p>
<p>4) new sensors.  <code>ObstacleDetector</code>, a simple raycast sensor to detect something in front of the ego vehicle and what is it; and <code>GlobalNavigationSatelliteSystem</code>, attach to ego vehicle and get its geolocation, which is based on the geo-reference define in OpenDriven file associated with each map.</p>
<h3 id="9-4"><a href="#9-4" class="headerlink" title="9.4"></a>9.4</h3><p>1) allow client side to change physics properties of vehicle or their components in runtime <code>WheelsPhysicsControl</code> </p>
<p>2) logging and playback system, which includes a camera-following mode to follow a target actor while replaying the simulation, and can replay situations from different viewpoints. and the logging query engine allow users to query different types of events.</p>
<p>3) random streaming port, which makes it possible to stream sensor data in a secondary port</p>
<p>4) import maps,  replace maps as tar.gz files in “ExportedMaps” folder </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/29/paper-reading-autonoVi-AV-planning-with-dynamic-maneuvers-and-traffic-constraints/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/29/paper-reading-autonoVi-AV-planning-with-dynamic-maneuvers-and-traffic-constraints/" itemprop="url">paper reading-autonoVi: AV planning with dynamic maneuvers and traffic constraints</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-29T10:21:35-04:00">
                2019-03-29
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/29/paper-reading-autonoVi-AV-planning-with-dynamic-maneuvers-and-traffic-constraints/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/29/paper-reading-autonoVi-AV-planning-with-dynamic-maneuvers-and-traffic-constraints/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>this is the advanced driver module in <a href="https://zjli2013.github.io/2019/03/28/paper-reading-autono-Vi-Sim-simualtion-platform/" target="_blank" rel="external">Vi-sim simulation platform</a>. this driver module algorithm pipeline:  </p>
<p>1) a route plan by graph-search over the network of roads </p>
<p>2) rules based guiding trajectories generation(traffic and lane following rules) </p>
<p>3) set of candidate trajectories(control inputs) generation and evaluated by vehicle dynamic model and collision free model</p>
<p>4) most feasible trajectory evaluated through optimization</p>
<h3 id="vehicle-state-space"><a href="#vehicle-state-space" class="headerlink" title="vehicle state space"></a>vehicle state space</h3><p>the full state of a vehicle updates: </p>
<p><code>X = (x, y, v, theta, throttle, steering, behavior)</code></p>
<p>the vehicle updates its plan at a fixed palnning rate <code>dt</code>; at each pllaning step, the vehicle computes a target speed <code>v</code> and target steering <code>theta</code> to be achieved by the control system </p>
<p><code>S(u, X)</code> determine if a set of control is feasible, given current state of the vehicle, <code>S(u, X)</code> will return false if the given input <code>u</code> cause a loss of traction or control.</p>
<h3 id="sensing-and-perception"><a href="#sensing-and-perception" class="headerlink" title="sensing and perception"></a>sensing and perception</h3><p>the sensing module provide an approximation of the center line of lane, closet point on the lane center to the ego-vehicle, and friction coefficient.</p>
<h3 id="route-choice-and-behavior-state"><a href="#route-choice-and-behavior-state" class="headerlink" title="route choice and behavior state"></a>route choice and behavior state</h3><p>behavior set includes merging, right turn, left run, keep straight. the behavior state of the vehicle is described as a finite-state machine(turn left, turn right, merge left, merge right), which restrict potential control decisions and adjust the weight of the cost function. </p>
<h3 id="guiding-path"><a href="#guiding-path" class="headerlink" title="guiding path"></a>guiding path</h3><p>the ego-vehicle computes a set of waypoints along the current lane at fixed time intervals. <code>how to create the path based on waypoints</code> </p>
<h3 id="collision-avoidance"><a href="#collision-avoidance" class="headerlink" title="collision avoidance"></a>collision avoidance</h3><p>define obstacles domain for each neighbor of the ego-vehicle, which is defined as all controls that could lead to collision.  the obstacles domain and the set of dynamic infeasible domain form the boundary of collision-free space for the ego-vehicle. </p>
<h3 id="trajectory-sampling"><a href="#trajectory-sampling" class="headerlink" title="trajectory sampling"></a>trajectory sampling</h3><p>the exact obstacle domain is not computing time efficent, instead here use a sampling strategy around <code>theta</code> and <code>v</code> to determin a feasible control. each sample is referred to as a candidata control <code>u_c</code>.</p>
<h3 id="trajectory-cost-function"><a href="#trajectory-cost-function" class="headerlink" title="trajectory cost function"></a>trajectory cost function</h3><p>once the set of suitable control candidates has been computed, the most feasible control will be selected by minimizing the cost function for each sample point <code>i</code> : </p>
<p><code>C = sum_i{ C_path(i) + C_cmft(i) + C_mnvr(i) + C_prox(i)</code> </p>
<p>1) path cost, defined as success at tracking its path and the global route.</p>
<p>2) comfort cost, <code>C_cmfg = ||vel_acc|| +  ||theta_acc||</code> </p>
<p>3) maneuver cost, penalize lane changes <code>C_mnvr = lane_change</code> </p>
<p>4)  proximity cost, prevent the ego vehicle from passing close to neighbors. </p>
<h3 id="control-input"><a href="#control-input" class="headerlink" title="control input"></a>control input</h3><p>one PID controller to driven current speed to match the target speed;  another PID controller drives the current steering angle to match the target.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/29/未来5年在哪里-6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/29/未来5年在哪里-6/" itemprop="url">未来5年在哪里(6)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-29T10:18:02-04:00">
                2019-03-29
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/29/未来5年在哪里-6/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/29/未来5年在哪里-6/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="广州之行"><a href="#广州之行" class="headerlink" title="广州之行"></a>广州之行</h2><p>投自动驾驶，隐约有些不安全感。比如，激光雷达、定位l3+的HDMap, 仿真环境，l4全栈解决方案。一旦l3+以上的自动驾驶方案短期内不会量产，做这些方向的创业团队、产品投入都会”死“。</p>
<p>国内所有行业的激烈竞争，造成包括互联网公司、主机厂、创业团队，都强烈需要落地产品。而对于一个遥遥无期，5～10年，甚至更久以后才能实现的产品的技术研发投入是所有公司不能承受之轻。相反，对能快速落地的产品、应用场景，也是各方发力的地方。比如， l1 ~ l2.5 的 adas 产品。</p>
<p>在国外主机厂侧重研发；国内主机厂侧重落地。也是回国感受到的落差。朋友讲，国内主机厂对供应商的依赖很重。长城的情况大概就是，l3以下的adas产品软硬件全栈由供应商提供，主机厂自身连标定/调参都不参与😓。主机厂的趋势是慢慢自己做，也是国内汽车人的机会吧。相比，福特，通用都是15+万员工的规模，国内自主品牌主机厂的员工规模在1/20。另外，国内主机厂员工大多是dre角色。</p>
<p>行业走近了，都是深水。想轻轻松松工作，就是表面划水。对行业风险缺乏判断、或者不能承受行业风险的，想挑容易的活儿，那在哪行都待不长。所以啊，年轻人就要在压力环境下活着。</p>
<h2 id="汽车创业"><a href="#汽车创业" class="headerlink" title="汽车创业"></a>汽车创业</h2><p>了解到一些汽车行业的创业者，比如做汽车云、车载服务、以及自动驾驶软硬件方案。可能因为创业方向本身只是依托于自驾、智能网联车等具体应用场景，其所创的技术只是一些在其他领域成熟或新的技术。比如，云计算、移动操作系统、视觉AI、5G等技术在汽车载体上的转化应用。</p>
<p>所看到的汽车领域的创业，更像是一个技术转化。而源于汽车领域自身的新创意，似乎只在博世、大陆等成熟技术积淀的企业里面逐步推进的。而且行业内新应用场景的标准定义也是由这些大厂主导的。比如，AutoSar, LTE-V2X, ADAS前装需求定义等等。</p>
<p>没有行业积淀的汽车创业，看着叫心悬，这样都敢玩！他们最好的命运可能是被主机厂收购，但是更大可能是被互联网巨头挤掉，无声无息。从广州回家的路上想到：自己曾经也是有梦想的人，面对现在的市场环境，也许能去个大平台做点事，就聊以自慰了。</p>
<p><code>创业</code> 本是个挺好的事儿，但必须有强大的信念，觉得这事儿一定能成。只想搞个概念移植，那是注定要凉。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/28/paper-reading-autono-Vi-Sim-simualtion-platform/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/28/paper-reading-autono-Vi-Sim-simualtion-platform/" itemprop="url">paper reading- autono Vi-Sim simualtion platform</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-28T05:36:00-04:00">
                2019-03-28
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/28/paper-reading-autono-Vi-Sim-simualtion-platform/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/28/paper-reading-autono-Vi-Sim-simualtion-platform/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="introduction-of-Vi-Sim"><a href="#introduction-of-Vi-Sim" class="headerlink" title="introduction of Vi-Sim"></a>introduction of Vi-Sim</h2><ul>
<li><p>data generation, allowing exports of traffic data and virtual sensor data on the vehicle, which can be used in training DL by generating automatically labelled classification and control data</p>
</li>
<li><p>dynamic traffic conditions, with varying vehicles, pedestrians, lighting, weather </p>
</li>
<li><p>rapid scenario construction</p>
</li>
</ul>
<h2 id="simulation-modules"><a href="#simulation-modules" class="headerlink" title="simulation modules"></a>simulation modules</h2><p> Vi-Sim is divided into 8 extensible modules. </p>
<h3 id="roads"><a href="#roads" class="headerlink" title="roads"></a>roads</h3><p> represented by center line, #lanes, directions, surface friction. the roads can quick constructed by drawing splines on the landscape</p>
<h3 id="road-network"><a href="#road-network" class="headerlink" title="road network"></a>road network</h3><p> provides connectivity information of road and traffic infrastructure. the road network provides routing and localization purpose.</p>
<h3 id="infrastructure"><a href="#infrastructure" class="headerlink" title="infrastructure"></a>infrastructure</h3><p> represents traffic lights, signage, and any entities that will modify the behavior of vehicles on the road. </p>
<h3 id="environment"><a href="#environment" class="headerlink" title="environment"></a>environment</h3><p> represents the time of the day, weather, rain conditions, road friction etc. </p>
<h3 id="non-vehicle-traffic"><a href="#non-vehicle-traffic" class="headerlink" title="non-vehicle traffic"></a>non-vehicle traffic</h3><p> basically pedestrains and cyclists in the map. both are following safe traffic rules.</p>
<h3 id="data-capture"><a href="#data-capture" class="headerlink" title="data capture"></a>data capture</h3><p> this module used for logging data of the environment as well as sensor data from ego vehicle</p>
<h2 id="driving-modules"><a href="#driving-modules" class="headerlink" title="driving modules"></a>driving modules</h2><h3 id="vehicle"><a href="#vehicle" class="headerlink" title="vehicle"></a>vehicle</h3><p>  represented as a physical-driven entity with specific tire, steering, sensor parameters. </p>
<p>  the vehicle has 3 components: </p>
<pre><code>* control is provided with steering, throttle, brake inputs;  


* dynamics is implemented in Nvidia physX engine; 


* perception component is a ray-cast with configurable uncertainty, detection time, classification error rate, and sensor angle/range. 
</code></pre><p>   a vehicle can equip multiple sensors. the perception component provides interface to a generic camera interface and Monte Carlo scanning ray-casts, which can be extended to Lidar/camera based NN claassifiers. </p>
<h3 id="driver"><a href="#driver" class="headerlink" title="driver"></a>driver</h3><p>   driving decision module, who fuses information from road network and vehicle’s sensor to make decisions. currently there are 3 driver models</p>
<pre><code>   * lane-following driver, which employs control command like lane-keeping ADAS

   * manual driver, allows a human drive the vehicle

* autonoVi driver, use optimization-based maneuvering with traffic constraints to generate advanced behaviors 
</code></pre><h2 id="limitations"><a href="#limitations" class="headerlink" title="limitations"></a>limitations</h2><ul>
<li><p>lack of calibaration configuration to replicate specific sensors</p>
</li>
<li><p>driver modules are limited to hierarchical, rule-based approaches</p>
</li>
<li><p>real traffic conditions </p>
</li>
</ul>
<h2 id="thoughts"><a href="#thoughts" class="headerlink" title="thoughts"></a>thoughts</h2><pre><code>1) sensor components in simulation, e.g.  Lidar, camera, Radar

2) sensor calibration in simulation, Apollo and Carla may has some good suggestions 

3) multi-agents environment

4) distributed framework to ensure real time multi-agents simualtion 
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/28/paper-reading-distributed-simulation-platform-for-autonomous-driving/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/28/paper-reading-distributed-simulation-platform-for-autonomous-driving/" itemprop="url">paper reading-distributed simulation platform for autonomous driving</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-28T01:21:13-04:00">
                2019-03-28
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/28/paper-reading-distributed-simulation-platform-for-autonomous-driving/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/28/paper-reading-distributed-simulation-platform-for-autonomous-driving/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>to test newly developed algorithms, due to the massive amount of simulation data, need a distributed simulation platform based on Spark distributed framework.</p>
<ul>
<li><p>simulation based on synthetic data, used in control and planning </p>
</li>
<li><p>simulation based on real data playback, used to test function and performance of different components</p>
</li>
</ul>
<p>in autonomous driving system, each functional module in ROS is deployed as a node, the communication between nodes rely on the messages with well-defined formats. so the test of each module is independent, we can develop simulation module for each functional module. </p>
<h2 id="anatomy-of-simulator"><a href="#anatomy-of-simulator" class="headerlink" title="anatomy of simulator"></a>anatomy of simulator</h2><p>there should be a dynamic model of the car, a vehicle dynamic model;  then the external environment is needed, which includes static and dynamic scenes.</p>
<p>the simulator can decompose external environment into basic elements, and rearranges the combination to generate a variety of test cases, each simulating a specific scenario. </p>
<p>e.g. the position, speed, next step command of the barrier vehicle can give different basic elements. </p>
<h2 id="ROS-based-simulator"><a href="#ROS-based-simulator" class="headerlink" title="ROS based simulator"></a>ROS based simulator</h2><p>to use the real traffic data to reproduce the real scene requires a distributed simulation platform. </p>
<ul>
<li><p>ROSBAG, record from Topic and replay message to Topic. </p>
<p>  the Record function is to create a recording node in ROS, and call the subscribe method to receive ROS message to all Topics, and then write the message to Bag file. </p>
<p>  the Play function is to establish a play node, and call the advertise method to send message in bag to specified Topic. </p>
</li>
</ul>
<h2 id="Spark-distributed-platform"><a href="#Spark-distributed-platform" class="headerlink" title="Spark distributed platform"></a>Spark distributed platform</h2><p>the Spark driver launch different simulation applications, e.g. localization algorithms, object recoginization algorithms, vehicle decision-making and control algorithms etc, then allocate resources to each Spark worker, who first reads the RosBag data into memory and launches a ROS node to process the incoming data. </p>
<p>the interface between Spark and ROS is through Linux pipe, basically data written to the write end of the pipe is buffered by the kernel until it is read from the read end of the pipe.</p>
<p>two problems: 1) Spark only support text-based data consuming; 2) Spark memeory to ROBag </p>
<h3 id="Binary-data-streaming"><a href="#Binary-data-streaming" class="headerlink" title="Binary data streaming"></a>Binary data streaming</h3><p>the core Spark data structure is resilient distributed dataset (RDD). to process and transform binary data into a user-defined format and transform the output of Spark computation into a byte stream, even further to a generic binary file(HDFs)</p>
<pre><code>1) encode and serialize the binary files(image, lidar input data) to form a binary byte stream 

2) de-serialize and decode the binary stream, according to interpret byte stream into an understandable format and perform target computation

3) the output then be encoded and serialized before passed in RDD partitions(e.g. HDFs), and returned to Spark driver 
</code></pre><h3 id="data-retrieval-through-ROSbag-cache"><a href="#data-retrieval-through-ROSbag-cache" class="headerlink" title="data retrieval through ROSbag cache"></a>data retrieval through ROSbag cache</h3><p>two things: reading from memory through ROSbag play, and writing to memory through ROSbag record. </p>
<p>solution: design a memoryChunkedFile class, derived from ChuckedFile class, to read/write memory rather than files.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/27/paper-reading-perception-planning-control-and-coordination-for-autonomous-vehicles/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/27/paper-reading-perception-planning-control-and-coordination-for-autonomous-vehicles/" itemprop="url">paper reading-perception, planning, control and coordination for autonomous vehicles</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-27T05:41:05-04:00">
                2019-03-27
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/27/paper-reading-perception-planning-control-and-coordination-for-autonomous-vehicles/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/27/paper-reading-perception-planning-control-and-coordination-for-autonomous-vehicles/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Lidar-Perception"><a href="#Lidar-Perception" class="headerlink" title="Lidar Perception"></a>Lidar Perception</h2><ul>
<li><p>point cloud based approach, directly use the raw sensor data for further processing. usually applied a voxel-based filtering to reduce the number of points </p>
</li>
<li><p>feature based approach, extract parametric features out of the point cloud, and represent the environment usign extracted features (out of date)</p>
</li>
<li><p>grid based approach</p>
</li>
</ul>
<h3 id="segmentation-algorithms"><a href="#segmentation-algorithms" class="headerlink" title="segmentation algorithms"></a>segmentation algorithms</h3><p>cluster points into multiple homogeneous groups.</p>
<ul>
<li>edge based method</li>
<li>region based method, cluster neighborhood points based on certain criteria</li>
<li>model-based / parametric method,</li>
<li>graph based method </li>
</ul>
<h3 id="detection-algorithms"><a href="#detection-algorithms" class="headerlink" title="detection algorithms"></a>detection algorithms</h3><p>categorize each cluster into different objects, the information in each cluster is mainly from spatial relationship and Lidar intensity of the points. </p>
<h2 id="Vision"><a href="#Vision" class="headerlink" title="Vision"></a>Vision</h2><p>usually deal with road detection and on-road object detection. </p>
<h2 id="Road-Detection"><a href="#Road-Detection" class="headerlink" title="Road Detection"></a>Road Detection</h2><h3 id="lane-mark-detection"><a href="#lane-mark-detection" class="headerlink" title="lane mark detection"></a>lane mark detection</h3><ul>
<li><p>lane line feature extraction<br>basically identify the pixels that belong to lane line marks. </p>
</li>
<li><p>fitting the pixels into different models</p>
</li>
</ul>
<ul>
<li>estimate the vehicle pose(lateral position and moving orientation) based on the fitted model. </li>
</ul>
<h3 id="road-surface-detection"><a href="#road-surface-detection" class="headerlink" title="road surface detection"></a>road surface detection</h3><p>inform the self-driving car on the location of free space where it can drive without collision. usually three ways:</p>
<ul>
<li>feature based detection</li>
</ul>
<p>first identify the feature points or patches in the original image; based on the identified features, either model fitting or segmentation kind of algorithms will be applied to identify the road surfaces. </p>
<ul>
<li>feature based learning<br>first extract a set of features associated to pixels or image patches, then train a classifier based on the features to assign a road or non-road label to the pixels or patches</li>
</ul>
<ul>
<li>deep learning</li>
</ul>
<h3 id="on-road-object-detection"><a href="#on-road-object-detection" class="headerlink" title="on-road object detection"></a>on-road object detection</h3><p>mainly concerns vehicle and pedestrain object classes, and mainly with deep learning based approaches, whose pipeline usually like:</p>
<p>1) the proposal bounding boxes needs to be generated around the input image</p>
<p>2) each proposal box will be sent through the CNN network to determine a classification and fine tune its bounding box location </p>
<h2 id="Fusion"><a href="#Fusion" class="headerlink" title="Fusion"></a>Fusion</h2><p>sensor fusion betweeen Lidar and camera is necessary to make the best use of these devices and achive a robust environment perception result. </p>
<h2 id="Localization"><a href="#Localization" class="headerlink" title="Localization"></a>Localization</h2><p>the problem of estimating the ego vehicle’s pose, can divided into 2 sub-problems:  pose fixing problem and dead reckoning problem. </p>
<ul>
<li><p>pose fixing problem is to predict a measurement given a pose, e.g. a map. </p>
</li>
<li><p>dead reckoning problem, the state is related to the observation by a set of differential equations, and these equations has to be integrated in order to navigate. </p>
</li>
</ul>
<p>map aided localization algorithm use local features to achieve highly precise localization.  e.g. SLAM.</p>
<p>a key event in smoothing based SLAM is loop closure, basically when features that have not been seen for a while are observed again from the sensor readings. when a loop closure is detected, the error caused by imperfect odometry can then be removed, and a substantial portion of the map can be updated. </p>
<p>approaches to semantic mapping can be categorized into three ways:  object based, appearance based, and activity based. </p>
<ul>
<li><p>appearance based semantic mapping, interpret sensor readings to construct semantic information of the environment</p>
</li>
<li><p>object based semantic mapping, use the occurrence of key objects to build a semantic understanding of the environments, where object recognition and classification is important. </p>
</li>
<li><p>activity based semantic mapping, relies on information about the activities of the agents around the ego vehicle. </p>
</li>
</ul>
<h2 id="Planning"><a href="#Planning" class="headerlink" title="Planning"></a>Planning</h2><h3 id="mission-planning"><a href="#mission-planning" class="headerlink" title="mission planning"></a>mission planning</h3><p>performed through graph search over a directed graph network, which reflects road/path network connectivity. </p>
<h3 id="behavioral-planning"><a href="#behavioral-planning" class="headerlink" title="behavioral planning"></a>behavioral planning</h3><p>decision making to ensure the vehicle follows any road rules and interacts with other agents in a conventional, safe manner. </p>
<h3 id="motion-planning"><a href="#motion-planning" class="headerlink" title="motion planning"></a>motion planning</h3><p>the process of deciding on a sequence of actions to reach a specified goal, typically based on avoiding colisions on a sequence of actions to reach a specified goal. </p>
<ul>
<li>combinatorial planning, builds a discrete representation of the real environment, and finds a complete solution. </li>
</ul>
<ul>
<li>sampling-based planning, utilizes a collision checking module to conduct discrete searching over samples drawn from the configuration space, which rely on random sampling of continuous spaces and the generation of  a feasible trajectory graph where feasibility is verified through collision checking of nodes and edges to connect these nodes .</li>
</ul>
<h3 id="planning-in-dynamic-environments"><a href="#planning-in-dynamic-environments" class="headerlink" title="planning in dynamic environments"></a>planning in dynamic environments</h3><ul>
<li><p>decision making structures for obstacle avoidance </p>
<p>  to monitor regions along the intended path for potential obstacle collisions, where these regions are labeled as “critial zones”, and checking against the trajectories of all nearby vehicles to determine a “time to collision”. </p>
</li>
</ul>
<ul>
<li>planning in space-time </li>
</ul>
<ul>
<li><p>control space obstacle represnetations </p>
<p>  rather than checking for collisions directly in robot’s configuration space, directly plan in the control space by prohibiting certain control actions which are predicted to lead to collision.</p>
</li>
</ul>
<h3 id="incremental-planning-and-replanning"><a href="#incremental-planning-and-replanning" class="headerlink" title="incremental planning and replanning"></a>incremental planning and replanning</h3><p>a means of incrementally generating sub-goals, a new plan is generated as often as a new sub-goal is defined. iteratively replanning to generate new solution trajectories presents a potential opportunity to carry over knowledge from previous planning iterations to subsequent planning iterations.</p>
<h2 id="Control"><a href="#Control" class="headerlink" title="Control"></a>Control</h2><h3 id="feedback-control"><a href="#feedback-control" class="headerlink" title="feedback control"></a>feedback control</h3><p>e.g. proportional-integral-derivative(PID) controller, the limitation of feedback-only control, is has delayed response to errors.</p>
<h3 id="model-predictive-control"><a href="#model-predictive-control" class="headerlink" title="model predictive control"></a>model predictive control</h3><h3 id="trajectory-generation"><a href="#trajectory-generation" class="headerlink" title="trajectory generation"></a>trajectory generation</h3><ul>
<li><p>combined trajectory generation and tracking </p>
</li>
<li><p>separate trajectory generation and tracking </p>
<p>  1) trajectory generation, to find an entire control input, which corresponds to some desired state trajectory. can be dealed as a two point boundary value problem, with a starting state and a final state. </p>
<p>  1.1) sensor based trajectory generation</p>
<p>  1.2) dynamic based trajectory generation </p>
</li>
</ul>
<h3 id="trajectory-tracking"><a href="#trajectory-tracking" class="headerlink" title="trajectory tracking"></a>trajectory tracking</h3><ul>
<li><p>geometric methods</p>
<p>  pursues a point along the path that is located at a certain lookahead distance away from the vehicle’s current position. the input is waypoints, rather than smooth curves. </p>
</li>
<li><p>model based methods </p>
<p>  kinematic model based controllers performs well at low speed applications, but the error increase as the vehicle speed and curvature rate of path increases.</p>
<p>  dynamic model based controllers performs well for higher speed driving applications</p>
</li>
</ul>
<h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p>this is an overview of self-driving car system. From a job-hunting view, the algorithms details are more important and better with some practial experience.</p>
<p><a href="https://www.mdpi.com/2075-1702/5/1/6/htm" target="_blank" rel="external">paper link</a> </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/27/book-reading-第一本无人驾驶技术书/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/03/27/book-reading-第一本无人驾驶技术书/" itemprop="url">book reading: 第一本无人驾驶技术书</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-27T05:39:51-04:00">
                2019-03-27
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/03/27/book-reading-第一本无人驾驶技术书/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2019/03/27/book-reading-第一本无人驾驶技术书/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="一些方案"><a href="#一些方案" class="headerlink" title="一些方案"></a>一些方案</h2><ul>
<li>基于gps/imu融合的定位</li>
<li>基于视觉的定位</li>
<li>基于点云的定位</li>
<li>基于视觉的物体识别与跟踪</li>
<li>基于lidar的物体识别与跟踪</li>
</ul>
<h2 id="基于点云的定位"><a href="#基于点云的定位" class="headerlink" title="基于点云的定位"></a>基于点云的定位</h2><p>简化概率问题：已知t_0 时刻的点云信息，以及t_1时刻，无人车位置的先验概率分布，求无人车位置的概率分布。</p>
<p>贝叶斯法则:</p>
<p>  $$ P(X_t) =  P(Z_t | X_t ) \cdot \ \vec(P(X_t)) $$ </p>
<p>$\vec(P(X_t))$ 是汽车当前位置的概率分布； $P(Z_t | X_t)$ 是当前位置下观察的点云概率分布。</p>
<h2 id="ROS-based-system"><a href="#ROS-based-system" class="headerlink" title="ROS based system"></a>ROS based system</h2><p>ROS是基于消息传递通信的、分布式多进程框架。Topic发布、接受是一种异步通信方式； Service服务是一种利用同步通信请求/回复交互的分布式系统。</p>
<h2 id="传感器"><a href="#传感器" class="headerlink" title="传感器"></a>传感器</h2><h3 id="Lidar"><a href="#Lidar" class="headerlink" title="Lidar"></a>Lidar</h3><ul>
<li>环境感知： 通过雷达扫描汽车周围的环境3d模型。运用相关算法比对上一帧和下一帧，从而匹配环境中的其他车辆或行人</li>
<li>slam定位：实时扫描地图，与高精地图中的特征物比对，实现导航及精准定位。</li>
<li>供应商： Velodyne </li>
</ul>
<h3 id="毫米波雷达"><a href="#毫米波雷达" class="headerlink" title="毫米波雷达"></a>毫米波雷达</h3><ul>
<li><p>可用工作频段 24ghz、77ghz, 波长 1 ～ 10 mm。77ghz物体分辨率较24ghz提高2～4倍，测速和测距精度提高3~5倍。电磁波频率越高，距离和速度的检测解析度越高。</p>
</li>
<li><p>供应商</p>
<p>   射频芯片：24ghz成熟供应（博世、飞思卡尔）； 77ghz没有对中国开放</p>
<p>   雷达数据处理芯片：恩智浦，意行半导体</p>
</li>
</ul>
<h3 id="摄像头"><a href="#摄像头" class="headerlink" title="摄像头"></a>摄像头</h3><ul>
<li>高动态</li>
<li>中低像素</li>
<li>适合温度范围 -40 ～ 80 度</li>
<li>防磁抗振 </li>
<li>寿命长</li>
</ul>
<h2 id="计算平台"><a href="#计算平台" class="headerlink" title="计算平台"></a>计算平台</h2><ul>
<li><p>计算单元与计算负载</p>
<p>  GPU执行卷积任务最有效，DSP执行特征提取最有效。</p>
</li>
<li><p>移动端soc架构</p>
<p>  I/O子系统与前端传感器交互；DSP负责图像处理流以进行特征提取；由GPU进行目标识别和其他深度学习任务；由一个多核CPU完成规划、控制和互动的子任务；由FPGA进行动态重构以分时共享的方式完成传感器数据压缩上传，物体跟踪和流量预测等。计算部件和I/O部件之间通过共享内存进行数据通信。</p>
</li>
</ul>
<h2 id="系统安全"><a href="#系统安全" class="headerlink" title="系统安全"></a>系统安全</h2><p>安全问题：强磁场干扰IMU；假大功率的gps信号；干扰激光雷达，在无人处周围放置强反光物；干扰高精地图的更新； ros系统劫持、通信修改。obd-2入侵， 充电桩入侵，车载cd入侵，蓝牙入侵。</p>
<h2 id="Spark与ROS的分布式模拟平台"><a href="#Spark与ROS的分布式模拟平台" class="headerlink" title="Spark与ROS的分布式模拟平台"></a>Spark与ROS的分布式模拟平台</h2><p>基于合成数据的模拟；基于真实数据回放的模拟。</p>
<h2 id="高精地图"><a href="#高精地图" class="headerlink" title="高精地图"></a>高精地图</h2>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/8/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><a class="extend next" rel="next" href="/page/10/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="David Z.J. Lee" />
          <p class="site-author-name" itemprop="name">David Z.J. Lee</p>
           
              <p class="site-description motion-element" itemprop="description">what I don't know</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">151</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">34</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/ZJLi2013" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/zhengjia13/" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  LinkedIn
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">David Z.J. Lee</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://zjlee.disqus.com/count.js" async></script>
    

    

  




	





  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

  

</body>
</html>
