<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[model based design sucks]]></title>
    <url>%2F2019%2F07%2F18%2Fmodel-based-design-sucks%2F</url>
    <content type="text"><![CDATA[AV development includes perception, sensor fusion, location &amp; mapping, decision-making &amp; control (or motion planning), embedded, simulation and maybe many system-glue software tools. L3 planning &amp; control is now expert-based decision system, which basically defines rules to make decision, where model based design(mbd) is a helper. Waymo mentioned their hybrid decision-making solution, basically Machine Learning(ML) will take a big part of the situations, but still space to allow rule-based solution to take priority. when consider to ML decision making, mdb will become less useful. why model-basedTraditional OEMs follow vehicle-level safety requirements(ASIL-D) to develop vehicle products and components, usually can be represented as the V style development, from user requirs, system design, implmenent to test verification. to go through the whole V process take a rather long time, e.g. for a new vehicle model, it means 2~5 years. Commercial hardware and software(mobile apps) products which has lower level safety requirements, however, can iterate in a quicker frequency. the safety requirements drive the product development in a very different way, compared to common Internet products, which include more straight-forward programming skills and software architecture mindset. but to satisfy the additional, or should say the priority safety requirements, how to organize the code is less important than how to verify the functions is to satisfy the safety. so there comes the model-based design, the most-highly feature of which is to support system test and verify at pre-product period. of course, model-based design should be easily to build up prototype and visualize the system, which is the second feature of mbd, working similar like a microsoft vision e.t.c thirdly, from design to product, is auto code generation. which means once the design is verified, you don’t need to go back to write code again, but directly generate code from the design graph. model-based design toolchain is already a whole eco-system, e.g. system design, auto code generator, test tools. and all these tools should be first verified by ASIL-D standard. Internet AI companies once thought it would be easy to take over this traditional development by Internet agile development, while the reality is they still depends on model-based design at first to verify the system, then back to implement code again, which should be more optimized than auto-generated ones, which is one drawbacks of mbd, as mbd is tool-depended, e.g. Matlab, if Matlab doesn’t support some most updated libs, then they are not in the auto-code, and most time Matlab is far behind the stable version of libs outside. what mbd can’t dombd is born to satisfy safety requirments in product development. so any non safety required product won’t use mbd. and by nature, mbd is good at turning mathematical expressions to system languages, and logical relations to state flows, so any non-articulatable system is difficult to represent in mdb languages. in vehicle product development, engine, powertrain, ECU, brake system, ADAS, L3 motion planning, e.t.c have depends heavily on mbd. but also we can predict, L3+ applications arise, with image, cloud point based object detection, data fusion, SLAM, AI-driven planning, IVI, V2X, will hybrid mbd with many Internet code style. industry experience: a metaphysicssome friends say mass-product-experience makes him more value than new birds. since industry experience is not transparent, as there is a no clear bar to test the ability/value of the enginer, unlike developers, who can valued by their product, or skills, also the same reason make these guys who stay long in the industry sounds more valued, and they have more likey went through one or many mass product experience. but at most, industry product depends e.g. vehicle, on teamwork, even the team lead can’t make it by himself, unlike developer, a top developer can make a huge difference, much valued than a team of ordinary ones.]]></content>
  </entry>
  <entry>
    <title><![CDATA[autosar sucks]]></title>
    <url>%2F2019%2F07%2F15%2Fautosar-sucks%2F</url>
    <content type="text"><![CDATA[what is AUTOSARbasically it’s an micro-service architecture for vehicle EE system. Each micro-service is called software component(swc), and it has uniform interfaces, while of which the implementation is varied. as the goal of AUTOSAR said: share on the standard (interface), compete in the implementation. the inter-connect of micro-services is through virtual function bus(vfb), which works as a gateway, guiding data flow from port A, from micro-serviceA to port B, from micro-serviceB the benefits of AUTOSAR is obvious, to design the interface at system level first, if any changed need, it can be updated quickly. after the system architecture is fixed, then go to the implementation details. refer input description software components(micro-services) description, only define the data flow, interface functions system, system topology(interconnection among ECUs, and available data buses, protocols etc) hardware, the available hardware(processors, sensors, actuators etc) system configurationused to distributes the software component descritpions to different ECU ECU configurationthe basic software(BST) and run-time environment(rte) of each ECU has been configured, this is based on the dedication of the application software components to each ECU. generation of executablesin this step to implement the software components, then build. this can be automated done by tool-chains. all steps up to now are supported by defining exchange formats(xml) and work methods. basic softwareeach swc has well-defined ports, either provider port(PPort) or request port(RPort), the swc interface can either be a client-server interface or sender-receiver interface. with a PPort, the swc will impelment data generation; with a RPort, the swc will implement data read. communication manager (ComM), is a resource mananger to encapsulates communication related basic software modules. the actual bus states are controlled by the corresponding bus state manager, e.g. CAN/FlexRay/Lin bus. when ComM request a specific commmunication mode from the state manager, it will map the communication mode to a special bus state. network management modules (NM) works in bus-sleep mode and only support broadcast communication. diagnostic communication manager(DCM), a common API for diagnostic services. CAN driver performs the hardware access and provides a hardware-independent API to upper layers; it can access hardware resources and converts the given information for transmission into a hardware specic format and triggers the transmission. runtime environment(RTE)between basic software to upper application softwares, I think it’s mostly vfb. application software componentsfor now, e.g. ADAS, traditional EE.]]></content>
      <tags>
        <tag>AUTOSAR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[play with ros]]></title>
    <url>%2F2019%2F07%2F13%2Fplay-with-ros%2F</url>
    <content type="text"><![CDATA[ros filesystem toolsfirst check ROS_PACKAGE_PATH, where defines all ROS packages that are within the directories. 1234567891011rospack find [package-name]rospack list roscd [package-name]``` take an example, to locate `rosbridge_websocket.launch` ```shell rospack find rosbridge* #rosbridge_serverroscd rosbridge_servercd launch another tool to view ros-launch: roslaunch-logs write a .launch filelaunch files, which uses XML format, usually make a directory named “launch” inside the workspace to organize all launch files, and it provides a convenient way to start up multiple nodes and master, it processs in a depth-first tarversal order. usually launch files can be put a launch folder under a ros node project. 123roslaunch package_name launch_file#or roslaunch /path/to/launch_file an sample launch file: 123&lt;launch&gt; &lt;node pkg="package_name" type=" " name=" " output=" " args=" " /&gt;&lt;/launch&gt; args can define either env variables or a command. node/type There must be a corresponding executable with the same name. rvizrviz can help to playback sensor rosbag at lab. and also the visualization tool in algorithm/simulation development. someone(at 2014) said Google’s self-driving simulation has used rviz: a sample with rviz to visualize rosbag info: 12345# terminal 1 roscore # terminal 2 rosbag play kitti.bag -l rosrun rviz rviz -f kitti-velodyne rosbagthe sensor ros node will collect data in rosbag during physical or vitual test, then playback rosbag to develop or verify the sensing algorithms. or use to build simulation scene. a few common commands, and also rosbag support interactive C++/Python APIs. 1234rosbag record #use to write a bag file wit contents on the specified topicsrosbag info #display the contents of bag files rosbag play #play back bag file in a time-synchronized fashion kitti datasetare we ready for autonoous driving? – the KITTI vision benchmark suite, which is a famous test dataset in self-driving sensing, prediction also mapping and SLAM algorithm development. there are a few benchmars includes: stereo, basically rebuild the 3D object from multi 2D images. optical flow, used to detect object movement(speed, direction) scene flow, include other 3D env info, and objects from optical flow depth visual odometry object detection object tracking road/lane detection semantic evaluation catkin packagecatkin is ros package build/manage tool. mkdir -p ~/catkin_ws/src cd ~/catkin_ws/src catkin_create_pgk demo std_msgs rviz cd demo mkdir launch cat "&lt;launch&gt; &lt;node name="demo" type="rviz" -d="ls `pwd`" /&gt; &lt;/launch&gt; " &gt; demo.launch cd ~/catkin_ws catkin_make --pkg demo # add catkin_ws to cat "export ROS_PACKAGE_PATH=$ROS_PACKAGE_PATH:/path/to/catkin_ws/" &gt;&gt; ~/.bashrc]]></content>
      <tags>
        <tag>ros</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[play with Docker swarm/compose]]></title>
    <url>%2F2019%2F07%2F12%2Fplay-with-Docker-swarm-compose%2F</url>
    <content type="text"><![CDATA[Docker swarmdocker swarm is Docker nature cluster manager, with built-in DNS service found mechanism, and load-balancing mechanism. compare to k8s, is a light-weight and easy goers. create a swarm cluster12345678910111213141516export MASTER_IP=192.168.0.1docker swarm init --advertise-addr $&#123;MASTER_IP&#125; --name masterdocker swarm join --token tokens $&#123;MASTER_IP&#125; --name worker1 docker node ls # demote/ promote nodeID as managerdocker node demote/promote nodeID# rm node docker node rm worker1# stop swarm mode docker swarm leave create service123456789docker service create service-name # scale servicedocker service scael SERVICE=replicas docker service rm docker service inspect create overlay network12345docker network create --subnet=192.168.0.0/24 -d overlay ppss-netdocker network rmdocker network connect network-name docker-node in swarm mode, there are three network created by default: bridge0, the default network docker_gwbridge, local bridge used to connect containers hosted in the same host ingress, is a overlay network used in the swarm cluster however, in swarm mode, the default network for service is bridge, to across physical host, services need go through overlay network. load balancingIngress load balancingexpose Docker service to external network env Internal load balancingswarm mode has build-in DNS Docker composedocker compose is a manage/build tool to create application, which combine a bunch of micro-services, each of which can be ran as a Docker container. the docker-compose.yml configure file has to include each micro-service Dockerfile, and the application running scripts. service startup orderthe services defined in docker-compose.yml is not necessary depended to each other, so each serice can up individually, but of course they can has based on each other. docker-compose.ymlbest practice build path to Dockerfile, can be absolute path or relative (to .yml) path. Compose will buid the image based on contextsub-choice under build, point to the Dockerfile image the image will be used, if not locally, will pull from hub (vs Dockerfile) containe_name volumes path to attached volumes, in the format HOST:CONTAINER[:access mode] network_mode same as docker run --network init privileged command override launch command when service contianer start environment set env variables, in the format ENV:valueif only ENV, the value will be derived from host machine runtime: nvidia to suuport nvidia-docker e.g. 1234567nvsmi: image: ubuntu:16.04 runtime: nvidia environment: - NVIDIA VISIBLE DEVICES=all command: nvidia-smi stdin_open std io aviable tty virtual terminal sample yml from projecta sample yml for web app: 123456789services: web: build: . links: - "db: database" db: image: postgres a sample yml for general app CI: 12345678910111213141516171819202122232425262728services: build: build: context: ./Dockerfile image: docker-image container_name: build_app volumes: - ./build_scripts: /root/build commands: /root/build/build.sh run: context: ./Dockerfile image: docker-iamge container_name: run_app volumes: - ./run_scripts:/root/run environments: -DISPLAY -ROS_MASTER network_mode: host runtime: nvidia command: /root/run/run.sh test: #TODO docker-machinedocker-machine is a tool to build virtial host when hosted in one physical host or among multi-physical hosts. ros-dockerin self-driving software stack, ros is often used. and there is a need to deploy ros in docker. next time.]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[play with Docker]]></title>
    <url>%2F2019%2F07%2F12%2Fplay-with-Docker%2F</url>
    <content type="text"><![CDATA[Docker networking bridge: the default network driver, only in standalone containers; best when have multiple containers to communicate on the same host machine. host: for standalone containers, the Docker host use the host machine’s networking directly; best when need no isolated from the host machine. overlay: connect multi Docker containers, enable swarm services to communicate with each other, no OS-level routing; best when need containers running on different host machines to communicate. none: disable all networking the network base is open source project libnetwork containers can communicate through hostname, or through DNS(the now Docker engine has default built-in DNS server), but in early days, can use external dns, e.g. Blowb to host docker images, either pull to Docker Hub, or to create a private cloud by ownCloud, or docker save/export tools: 1234docker save -o /path/to/save/file image | gzipscp *.tar.gz remote_user@remote_hostnamedocker load *.tar.gz running GUI apps in Dockerthere is a benchmark GUI/openGL test in Linux glxgears. to test the host machine support ssh or container based apps, we can first do the following test: 1234567891011121314151617181920sudo apt-get install mesa-utilsglxinfo glxgears``` Docker by default is bash/text based, but `nvidia-docker` is a gui-supported Docker engine, which requires Nvidia OpenGL drivers and Nvidia Gpus of course. since the gpu hardware version and the docker engine version, please check the compatability at first. ## remote hosted apps * configure master and worker nodes communication by setting IP address in the same domain, and setting the master node IP address as the gateway IP address for all worker nodes, basically the master node will work as the swticher.* install xserver-common, xserver-utils, as Ubuntu by deafult doesn't have X-server. ```shellmaster:~/ ssh -X user@workerworker:~/ DISPLAY=:0worker:~/ ./gui_app for docker containers, there is also authority property need take care. Dockfilewhen the Docker container starts, usually we want to auto start a shell process, so by CMD or ENTRYPOINT defined in the Dockfile. for the base images, e.g. Ubuntu, busybox, are used as the base for upper applications, usually will use CMD at the end of Dockerfile; but if the Docker container is specially for a certain application, it’s usually using ENTRYPOINT. the last line of Ubuntu 16.04 Dockerfile: CMD &apos;/bin/bash&apos; usually in one Dockerfile, there is only one CMD or ENTRYPOINT, and it’s better written in exec format: CMD [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] since in shell format: CMD exectuable, param1, param2 Docker will trigger /bin/sh first by default, if not define a shell. and this shell is always the first process in this Docker container, which sometimes is not what we expected. when using both CMD and ENTRYPOINT in one Dockfile, the output will looks like append/pipe CMD command after ENTRYPOINT command. a sample of Dockerfile: 123456789FROM &lt;image&gt;:[&lt;tag&gt;] [AS &lt;name&gt;]ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt; ... &lt;dest&gt;ADD [" ", ... " "]COPY &lt;src&gt; ... &lt;dest&gt;RUN &lt;command&gt;VOLUME /mount/nameCMD ["executable", "param1", "param2"]CMD command par1 par2 from docker image to dockerfilewe can easily pull images from hub, but when we try to build some images directly, there is also way to get Dockfile from existing docker image: dfimage 1sudo docker pull chenzj/dfimage mount host volume to containereither we can define in Dockerfile by VOLUME, which is create a volume name in the base image, or during runtime, docker run -v /host/volume/path:/container/volume/path, to bind a host volume to current container.]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where are you in next 5 years 8]]></title>
    <url>%2F2019%2F07%2F09%2Fwhere-are-you-in-next-5-years-8%2F</url>
    <content type="text"><![CDATA[工薪和自由职业者/创业/老板，退休以后会有什么不同。也许对于工薪阶层，退休的生活也会如上班的：说不上的无奈感，没有痛快酣畅的体验过人生 — 离开了根本不享受的工作，也谈不上享受生活。就像《肖生克的救赎》被放出去的老头，离开了监狱，也融不进社会了。 有个表哥创业了，做了一个健身品牌，小有所成，进入持续创业，第二份是乡政企业办公软件。两份业很不一样。甚至表哥说，这份业估计一年后就结束，生活还在继续，下一份业在哪里，现在根本想不到，但是也不担心没有。 认识一个姑娘，88年，澳洲留学读了两年mba就12年回国，用我的眼光看，之后就没正紧上过班，走走玩玩也在这些年学了瑜伽，今年(2019年)开了一家店，32岁了过的跟20岁出头的姑娘一样，到底是没心没肺，还是把生活过成了别人羡慕的样子。她并不符合我的价值观，但是难道这样的人生不值得吗？ 年初在深圳，被这里的年轻人着实震惊了。大公司（华为）加班到凌晨，年轻的生命就像路旁的热带植被在绽放和燃烧。只是大表哥说了句，是被洗脑了。 老妈在好几个城市工作做，做保姆、帮厨、家政，走到哪里都得到顾客的喜欢，走到哪里都可以有饭吃，根本不担心没有技能，找不到工作。像一个自由职业者。 打工和创业当老板的mindset，似乎是本质的不同。 创业者/自由职业者，总会有出路，生活处处都通达。 对比下，打工者的心态。就是处处被堵，操的心一点不少，把脑袋削尖了跟黑压压的长江后浪推前浪的年轻人比拼，担心技术上比不过行家，担心项目被各种原因取消了，担心行业遇冷，担心被老板穿小鞋，担心30岁还没有不可替代的核心，担心35岁要开始讨生活了，担心工资比年轻人高容易被开，也开始担心身体健康、家人健康等等。 采取的解决办法也是围绕着这些压力了，人生没有朝向，谈不上洒脱和享受。 生活不止眼前的苟且，打工者真是委屈了心，把路走窄了，反而觉得这是唯一的出路。打工解决不了焦虑，必须转变。这世上，除了生死，都是小事。所以无所谓待业；找不到真正实现价值的事业，宁可像无业游民一样活着。 民企打工没有完善的制度，好的方面就是可以立山头，只要说动了领导，技术上可以大胆尝试，当然并不一定能得到支撑。 没有稳定的做产品的氛围，所以即便立了项目，也不一定能看到项目落地。对产品开发人员，就是不利于积淀。 这样的氛围下，见风使舵就是生存哲学。 可以联想到更广大的中小民企，更缺乏完善的产品流程和考评体系，老板一个人的话语权太大，打工者基本没有话语权。 出来自己干的人，哪些不同的品质？首先，压力的来源不该是跟成千上万人挤独木桥。一切可以明确定义的职位，比如，程序员、会计、工程师、个体网商，都挤满了人。而一旦陷入了这种思维，思考就会局限在削尖脑袋挤到这个行业/职位的头部。付出的代价/成本非常不成比例。简言之，就是洗脑了。 打工只适合初期的资本积累。所以，选择做舞蹈老师、瑜伽教练，咖啡馆老板的，慢慢都会生活和工作双赢，退休了也不愁不知道怎么经营生活。而单一大公司打工的，可能初期会在工作上得意，但是慢慢的生活和工作都会失去，而且退休了根本不会打理生活。 这些愿意出来自己干的人，更珍惜生活吧。所以不能接受将精力埋没在日复一日的工作中。这些自己出来干的人，都是被逼，当初没机会选择有保险的工作，只能自己走出一条道儿来。 刻意要避免打工，估计也是自找麻烦。所以平常心。 做技术的氛围到底什么环境/氛围适合做技术？北美的工作环境，相比国内，算是无忧无虑了，虽然有讨厌的印度人，但是如果有心总是有钱有时间捣鼓技术。不过反而，普通人在这样的环境下，是没有表现很强的科研热情。国内相比，待遇，工作的可爱度低，周围的大牛少了，但是反倒人因为生活和人的竞争感，反而会想多学点。 另一方面，国内的资本家似乎更缺乏对行业的敬畏心，资本家对这个行业就是个格外挣钱工具的心理，当然不会真正给这个行业带来真正伟大的技术推动。比如，当宝能系，恒大都砸出一叠钱说要造车，网上大张旗鼓的招聘，按照自动驾驶的各个模块：感知算法，运动规划，决策控制，地图定位开始招人的时候。一方面是哭笑不得，一方面是无奈，觉得身为工程师只是个棋子罢了，被一个工具/算法/模块给定义了。 相比这些只有钱的资本家的嘴脸，虽然汽车厂背后也站着资本家，似乎对汽车行业本身也更关心。当然，在中国，总是要面对钱，落地的现实。美国人可以谈vision, 3，5年不出产品，中国的资本市场基本不允许出现。所以，即使在国内的车厂做技术/研究，也是被量产推着。所以，整体氛围是浮躁，也就没办法专心下去]]></content>
  </entry>
  <entry>
    <title><![CDATA[computing chips in AV]]></title>
    <url>%2F2019%2F06%2F23%2Fcomputing-chips-in-AV%2F</url>
    <content type="text"><![CDATA[chips requirements in vehicleBosch : BMW: the next-generation vehicle EE platform can be easily modulized based on the topology of network composed by domain controllers and in-vehicle Ethernets. take an example with Singulato iS6, which has five domains: smart driving, powertrain, chassis, smart body, smart seat. each domain need support by a domain controller unit(DCU), the core of which is a powerful computing chip, which is usually more powerful than traditional ECUs. in average, L2 requires computing power about 10TOPS , L3 needs 60TOPS, L4 needs 100TOPS. computing chips product MDC600 Driver PX Pegasus EyeQ 4 BlueBox R-car H3 Journey2.0 Huawei Nvidia Mobileye NXP Renesas Horizon TOPS 352 320 2.5 10 main cores 8 * 晟腾310 16 ARM VMP LS2084A 4*Arm/A57 BPU2.0 other cores Ascend 310 2 TensorCore GPU S32V234 4*Arm/A53 FPGA AV-level L3+ L5 L3 L4(target) IVI L3 Camera support 16 10 8 8 8 4 Lidar support 8 6 function safety ASIL-D ASIL-B ASIL-D ASIL-D(target) ASIL-B ASIL-B products timelineTier1s/Tier2s timeline 2018 2019 2020 2021 Aptive level3 level4 Bosch level2 level3 level4 Conti level2 level3+ Autoliv level2 level3 level4 Intel level3 level4+ Nvidia level3 level4+ Chinese OEMs timeline 2019 2020 2021 2022+ changan level4 FAW level4 GAC level3 level5 Geely level3 level5 GWM level3 level4 SAIC level3 xiaoPeng level3 WeiMa level3 Nio level2 level4+ global OEMs timeline 2018 2019 2020 2021 2022+ Ford level2 level4 GM level2 level4 Fiat-Crysler level3+ Audi level2 level4 Mercedze level2 level3 level4 Toyota level2 level3 level4 Honda level3 level4 referenceMatrix 1.0 the five chip vendors from GPU to ASIC hauwei and the others global chips vendors L4 AI chips the evolution of EyeQ Mobileye tech NXP bluebox R-car H3 soc NXP function safety horizontal AI matrix2.0 cars, mobility, chip-to-city design and the Iphone4 2018-2019 汽车域控制器产业研究报告 汽车电子演化 Global L3 self-driving vehicle market insights 2019 self-driving car research report]]></content>
  </entry>
  <entry>
    <title><![CDATA[Lidar in AV]]></title>
    <url>%2F2019%2F06%2F22%2FLidar-in-AV%2F</url>
    <content type="text"><![CDATA[science, religion, music, universe as well as other sources of beauty, are what we humans should look for. – zj operational theorya pulse of light is emitted and the precise time is recorded. the reflection of that pulse is detected and the precise time is recorded. using the constant speed of light and the delay can convert into distance, with the known position and orientation of the sensor, the xyz position of the reflective surface can be calculated. components laser scanner/emitter and laser detector high-precision clock GPS and GPS ground station record xyz of the scanner IMU record angular orientation of the scanner field of view(FOV)azimuth with fixed vertical angle resolution, the neighboring laser emmiter-detector pair will create concentric circle, the distance between two neighboring concentric circle will grow with the distance from detected objects to Lidar. light source950nm wavelength producer is Si-based, which makes it cheaper than 1550nm, the InGaAs based, making it safer to human eyes as 950nm can burn retina and powerful. 1550nm is easier to be absorbed by water than 950nm, which makes it performance better in rainy days. the laser source emiss lines of pulse every frame, and a few photon return back to Photodetector(光电探测器), there are lots of env photons(noise), we can use narrow-band-filter to tick off some env photons, but not all of them, since the solar radiation is in the range from 905nm 50 1550nm. solid-statethere are two ways ongoing: MEMS based, phased array tech(相位阵列）. MEMS tech is using a micro scaning mirror, either rotate or vibrate to control laser direction. the drawback of micro-mirror is the in the process of relection, lots of laser energy is lost. phased array tech(Quanergy) integerated multi micro laser emission into one socket to control laser direction. and the drawback at this moment is the short detection distance. the traditional mechanical design Lidar(Velodye) usually has multi light emitters as well as multi corresponded light detectors. while SS-Lidar depends only on one single light emitter and the scanning mirror to control emission direction, which makes it cheaper. for example, each pair of mechanical emitter-detector cost 200 us dollar, so a 64 lines product will cost about 12800 us dollar, compared to MEMS socket about 200 us dollar each. detection distance(dd) &amp; angle resolution(ar)detection distacne with 10 % reflectivity vertical angle range(var) vertical angle resolution(va_res) company product dd(m) var va_res channels Hesai Pandar40 200 23&deg; 0.33&deg; 40 Robo sense RS-Lidar-32 200 40&deg; 0.33&deg; 32 Velodyne HDL-32e 100 41.3&deg; 32 Quanergy M8 150 20&deg; 32 Ibeo NSH_32 80 16&deg; 0.2&deg; 32 InnoVusion Cheetah 200 40&deg; 0.13&deg; 300 env effectswhat about weather effects? e.g. snow, dust, rain; what about env effects? e.g. temperature, system vibration. fusion with camerathe speed of productivizationwhen I first heard about InnoVusion, the founder Bao Junwei who was working at Baidu AI, then had the idea to produce Lidar around 2015, then he left Baidu and started InnoVusion, at the end of 2016, their first product Cheetah was born. this process is really speedy, one thought is the drive force either by capital market or industry needs is becoming so fast that every good chance from idea to product is becoming shorter in time; the other thought, only these highly effective persons will survive in this fast-iteration world. some other founders stories are here : the AI masters who left from Baidu referenceIbeo Next 3D SS-Lidar Innovusion Cheetah Lidar Velodyne HDL_32e product manual]]></content>
  </entry>
  <entry>
    <title><![CDATA[principles of GNSS positioning]]></title>
    <url>%2F2019%2F06%2F17%2Fprinciples-of-GNSS-positioning%2F</url>
    <content type="text"><![CDATA[novatel introduction GNSS architecturea) space segment the GNSS satellites, each of which broadcasts a signal that identifies ti and provides its time, orbit and status. b) control segment a ground-based network of master control stations, data uploading stations adn monitor stations. in case of GPS, 2 master control stations(one primary and one backup), 4 data uploading stations, and 16 monitor stations c) user segment the user equipment that process the received signals. GNSS propagationthe layer of atmoshpere that most influcences the transmission of GPS signals is the ionosphere(电离层), ionoshperic delays are frequency dependent; and the other layer is troposphere(平流层), whose delay is a function of local temperature, pressure and relative humidity. some singal energy is reflected on the way to the receiver, called “multipath propagation”. Antennaeach GNSS constellation has its own signal frequencies and bandwidths, an antenan must cover the signal frequencies and bandwidth. antenna gain is defined as the relative measure of an antenna’s ability to direct or concentrate radio frequency energy in a particular direction or pattern. A minimum gain is required to achieve a minimum carrier : power-noise-ratio to track GNSS satellites. GNSS error sourcescontributing sources error range satellite clocks +- 2m orbit errors +-2.5m inospheric delays +-5m tropospheric delays +-0.5m receiver noies +-0.3m multi path +-1m Resolving errorsmulti-constellation &amp; multi-frequencymulti-frequency is the most effective way to remove ionospheric error, by comparing the delays of two GNSS signals, L1 &amp; L2, the receiver can correct for the impact of ionospheric errors. multi-constellation has benefits: reduce signal acquisition time, improve position and time accuracy. D-GNSSin differential GNSS(D-GNSS), the position of a fixed GNSS receiver, refered as a base station, which sends the atmospheric delay related errors to receivers, which incorporate the corrections into their positoin calculations. differential positiong requires a data link betwen the base station and rovers, if corrections need to be applied in real-time. and D-GNSS works very well with base station-to-rover separations of up to 10km. Real time kinematic(RTK)it uses measurements of the phase of the signal’s carrier wave, in addition to the information content of the signal and relies on a single fixed reference station to provide real-time corrections, up to centimetre-level accuracy. the range to a satellite is calculated by multiplying the carrier wavelength times the number of whole cycles between the satellite and the rover and adding the phase difference. the results in an error equal to the error in the estimated number of cycles times the wavelength, so-called integer ambiguity search, which is 19cm for L1 signal. Precise Point Positioning(PPP)PPP solution depends on GNSS satellite clock and orbit corrections, generated from a network of global reference stations. GNSS + IMUthe external reference can quite effectively be provided by GNSS, and GNSS provides an absolute set of coordinates that can be used as the initial start point, as well, GNSS provides continuous positions adn velocities thereafter which are used to update the IMU/INS filter estimates. for additional combined sensors, such as odometers, cameras vision. challenges of GNSS in AVtalk from iMorpheus.ai 1) antenna 2) multipath mitigation 3) multi-band, multi-constellation signals 4) integrated navigation (camera )]]></content>
  </entry>
  <entry>
    <title><![CDATA[Manhanton SC review]]></title>
    <url>%2F2019%2F06%2F12%2FManhanton-SC-review%2F</url>
    <content type="text"><![CDATA[conjunctionsthe seven conjunctions can used to connect two independent clauses: For, And, Nor, But, Or, Yet, So comma only cant connect two sentences; but can connect two independent clauses using a semicolon(;) semicolon is often followed by a transition expression, (however, therefore, in addition), but these expression are not conjunctions, so must use semicolons, not commas to join. noun modifiersin the format: prepositon, part participle, presetn participle without commas. put the noun and its modifier as close together as possible “ comma which” is a nonessential modifier relative pronounswhich, cant modify people, who/ whom, must modify people whose, can modify either people or things where, can modify a noun place, can’t modify a metaphorical place, such as situation, case … when, can modify a noun event or time Noun Modifier markersany -ing that are not verbs and not separated from the rest of the sentence by comma will either be a noun, or a modifier of another noun. any “comma -ing” is adverbial modifiers adverbial modifierin the format of: prepositional phrase, present participle with commas , past participle with commas the adverbial modifier must modify a certain verb or clause at a right position, not structurally closer to another verb or clause participle modifierswhen using particples, the information present earlier in the sentence leads to or results in the information presented later in the sentence . subordinatorssubordernate clause provides additional info about the main clause. common subordinatetor markers: although, before, unless, because, that, so that, if, yet, after, while, since, when. and using only one connected word per “connection” . . which vs -ingwhenever using which, must refer to a noun, can’t modify a whole clause. so if need to modify the whole clause, use an adverbial modifier(either -ing, or past) quantitycountable modifiers: many, few, fewer, fewest, number of , numerous uncountable modifiers: much, little, less, least, amount of , great more, enough, all works with both countable and uncountable. parallelismcomparable sentence parts must be structurally and logically similar comparisoncomparison are a subset of parallelism, which requires parallelism between two elements, but also require the two compared items are fundamentally the same type of thing like, unlike, as, than, as adj as, different from, in contrast to/with like vs aslike is used to compare nouns, pronouns or noun phrase, never put a clause or prepositional phrase after like. as can used to compare two clauses.]]></content>
  </entry>
  <entry>
    <title><![CDATA[how simulation helps for autonomous vehicle]]></title>
    <url>%2F2019%2F06%2F06%2Fhow-simulation-helps-for-autonomous-vehicle%2F</url>
    <content type="text"><![CDATA[prefarerecently joined another Chinese auto OEM, still work in simulation platform for autonomous vehicle. this experience is a different pratice from GM or Ford. at first, it’s the mindset update, once for a long time, or even take for granted that I was looking for to be treated greatly, like in NA companies, what the company can offer me. it’s about freedom and responsibility. To have the freedom/right to make a difference in project direction, contents, and methods to achieve sth, first prove that I can take it, which is responsibility. “ you can you up” that kind of phylosphy is very common and actually I’d love it in some point. beta versionthere are ways to make a virtual simulator. traditional tool vendors include Matlab/Simulink, Prescan, VTD, ANSYS e.t.c. and as the beta version of simulator tool-chain, they are common in most OEMs in China. while have to say, in China, cause most software tools, from engineering tools to modern HR managment tools to product managment tools are kind of in practice process in Chinese companies as I can see, rather than as a matured segment pluged-in the company’s DNA. e.g. the product development tools are pretty in trial and error, occasionaly some PLM vendors come to introduce their products. and actually except the CAD/CAE tools, which were introduced in China since 80’s, and which sounds matured right now, the simulation tools for autonomous vehicle is pretty new-things, from map, sensor to all kinds of internal algorithms. the beta version of simulation tools has its DNAs as well. first they are charged by license fee, which is a pretty old way like IBM days. not many modern Internet mobility companies live in this way anymore. secondly, they can’t update frequently, once or twice a year with a new version of the product is common, which maybe OK in CAD/CAE tools, since the engineering analysis process are pretty matured and few exceptional requirements jump out in daily work, and there update is sometime by the vendor itself, which is not a required update, maybe optimized the algorithms, maybe added a third-party function, and sometime is from the users conference, usually the tool vendor will organize this kind of user conference to group users together, one way to get some connections, as well as to get some end-user requirements to fix the next version product, which is also a drawback compared to open source tool community, in where the user is more active. thirdly, the beta version tools are excluding the users someway, who can’t actually manage the tool as part of its whole functions. assuming simulation will be the key to make a difference in future auto product, then this excluding is unacceptable. on the other side, if autonomous simulation tool are at most aided to develop new product, then it becomes a piece of chicken neck either to take or to throw. from a product view, what is the role of simulation tool or as a product itself, where it is blooming point alpha versionwhy simulation tool become a role in autonomous, except the traditional vendors, mostly coming from Internet companies, e.g. Google, Uber, Baidu, Tecent etc. they are pretty strong to make a software product, including the simulation software in auto industry. interesting, these Internet companines never go to make a CAD/CAE software, but they actually prefer to support the cloud/HPC infrastructures for CAD/CAE simulation. these big mobility companines make their simulation tools now and well cowork with their existing IT development methodlogy, software product ideas as well as all ICT infrastures, which make these tools sounds huge great, and which also make themselves as the core role, rather than the OEMs, few are free or not yet open-sourced. and there are a few popular open source simulation tools, e.g. Carla, Airsim, LG simulator e.t.c. I actually get a chance with Carla at GM research team, which even now still great, but does’t study deeper, and for me it is a great tool for AI training, which should be the key role of simulation tool in future, since L3 or below, really cares little environment info, and its rule-based decision has no need for a large chunk of virtual test. that’s also a difference between Chinese and NA team, NA teams have the trend to invest in new tech even without immeditaly money back, but Chinese companies would prefer in immediate invest. lg simulatorUnreal never tried, but Unity looks pretty easy to use, while still need sometime to get familiar with the editor and play with scenes. lg simulator has give a great reference to build the virtual city and make autonomous vehicles running. the real problem actually for most team is how to make this tool useful in product development. we can think about the tool strucutre itself, like cloud running features, implement measure/verified methods, and build scenes database as we can think about or from the sort of system engineering port. as for a L3 or below usage, the whole meaning of simualtion is not driven, but at most additional support of product development, as I can see. so what simulation for ? L4+, which leads to AI, or data driven product development! from this point, the simlation itself is not the core, but the AI, so think about that in career development.]]></content>
      <tags>
        <tag>simulation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[robust control theory]]></title>
    <url>%2F2019%2F05%2F10%2Frobust-control-theory%2F</url>
    <content type="text"><![CDATA[this is a review from cmu refer state variable methodany Nth order differential equation describing a control system could be reduced to N 1st order equations, these equations could be arranged in the form of matrix equations. define x as system state, y as output, u as input: modern control methods(ODEs) can handle multiple-input-multiple-outputs, and they can be optimized, and they allow to design performance and cost model. effects of uncertaintyobservabilitythe ability to observe all of the parameters or state variables in the system controllabilitythe ability to move a system from any given state to any desired state stabilitythe bounded response to any bounded input robust control theory might be stated as a worst-case analysis, to bound the uncertantiy. metircshow to model the behavior of the test system is one most difficult challenge in design a good control system. adaptive controlset up observers for each significant state variable. at each iteration loop, the system learns about the changes in the system parameters, and getting closer to the desired. while the method may suffer from convergence issues H2 or H-infinityH2 control seeks to bound the power gain of the system, H-infinity seeks to bound the energy gain of the system. gains in power or energy indicate operation of the system near a pole in the transfer function. parameter estimationby establishing boundaries in the frequency domain that cannot be crossed to maintain stability. Lyapanovthe only universal tech for assessing non-linear systems, the method focus on stability. Lyapanov functions are constructed, which are described as energy-like functions, to model the behavior of real system.]]></content>
      <tags>
        <tag>control</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Carmaker 8.0]]></title>
    <url>%2F2019%2F05%2F10%2FCarmaker-8-0%2F</url>
    <content type="text"><![CDATA[this is from IPG open house Shang Hai scenario generation taskdata recordtracking vehicles, roads, tobstacles obj: lane, road, barries, GPS input, vehicle position/orientation, fixed ID, type the goal of recoding is for road building, which will be used in replay. road buildGPS input + lane mark info + vehicle location –&gt; vehicle trajectory replayrun config, input as tranversal and longitudial position traffic vehicle location, speed rearrangeinput as : traffic vehile info + ego info , list of traffic vehicle info traffic vehicle manage: 1) manuevor control: free move 2) spawn control: lati + longi --&gt; 23 cases 3) support external plugins + manuevor trigger Synthetic Scenariojunction assistant road type + traffic rules + scenario –&gt; support road topology modification support different envs: day of time, weather, scenario editor to support opendrive import standardizationPEGASUS + ASAM simulation standards roads, scenarios, simulation interfaces Opendrive –&gt; road topology opENScenario –&gt; maneuver &amp; anction abstract definitions Open simulation interface –&gt; interface developed for PEGASUS limitationspre-define route for vehicle ? the ego car has AI maneuvor ? Vitual Prototypeincluding gearbox loss mode, gas mode, through look-up table including hybrid powertrain architectures: automatic gearbox + parallel hybrid including powertrain masses(engine, tank, gearbox, battery, motor) including trailer data set generator including damping top mount Simulation testsupport:: ADAS/AD, POWERTRAIN, Vehicle Dynamics steering system visual casefor less steering will overall comfort and vehicle dynamics reference measurements(steering-in-loop simulator) -&gt; model parameter id + softare + ECU integration –&gt; parameterization &amp; validation -&gt; training how the steering system worksopen loop to get mechanical characteristics(stiffness, friction..) system performance with or without EPS 1) ideal(basis) model vs physical model how to cowok the physical model with autopilot control model ? test bedto support electrification, durability, balancing, driveability, powertain caillbratio, connected powertrain AI training with synthetic scenariodecion making trajectory planning image perception q: how to make sure AI robost ? –&gt; what CarMaker can do for AI? 1) obj annotation (vehicles, pedestrains) –&gt; auto annotation 2) semantic segmentation e.g. IPG Movier for auto semantic segmentation Q: what’s the hardware for ? Cloud &amp; CPU/GPU for Parallelizationq: how to parallel in docker ? 1) test case in each CPUs 2) even for single test run(with multi sensors, multi cars ) resources &amp; distribution CPU: vehile model, drivel model, envs, ideal sensors GPU; visual, camera RIS, radar ris, lidar rs Test run in prallelsensor setup(10 ultra, 5 Radar, 1 Lidar, 1 Camera) host pc (with test manager) + 4 virtual machines output: key figures, reports, statistics, queries open archi for scalable processing( on-premise and cloud) big data anaysis with DaSense by NorCom how it works ? external scheduler mananger, PBS HPC light to support local PC parallel new features in 8.0virtual test driving 8.0 simulink lib (through Simscape) Scenario Editor: vege geenration, animated 3D objs, new models(vehicles, trailers, trucks, bus, buildings, houses, street furniture, pedestrains) visulize road surfaces .. ipg movie fisheye distortion from external file new sensor models(Lidar RSI) q: what’s the difference of open source tool vs commericial ? Lidar RSIIdeal perfect world –&gt; ground truth HiFi –&gt; false positives &amp; negatives raw data –&gt; RSI supporting Lidar type: moving laser &amp; photot diode moving mirrors solid state flash input features : Laser beam, including custom beam pattern, Raytracing rays Scene Interaction, including atmoshpere attenuation, color or material or surface or transparent dependency detection, including threashold, multiple echoes per beam, separability output features: sending &amp; receiving direction of every beam light intensity of every beam time &amp; lenght of light pluse width number of interactions User Case : Nio Pilotby sun peng casesinter-city, parking, closed space, crowded space sensors: 3 front camera, 4 surround camera, 4 mm RADARS, 12 Ultra, 1 driver monitor camera higway pilot in June perception: camera, radar, ult, hd map, location planning : path planning, maneuvor decsion, system control cloud &amp; AI simulation usage FDS -&gt; cases -&gt; SIL platform –&gt; cases -&gt; regression test, abstraction &amp; instantiation ; scene reconsturction(in-house) / close loop SIL ; traffic model training(to do) integration -&gt; HIL what about vd ? –&gt; co-work with simulation and physical test, the cover percentage of simulation is about 80%, the left is from data platformupload nodes -&gt; cloud med usa API server -&gt; fleet mgmt log stash –&gt; elastic search –&gt; Kibana &amp; Admin (tensn and spark ) I think they are collecting data, and this data for scene building and simulation usage in future data visulazationHIL lane model simualtion on HIL fusion simulation on HIL automation testjenkins master –&gt; jenkins slave (agent IPG) –&gt; cloud goalsimulation server &lt;—&gt; data center parallel sim core + simulation monitor (data exchange service) data processing + labelling + case management + traffic model training (replay, SIL, REMODEL, Visuliazation )]]></content>
      <tags>
        <tag>simulation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PID control]]></title>
    <url>%2F2019%2F05%2F04%2FPID-control%2F</url>
    <content type="text"><![CDATA[closed loop systemset point is the desired or command value for the process variable. at any given moment, the difference between the process variable and the set point is used by the control system algorithm to determine the desired actuator output to drive the system. closed loop system, the process of reading sensors to provide constant feedback and calculating the desired actuator output is repeated continuously and at a fixed loop rate. control system performance is measured by applying a step fuction as the set point command variable, and then measuring the response of the process variable. rise time is the amount of time that the system takes to go from 10% to 90% of the steady-state/final. percent overshoot is the amout that the process variable overshoots the final value, expressed as a percentage of the final value. settling time is the time required for the process variable to settle to within a certain percentage(5%) of the finla value steady state error is the final difference between the process variable and set point disturbance rejection is the measure of how well the control system is able to overcome the effects of disturbances. often there is a disturbance in the system that affects the process variables or the measurements of these variables, it’s important to design a control system that performs satisfactorily during the worst case conditions. nonlinear system , in which the control parameters that produe a desired response at one operating point might not produce a satisfactory response at another operating point. deadtime is the delay between when a process variable changes, and when that change can be observed. loop cycle the interval of time between calls to a control system, system that change quickly or have complex behavior requires faster control loop rates. PID theoryproportional responseerror the difference between the set point and the process variable. the proportional gain(K_g) determins the ratio of the output response to the error signal. e.g. the error term has a magnitude of 10, and the K_g is 5, then the proportional response is 50. increasing K_g will increase the speed of the control system response, but if K_g is too large, the process variable will oscillate(why?) integral responsethe integral component sums the error term over time. the result is that even a small error term will cause the integral component to increase slowly. the integral response will continually increase unless the error is zero, so the effect is to driven the steady-state-zero to zero. integral windup when integral action saturates, still without the controller driving the error signal toward zero derivative responsethe response is portortional to the rate of change of the process variable. increasing the derivative time will cause the control sytem to react more strongly to changes in the error, and react more quickly. in practice, most control system use very small derivative time, since the derivative response is highly sensitive to noise. turningwhich is the process of setting the optimal gains of P, I, D to get an ideal response. trial and errorset I, D as zero, and increas P gain. Once P has been set to obtain a desired fast response, I starts to increase to stop the oscillatins to achieve a minimal steady state error. once P and I have been set, the D is increased untill the loop is acceptably quick to its set point. filteringassume a sinusoidla noise with frequency w, the direvative is: so in practice it’s necessary to limit the high frequency gain of the derivative term, either by adding a low pass filtering of the control signal, or implement the derivative term in a cut-off way. Udacity Self driving Car project 9 int main() { uWS::Hub h ; PID pid ; pid.Init(pinit, iinit, dinit); h.onMessage( // cte, the error { double diff = fabs(pid.p_error - cte) ; if( diff &gt; 0.1 &amp;&amp; diff &lt; 0.2) thr = 0.0; else if( diff &gt; 0.2 &amp;&amp; speed &gt; 30) thr = -0.2; pid.UpdateError(cte, dt); steer_value = -pid.TotalError(speed); } } void PID::UpdateError(double cte, double dt) { d_error = (cte - p_error) /dt ; p_error = cte ; i_error = integral(cte * dt); } double PID::TotalError(double speed) { return (Kp - 0.0032 * speed) * p_error + Ki * i_error + (Kd + 0.002 * speed) * d_error ; } in real self driving control system, usually divide as latitual and longitual control. and in different scenarios, there are plenty of PID controls. in the future will expose: highway autopilot, auto parking, urban L4 referencePID theory explained PID control from Caltech udacity pid control]]></content>
      <tags>
        <tag>control</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apollo 2.0 Localization 源码]]></title>
    <url>%2F2019%2F05%2F03%2FApollo-2-0-Localization-%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[there are two localization methods: RTK and multi-sensor fusion(MSF). RTK using GPS and IMU inputs, MSF using GPS, IMU and Lidar sensor and HD map as inputs. the output is the localization estimated object instance. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657Status Localization::Start()&#123; localization_ = localization_factory_.CreateObject(cofig_.type()); localization_-&gt;Start(); return Status::OK();&#125;Status RTKLocalization::Start()&#123; AdapterManager::Init(FLAGS_rtk_adapter_config_file); timer_ = AdapterManager::CreateTimer(ros::Duration(duration), &amp;RTKLocalization::OnTimer, this); AdapterManager::GetGps(); AdapterManager::GetImu(); tf2_broadcaster_ = new tf2_ros::TransformBroadcaster() ; return Status::OK();&#125;void RTKLocalization::OnTimer(const ros::TimerEvent &amp;event)&#123; AdapterManager::Observe(); PublishLocalization(); RunWatchDog(); &#125;void RTKLocalization::PublishLocalization()&#123; LocalizationEstimate localization ; PrepareLocalizationMsg(&amp;localization); AdapterManager::PublishLocalization(localization); PublishPoseBroadcastTF(localization);&#125;void RTKLocalization::PrepareLocalizationMsg(LocalizationEstimate *localization)&#123; const auto &amp;gps_msg = AdapterManager::GetGps()-&gt;GetLatestObserved(); Imu imu_msg = AdapterManager::GetImu()-&gt;GetLatestObserved(); ComposeLocalizationMsg(gps_msg, imu_msg, localization);&#125;void RTKLocalization::ComposeLocalizationMsg(const localization::Gps&amp; gps_msg, const localization::Imu &amp;img_msg, LocalizationEstimate* localization)&#123; // add header // set measurement time // combine gps and imu auto mutable_pose = localization-&gt;mutable_pose(); if(gps_msg.has_localization())&#123; const auto &amp;pose = gps_msg.localization(); if(pose.has_position())&#123; // update mutable_pose &#125;; if(pose.has_orientation()) &#123; //update mutable orientation &#125;; if(pose.has_linear_velocity())&#123;&#125;; &#125; if(imu.has_linear_acceleration())&#123; //update mutable_pose acc &#125;; if(imu.has_angular_velocity())&#123;&#125;; if(imu.has_euler_angles())&#123;&#125;;&#125; MSFvehicle localization based on multi-sensor fusion 12345678910111213141516171819202122232425class MSFLocalization &#123; void InitParams(); void OnPointCloud(const sensor_msgs::PointCloud2 &amp;message); void OnRawImu(const drivers::gnss::Imu &amp;imu_msg); void OnGnssRtkObs(const EpochObservation &amp;raw_obs_msg); // ... void PublishPoseBroadcastTF(const LocalizationEstimate&amp; localization);&#125;Status MSFLocalization::Start()&#123; AdapterManager::Init(FLAGS_msf_adapter_config_file); Status &amp;&amp;status = Init(); AdapterManager::GetRawImu(); AdapterManager::ADDRawImuCallback(&amp;MSFLocalization::OnRawImu, this); AdapterManager::GetPointCloud(); AdapterManager::AddPointCloudCallback(&amp;MSFLocalization::OnPointCloud, this); // ... return Status::OK();&#125; there is addtional local_map module, which will be review later.]]></content>
      <tags>
        <tag>apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apollo 2.0 Prediction源码]]></title>
    <url>%2F2019%2F05%2F03%2FApollo-2-0-Prediction%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Predictionprediction inputs are: obstacles from perception module nad localization from localization module. outputs are obstacles will predicted trajectories. there are three classes in prediction modules: * container store input dat from subscribed channelds, e.g. perception obstacles, vehicle localization * evalutor predicts paths and speed separately for any given obstacles * predictor generate predicted trajectories for obstacles. e.g. lane sequence(obstacle moves following the lanes), free movement, regional moves(move in a possbile region) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 模块入口APOLLO_MAIN(apollo::prediction::Prediction);Status Prediction::Init()&#123; predicition_conf_.Clear(); adapter_conf_.Clear();common::util::GetProtoFromFile(FLAGS_prediction_adapter_config_filename, &amp;adapter_conf_); //Initial managers AdapterManager::Init(adapter_conf_); ContainerManager::instance()-&gt;Init(adapter_conf_); EvaluatorManager::instance()-&gt;Init(prediction_conf_); PredictorManager::instance()-&gt;Init(prediction_conf_); AdapterManager::GetLocalization(); AdapterManager::GetPerceptionObstacles(); AdapterManger::AddPerceptionObstaclesCallback(&amp;Prediction::RunOnce, this); AdapterManger::AddLocalizationCallback(&amp;Prediction::OnLocalization, this);AdapterManger::AddPlanningCallback(&amp;Prediction::OnPlanning, this); return Status::OK();&#125;void Prediction::RunOnce(const PerceptionObstacles&amp; perception_obstacles)&#123; ObstaclesContainer* obstacles_container = dynamic_cast&lt;ObstaclesContainer*&gt;(ContainerManager::instance()-&gt;GetContainer(AdapterConfig::PERCEPTION_OBSTACLES)); obstacles_container-&gt;Insert(perception_obstacles); EvaluatorManager::instace()-&gt;Run(perception_obstacles); PredictorManager::instance()-&gt;Run(perception_obstacles); auto prediction_obstacles = PredictorManager::instance()-&gt;prediction_obstacles(); for(auto const&amp; prediction_obstacle : prediction_obstacles.prediction_obstalces())&#123; for(auto const&amp; trajectory:prediction_obstacle.trajectory()) &#123; for(auto const&amp; trajectory_point : trajectory.trajectory_point()) &#123; if(!IsValidTrajectoryPoint(trajectory_point))&#123; return ; &#125; &#125; &#125; Publish(&amp;prediction_obstacles); &#125;void Prediction::OnLocalization(const LocalizationEstimate&amp; localization, ObstaclesContainer* obstacles_container)void Prediction::OnPlanning(const planning::ADCTrajectory&amp; adc_trajectory, ADCTrajectoryContainer* adc_trajectory_container) Prediction interface has defined: RunOnce() and Pulish(). the Prediction class has defined listener’s callback: OnLocalization, OnPlanning, and Start(), Stop() and implemented interface functions. For both EvaluatorManager and PredictorManager, there are Init() and Run() functions, and there are bunch of apis from container class. Evaluator1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859void EvaluatorManager::Init(const PredictionConf&amp; config)&#123; //... switch(config.obstacle_type())&#123; case PerceptionObstacle::VEHICLE :&#123; vehicle_on_lane_evaluator_ = obstalce_conf.evaluator_type(); break; case PerceptionObstacle::BICYCLE:&#123; cyclist_on_lane_evaluator_ = obstlce_conf.evluator_type(); break; case PerceptionObstacle::PEDESTRAIN:&#123; break; &#125; case PerceptionObstacle::UNKNOWN:&#123; default_on_lane_evaluator_ = obstacle_conf.evalutor_type(); break; &#125; &#125;&#125;Evaluator* EvaluatorManager::Run(const perception::PerceptionObstacles&amp; perception_obstacles)&#123; ObstaclesContainer* container = dynamic_cast&lt;ObstaclesContainer*&gt;(); Evaluator* evaluator = nullptr ; for(const auto&amp; perception_obstacle : perception_obstacles.perception_obstalce()) &#123; int id = perception_obstalce.id(); Obstacle* obstacle = container-&gt;GetObstalce(id); switch(perception_obstalce.type()) &#123; case PerceptionObstacle::VEHICLE: &#123; if(obstacle-&gt;IsOnLane())&#123; evaluator = GetEvaluator(vehicle_on_lane_evaluator_); &#125; break; &#125; case PerceptionObstacle::BICYCLE:&#123; if(obstacle-&gt;IsOnLane())&#123; evaluator = GetEvaluator(cyclist_on_lane_evaluator_); &#125; break; &#125; // ... if(evaluator != nullptr) &#123; evaluator-&gt;Evaluate(obstacle); &#125; &#125; &#125;&#125; and there are a few different evaluators: (multilayer perception approach) MLP and RNN(deep neural network), both will discuss in details in future. Predictorpredictor will generate trajectories, a few apis: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172virtual void predictor::Predict(Obstacle* obstacle) = 0;void predictor::TrimTrajectories(const Obstacle, const ADCTrajectoryContainer* );static predictor::Trajectory GenerateTrajectory(const std::vector&lt;apollo::common::TrajectoryPoint&gt;&amp; points) ;void PredictorManager::Init(const PredictionConf&amp; config)&#123; // ... switch(obstacle_conf.obstacle_type()) &#123; case PerceptionObstacle::VEHICLE: &#123; if(obstacle_conf.obstacle_status() == ObstacleConfg::ON_LANE)&#123; vehicle_on_lane_predictor_ = obstacle_conf.predictor_type(); &#125;else if(obstacle_conf.obstacle_status() == ObstacleConf::OFF_LANE)&#123; vehicle_off_lane_predictor_ = obstacle_conf.predictor_type(); &#125; &#125; break; // ... &#125; void PredictorManager::Run(const PerceptionObstacles&amp; perception_obstacles)&#123; ObstaclesContainer* obstacles_container = dynamic_cast&lt;ObstaclesContainer*&gt;(AdapterConfig::PERCEPTION_OBSTACLES) ; ADCTrajectoryContainer *adc_trajectory_container = dynamic_cast&lt;ADCTrajectoryContainer*&gt;(AdapterConfig::PLANNING_TRAJECTORY); Predictor* predictor = nullptr ; for(const auto* perception_obstacle : perception_obstacles.perception_obstacle()) &#123; int id = perception_obstacle.id(); PredictionObstacle prediction_obstacle ; Obstacle* obstacle = obstacle_container-&gt;GetObstacle(id); if(obstacle != nullptr) &#123; switch(perception_obstacle.type()) &#123; case PerceptionObstacle::VEHICLE: &#123; if(obstacle-&gt;IsOnLane())&#123; predictor = GetPredictor(vehicle_on_lane_predictor_); &#125;else&#123; predictor = GetPredictor(vehicle_off_lane_predictor_); &#125; break; &#125; // ... &#125; if(predictor != nullptr) &#123; predictor-&gt;Predict(obstacle); if(obstacle-&gt;type() == PerceptionObstacle::VEHICLE)&#123; predictor-&gt;TrimTrajectories(obstacle, adc_trajectory_container); &#125; for(const auto&amp; trajectory : predictor-&gt;trajectories()) &#123; prediction_obstacle.add_trajectory()-&gt;CopyFrom(trajectory); &#125; &#125; &#125; prediction_obstacle.mutable_perception_obstacle()-&gt;CopyFrom(perception_obstacle); prediction_obstacles_.add_prediction_obstacle()-&gt;CopyFrom(prediction_obstacle); &#125; the predictor has a few types:: regional based, free move, lane sequence e.t.c, which defined as subclasses, will discuss more in future. Containercontainer manager class has a few subclass as adc_trajctory container, obstacles contianer and pose constainer, which should be discussed in details later. Adapter1234567891011121314151617181920212223242526272829// in adapter_manager.cc case AdapterConfig::LOCALIZATION: EnableLocalization(FLAGS_localization_topic, config);case AdatperConfig::PERCEPTION_OBSTACLES: EnablePerceptionObstacles(FLAGS_perception_obstacle_topic, config); // in messsage_adapters.h using PerceptionObstaclesAdapter = Adapter&lt;perception::PerceptionObstacles&gt;; using LocalizationAdapter = Adapter&lt;apollo::localization::LocalizationEstimate&gt;;// in adapter_manager.h static voi Enable##name()&#123; instance()-&gt;InternalEnable##name(topic_name, config);&#125;; static name##Adapter *Get##name()&#123; return instance()-&gt;InternaleGet##name();&#125;static void Add##name##Callback(name##Adapter::Callback callback)&#123; instance()-&gt;name##_-&gt;AddCallback(callback);&#125;template&lt;class T&gt; staic void Add##name##Callback(void(T:: *fp)(const name##Adapter::DataType &amp;data), T* obj)&#123; Add##name##Callback(std::bind(fp, obj, std::placeholders::_1));&#125;]]></content>
      <tags>
        <tag>apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apollo2.0 Control 源码 (3)]]></title>
    <url>%2F2019%2F05%2F01%2FApollo2-0-Control-%E6%BA%90%E7%A0%81-3%2F</url>
    <content type="text"><![CDATA[the input of Apollo control module includes: chassis info, localization info, and planning info ,the output is steering angle, acc, throttle. 12345678910111213141516171819202122232425262728293031323334// 模块入口#define APOLLO_MAIN(APP) int main(int argc, char **argv) &#123; google::InitGoogleLogging(argv[0]); google::ParseCommandLineFlags(&amp;argc, &amp;argv, true); signal(SIGINT, apollo::common::apollo_app_sigint_handler); APP apollo_app_; ros::init(argc, argv, apollo_app_.Name()); apollo_app_.Spin(); //check previous blog(1) return 0; &#125; Status Control::Init()&#123; init_time_ = Clock::NowInSeconds(); common::util::GetProtoFromFile(FLAGS_control_conf_file, &amp;control_conf_); AdapterManager::Init(FLAGS_control_adapter_config_filename); common::monitor::MonitorLogBuffer buffer(&amp;monitor_logger_); controller_agent_.Init(&amp;control_conf_); AdapterManager::GetLocalization(); AdapterManager::GetChassis(); AdapterManager::GetPlanning(); AdpaterManager::GetControlCommand(); AdapterManager::GetMonitor(); AdapterManager::AddMonitorCallback(&amp;Control::OnMonitor, this); return Status::OK();&#125; conf_file: /modules/control/conf/lincoln.pd/txt, which is derieved from /modules/calibration/data/mkz8/calibration_table.pd.txt the topics in control modules are : 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125config &#123; type: LOCALIZATION mode: RECEIVE_ONLY&#125;config &#123; type: PLANNING_TRAJECTORY mode: RECEIVE_ONLY&#125;config &#123; type: CHASSIS mode: RECEIVE_ONLY&#125;config &#123; type: CONTROL_COMMAND mode: PUBLISH_ONLY&#125;config &#123; type: MONITOR mode: DUPLEX&#125; ``` basically, control module will receive topic about /localization, /planning, /chassis, and publish /control_command the controller_agent is an interface class, so can support user defined controller algorithms, which only need to configure through `control_conf` ```cStatus ControllerAgent::Init(const ControlConf* control_conf)&#123; RegisterControllers(control_conf); InitializeConf(control_conf); for(auto &amp;controller : controller_list_) &#123; if(controller == NULL || !controller-&gt;Init(control_conf_).ok()) &#123; return Status(ErrorCode); &#125; &#125; return Status::OK();&#125;void ControllerAgent::RegisterControllers(const ControlConf *control_conf)&#123; for(auto active_controller : control_conf-&gt;active_controllers()) &#123; switch(active_controller)&#123; case ControlConf::MPC_CONTROLLER: controller_factory_.Register( ControlConf::MPC_CONTROLLER, []()-&gt;Controller * &#123;return new MPCController();&#125;); break; //case LAT_CONTROLLER //case LON_CONTROLLER &#125; &#125; &#125; Status Control::Start()&#123; //sleep for advertised channel to ready std::this_thread::sleep_for(std::chrono::millisecons(1000)); timer_ = AdapterManager::CreateTimer(ros::Duration(control_conf_.control_period()), &amp;Control::OnTimer, this); common::monitor::MonitorLogBuffer buffer(&amp;monitor_logger_); return Status::OK(); &#125; void Control::OnTimer(const ros::TimerEvent &amp;) &#123; double start_timestamp = Clock::NowInSeconds(); ControlCommand control_command ; Status status = ProduceControlCommand(&amp;control_command); double end_timestamp = Clock::NowInSeconds(); status.Save(control_command.mutable_header()-&gt;mutable_status()); SendCmd(&amp;control_command); &#125; Status Control::ProduceControlCommand(ControlCommand *control_command) &#123; Status status = CheckInput(); Status status_ts = CheckTimestamp(); Status status_compute = controller_agent_.ComputeControlCommand( &amp;localization_, &amp;chassis_, &amp;trajectory_, control_command); return status; &#125; Status ControllerAgent::ComputeControlCommand( const localization::LocalizationEstimate *localization, cosnt canbus::Chassis *chassis, const planning::ADCTrajectory *trajectory, control::ControlCommand *cmd)&#123; for(auto &amp;controller : controller_list_) &#123; controller-&gt;ComputeControlCommand(localization, chassis, trajectory, cmd) ; &#125; return status::OK(); &#125; ControllerAgent::ComputeCmd() is the interface, the real control cmd will be computed inside each specified controller modes. there are few controller modes: MPC, Lattice e.g in Apollo. in next few days continue work on localization, prediction, and decision modules in Apollo 2.0]]></content>
      <tags>
        <tag>apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apollo2.0 Routing源码(2)]]></title>
    <url>%2F2019%2F05%2F01%2FApollo2-0-Routing%E6%BA%90%E7%A0%81-2%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364// 模块入口APOLLO_MAIN(apollo::routing::Routing) int main(int argc, char** argv)&#123; google::InitGoogleLogging(arg[0]) ; google::ParseCommandLineFlags(&amp;argc, &amp;argv, true); signal(SIGINT, apollo::common::apollo_app_sigint_handler); apollo::routing::Routing apollo_app_ ; ros::init(argc, argv, apollo_app_.Name()); apollo_app_.Spin(); return 0;&#125;``` `appollo_app_.Spin()` can be found [here](https://zjli2013.github.io/2019/04/28/apollo-planning-源码/)```c apollo::common:Status Routing::Init()&#123; const auto routing_map_file = apollo::hdmap::RoutingMapFile() ; navigator_ptr_.reset(new Navigator(routing_map_file)) ; common::util::GetProtoFromFile(FLAGS_routing_conf_file, &amp;routing_conf_); hdmap_ = apollo::hdmap::HDMapUtil::BaseMapPtr(); AdapterManager::Init(FLAGS_routing_adapter_config_filename); AdapterManager::AddRoutingRequestCallback(&amp;Routing::OnRoutingRequest, this); return apollo::common::Status::OK();&#125;/* DEFINE_string(routing_adapter_config_filename, "modules/routing/conf/adapter.conf", "the adapter config filename")*/void AdapterManager::Init()&#123; //... for(const auto &amp;config :: configs.config()) &#123; case AdapterConfig::ROUTING_REQUEST : EnableRoutingRequest(FLAGS_routing_request_topic, config); break; case AdapterConfig::ROUTING_RESPONSE: EnableRoutingResponse(FLAGS_routing_response_topic, config); break; case AdapterConfig::ROUTING_MONITOR: EnableMonitor(FLAGS_monitor_topic, config); break; //... &#125;&#125; where define EnableRoutingRequest() ? 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//apollo/modules/common/adapters/adapter_manager.h #define REGISTER_ADAPTER(name) static void Enable##name(const std::string &amp;topic_name, const AdapterConfig &amp;config) &#123; instance()-&gt;InternalEnable##name(topic_name, config); &#125; template&lt;class T&gt; static void Add##name##Callback( void(T::*fp)(const name##Adapter::DataType &amp;data), T *obj)&#123; Add##name##Callback(std::bind(fp, obj, std::placeholders::_1)); &#125; tempalate&lt;class T&gt; static void Add##name##Callback(void (T::*fp)(const name##Adapter::DataType &amp;data))&#123; Add##name##Callback(fp); &#125; // apollo/modules/common/adapters/message_adapters.husing RoutingRequestAdapter = Adapter&lt;routing::RoutingRequest&gt; ;using RoutingResponseAdapter = Adapter&lt;routing::RoutingResponse&gt;;// apollo/moduels/common/adapters/adapter.h typedef typename std::function&lt;void(const D&amp;)&gt; Callback ;// apollo/modules/common/adapters/adapter.h template &lt;class D&gt; void Adapter&lt;D&gt;:OnReceive(const D&amp; message)&#123; last_receive_time_ = apollo::common::time::Clock::NowInSeconds(); EnqueueData(message); FireCallbacks(message);&#125;void AddCallback(Callback callback)&#123; receive_callbacks_.push_back(callback);&#125;tempplate&lt;class D&gt; void Adapter&lt;D&gt;::FireCallbacks(const D&amp; data)&#123; for(const auto&amp; callback : receive_callbacks_) &#123; callback(data); &#125;&#125; Dreamview and Planning modules have message publish API. e.g. 1234567891011121314151617SimulationWorldUpdater::(WebSocketHandler *websocket, SimControl *sim_control, const MapSerivce *map_service, bool routing_from_file) : sim_world_service_(map_service, routing_from_file), map_service_(map_service), websocket_(websocket),sim_control_(sim_control)&#123; // ... websocket_-&gt;RegisterMessageHandler("SendRoutingRequest", [this][cosnt Json &amp;json, WebSocketHandler::Connection *conn) &#123; RoutingRequest routing_request, bool succed = ConstructRoutingRequest(json, &amp;routing_request); if(succed)&#123; AdapterManager::FillRoutingRequestHeader(FLAGS_dreamview_module_name, &amp;routing_request); AdapterManager::PublishRoutingRequest(routing_request); &#125; &#125; ApapterManager class is used to make sure the connection among each module in ROS message type. Routing class has GPS and IMU input and generate routing and velocity info as output. Navigator class is using A start algorthm with hd map, start point and end point as input to generate a navigation route.]]></content>
      <tags>
        <tag>apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未来5年在哪里(7)]]></title>
    <url>%2F2019%2F04%2F30%2F%E6%9C%AA%E6%9D%A55%E5%B9%B4%E5%9C%A8%E5%93%AA%E9%87%8C-7%2F</url>
    <content type="text"><![CDATA[噱头团队必须在有危机意识的企业中成长。靠投资活的团队，往往只展现其繁荣的一面，对内对外；而实际公司的产品、市场定位，甚至内部员工都不知情。对员工缺乏诚实，对市场客户也不会诚实。 民企文化近距离观察了一家民企（长城汽车），意识到民企都不容易迈过国际化的坎儿。为什么需要国际化？因为资本市场是赢者通吃。行业内国际企业进入，本土行业要想生存，必须主动走出去。 民企的老总个人印记太深。集权的管理问题，符合中国文化传统，但与现代管理理念相差甚远。强调军事化管理的集体制，是无法调动个人主观积极性的，对于底层车间工人可能有效，但如此又会造成企业管理上的双轨制，产生内部紧张。另外，集体制会助长一些骄横的个人气息，狭隘自大，而不利于个人内在品质的培养。一个代表先进生产关系和生产力的团队，是不会容忍形式主义的。 国内不错的企业要么狼性，要么艰苦奋斗。其实鼓励创业氛围没有问题，但是文化上很容易“右倾”，把规则理解的太死。 另外强调艰苦奋斗又不集权的华为，给员工持股，也许才是现代优秀企业该有的特征。把员工当作“合伙人“，自然调动了员工的积极性，而不是为某个老板打工。 回国前的想法是参与一个团队的成长，而不是在一家公司打工。所以除了物质利益，现在人更渴求在工作中的身份认同：”合伙人“。 套路国内的套路：先放话。 改革开放前，国家层面严禁私有制，结果江浙的小农户搞了“分田到户”私有承包，后来却全国推广了。面对新情况，国家领导也在摸索，但又要给广大普通人一致的声音。所以先放话。在日后的实践中，慢慢修正，甚至会产生与放话的内容完全相反的实践。至于普通人，如果把放话的内容听的太真，跟领导较劲儿，就是不懂套路。 有些企业做了匪夷所思的规定，还名正言顺地称为“企业文化”，对于明显不符合人情逻辑的条例，也就是这类“放话”，企业领导并不知道怎么管理，员工明白就好，该怎么来还是怎么来；但如果因此想挑战企业领导的规定，就是不懂套路。 提拔 or 压制国内有个说法叫”站错队“：不怨能力，是没跟对人。在美国职场，管理层都至少表现比较”亲民“，另外工薪层也基本生活无忧，所以两者相安，比较容易相信对方；相对，国内的职场还没有成熟的系统，就会有”站错队“的风险。另外大家都有生活压力，难免成了隐性竞争对手，互不信任，所以国内的职场被压制可能多过受提拔。这当然是陋习。 偶然看了密西根的地图，一股亲切感就涌上来。在美国的大环境会把善意当作默认的配置，工作生活上有意无意都会受到他人的帮助或有意无意地帮助别人。善意比较容易表达出来；相比，国内的环境，职场上、生活上，都有一些压制感。 比如生活上的压抑感。在北美的同学都嘴上说，回国好啊，吃的多么多么好。实际上，外面的东西都不敢吃，忌讳比如肉干净吗、油干净吗、放了不该放的调料吗。办点事，老是担心哪里被骗了都不知道。社会系统不成熟，就会有这样的隐形成本。 写在最后写完上面的内容4天后，才有机会再次打开。工作到没时间读书是对人最大的消耗。希望自己尽快适应国内工作生活节奏，而又不受制于这样的工作生活状态。 某个人的回忆 ps 军训的时候，每天跑8km，站军姿一个半小时，在这样的环境下反而更激发我去思考，如何把高标准习成标配。 管理之路我以为自己是细节导向的，国内这个工作环境会占据太多个人时间，叫人没时间思考大方向的问题。高标准成为标配吧。 越来越看到技术是平的，相比，工作流程，系统建设才是企业愿意花钱的地方。写程序、推公式、做运营、甚至做基础研究，到一定阶段都是极易取代的。“单腿走路”是high risk的。相比，任何一个领域的产品人，至少有一条粗腿，同时还有很多不错的小腿。把各个环节、各个岗位有机组合起来的，就是管理。而在工作中需要有意培养系统（管理）意识。 现在的民企，管理水平还是很差的。文化层面上，虽然在推一些流程，但是也有一些制度性的限制。一方面，一边高举打破旧思维搞创新，一边又做很多行为细节上的约束，在员工心理建立墙。工作流程的建立，不是做几次讲座、参加几个培训，领导提倡几次，不是喊出来的，而是像培养一个工作习惯。需要反复练习，慢慢融入到企业文化，变成员工自然而然的行为。 日常层面上，任务管理、时间管理都比较缺乏。老板会希望员工加班，但并没有定义很好的工作内容，即缺乏任务管理，缺乏日常的考核机制。然后责任不明晰，缺乏有效的工作模式，比如出现一个问题，一伙儿人都围上来了。或者一个会议讨论停不下来。当然，大的层面还是工作的流程没有建立好。 今后的工作，要经常跳出来思考系统建设，而不要跟年轻人拼体力上。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Apollo 2.0 Planning 源码(1)]]></title>
    <url>%2F2019%2F04%2F28%2Fapollo-planning-%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104// 模块入口APOLLO_MAIN(apollo::planning::Planning)int main(int argc, char **argv)&#123; google::InitGoogleLogging(argv[0]); google::ParseCommandLineFlags(&amp;argc, &amp;argv, true); signal(SIGINT, apollo::common::apollo_app_sigint_handler); apollo::planning::Planning apollo_app_ ; ros::init(argc, argv, apollo_app_.Name()); apollo_app_.Spin(); return 0;&#125;///////////////////////////////////////////////////////int ApolloApp::Spin()&#123; ros::AsyncSpinner spinner(callback_thread_num_); auto status = Init(); status = Start(); spinner.start(); ros::waitForShutdown(); Stop(); return 0;&#125;///////////////////////////////////////////////////////Status Planning::Init()&#123; hdmap_ = apollo::hdmap::HDMapUtil::BaseMapPtr(); apollo::common::util::GetProtoFromFile(FLAGS_planning_config_file, &amp;config); if(!AdapterManager::Initialized())&#123; AdaapterManager::Init(FLAGS_planning_adapter_config_filename); &#125; AdapterManager::GetLocalization(); AdapterManager::GetChassis(); AdapterManager::GetRoutingResponse(); AdapterManager::GetRoutingRequest(); if(FLAGS_enable_prediction) AdapterManager::GetPrediction(); if(FLAGS_enable_traffic_light) AdapterManager::GetTrafficLightDetection(); ReferenceLineProvider::instance()-&gt;Init(hdmap_, config_.qp_spline_reference_line_smoother_config()); RegisterPlanners(); planner_ = planner_factory_.CreateObject(config_.planner_type()); return planner_-&gt;Init(config_);&#125;/* DEFINE_string(planning_adapter_config_filename, "modules/planning/conf/adapter.conf", "The adapter configuration file")*////////////////////////////////////////////////////////////////void AdapterManager::Init(const std::string &amp;adapter_config_filename)&#123; AdapterManagerConfig configs; util::GetProtoFromFile(adapter_config_filename, &amp;configs); Init(configs);&#125;//////////////////////////////////////////////////////////////void AdapterManager::Init(const AdapterManagerConfig&amp; configs)&#123; if(Initialized()) return; instance()-&gt;initialized_ = true; if(configs.is_ros())&#123; instance()-&gt;node_handle_.reset(new ros::NodeHandle()); &#125; for(const auto &amp;config : configs.config()) &#123; case AdapterConfig::CHASSIS: EnableChassis(FLAGS_chassis_topic, config); break; case AdapterConfig::LOCALIZATION: EnableLocalization(FLAGS_localization_topic, config); break; // ... &#125; &#125; /* DEFINE_string 宏 FLAGS_chassis_topic -&gt; /apollo/canbus/chassis FLAGS_localization_topic -&gt; /apollo/localization/pose*/ where is EnableChassis ? in /apollo/modules/common/adapters/message_adapters.h 12345using ChassisAdapter=Adapter&lt;::apollo::canbus::Chassis&gt;;using GpsAdapter = Adapter&lt;apollo::localization::Gps&gt;;using PlanningAdapter = Adapter&lt;planning::ADCTrajectory&gt;; in /apollo/modules/common/adapters/adapter_manager.h 1234#define REGISTER_ADAPTER(name) public static void Enable##name(const std::string &amp;topic_name, const AdapterConfig&amp; config) &#123; &#125; continue tomorrow]]></content>
      <tags>
        <tag>apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自动驾驶职位介绍]]></title>
    <url>%2F2019%2F04%2F08%2F%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E8%81%8C%E4%BD%8D%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[光庭科技（武汉）智能网联汽车车载终端产品，汽车IT公司，自主研发、产品设计、制造和销售。e.g. 自动驾驶控制器，远程无线通信终端，立体相机、地图传感器、”光谷梦4.0”自动驾驶系统 职位：感知算法工程师 要求：图像/点云目标检测、跟踪；slam算法；Camera/Lidar/Radar传感器融合算法；系统集成和调试 加分项：ROS开发经验，视觉SLAM算法，深度学习算法 职位：控制算法工程师 要求：控制系统设计、信号处理、动态系统建模； 时域/频域控制器设计和稳定性分析；汽车速度和方向控制 职位：测试主管 要求： 产品测试方案、管理。软件测试及自动化测试工具 华砺智行（武汉）智能基础设施平台，为智能驾驶、智慧城市提供软硬件解决方案。产品：智能网联汽车终端、交通行业、无线通信、云平台、交通应用等 天迈科技（郑州）城市公交运营、管理及服务提供综合解决方案。车联网产品：智能公交调度系统、远程监控系统、智能公交收银系统、充电运营管理。 职位：视频算法工程师 要求： 驾驶员行为状态检测算法，机器学习检测效果 赢彻科技物流 纵目科技环视ADAS解决方案 职位： 车身控制算法工程师 要求： 车身横向、侧向控制算法设计、仿真、测试。自动控制理论，车辆底盘控制，车身动力学，Carsim, Simulink 西井科技（上海）职位： 仿真平台开发工程师 要求： 设计仿真平台架构，传感器仿真模型，3D物理引擎(unreal, unity)，熟悉开源仿真平台(carla, airsim)，构建场景环境 小鹏汽车（广州）职位： SLAM专家 要求： 视觉定位算法；与感知、地图模块结合做3d视觉系统； 职位：HD Map工程师 要求： 大规模多层高精地图框架，地图API, 地图数据质量评估，地图数据格式 职位：运动控制算法专家 要求：转向、制动、动力系统的主动控制，对底盘、执行器的控制需求；车道保持、自适应巡航、自动变道等功能运动控制，现场调试 职位：规划与控制专家 要求：算法开发、测试，提出硬件设计和集成要求 职位： 雷达算法工程师 要求： 算法仿真验证、数据分析、算法嵌入式平台实现、维护 职位：计算机视觉 要求：场景元素识别；道路、停车场环境寓意分割；算法验证 职位：传感器融合 要求： 毫米波、超声波、摄像头、激光雷达测试开发； 感知数据处理、实时地图构建及应用；目标实时跟踪与预测 职位：项目经理 要求： l2-l4产品解决方案项目管理 宇通汽车（深圳）职位： 控制工程师 要求： 轨迹跟踪、车辆控制、 仿真优化 职位：行为决策工程师 要求：行为决策算法开发，碰撞预测、行为预测、驾驶经验库、交通安全规则库等，基于强化学习的跟踪(?) 职位：首席工程师 要求：自驾客车架构规划、设计；核心算法开发和测试；自动驾驶技术跟踪。熟悉人工智能、机器视觉、深度学习、高精地图、定位等， 熟悉滤波算法、轨迹规划 纽励科技职位：ADAS产品经理 要求：产品客户需求调研、项目收集整理， 与主机厂沟通技术方案，产品改进。熟悉AEB, ACC, LKA, FCW, 自动泊车，熟悉汽车电子软硬件设计、嵌入式开发标准，熟悉传感器 光束汽车职位： 控制算法 华人运通职位： 控制工程师 要求： 运动控制算法的设计开发、仿真、优化，测试； 基于驾驶员操作数据的车辆运动控制算法 恒大汽车自行开发，现有汽车平台及产品 职位： 仿真验证经理 要求：汽车电子网络、诊断开发测试、 研发中心结构： 造型中心，动力总成中心， 车联网中心，整车工程中心，自动驾驶中心 上海电气轨道公交智能系统 职位： 控制算法工程师 要求：车辆控制实时数据采集、理论模型、系统仿真和实测验证算法 Magna Steyr 麦格纳斯太尔汽车技术职位： L4 ADAS电子专家 要求： ADAS SE团队 职位： GNSS测试验证首席工程师 牧月科技职位：仿真系统工程师 要求： 负责仿真系统开发、测试，及各种传感器的仿真软件库，利用已有数据构建仿真场景；开发自动化仿真分析平台 景驰科技（文远知行）职位： 仿真算法工程师 要求： 开发场景自动化生成算法、人机交互仿真软件工具集、可扩展计算框架 腾讯CSIG事业部伟世通职位： 软件测试 要求： ADAS软件测试、竞品分析 博世（苏州）职位： 控制算法工程师 要求： ADAS自动泊车系统 亿伽通（吉利系）职位：算法工程师要求：定位产品场景、需求分析； 参与搭建自动驾驶数据智能服务平台；熟悉基于视觉的slam方案 奥迪中国（北京）车联网团队 职位： 测试工程师 要求： ADAS/HAD功能测试 职位：仿真工程师 要求： SiL环境搭建，adas功能仿真测试 斑马智行（阿里、上汽）智加科技（苏州）职位： 传感器标定工程师 要求： 传感器选型、数据读取、内外参标定、在线检测 职位：感知算法工程师 要求： 对图像、点云等的静态场景要素检测和追踪；融合传感器数据后的目标检测和跟踪；服务地图自建、预测规划决策系统 职位： 地图定位工程师 要求： 开发多传感器融合算法以提高地图精度，自动化地图的大规模采集、生成、标注、校政。 职位： 决策规划工程师 要求： 预测、决策、规划等系统 职位： 仿真工程师 要求： 利用真实数据或合成数据搭建动态环境的仿真框架；设计场景，为感知、规划、预测等模块开发仿真测试接口；开发基于仿真测试的自动化分析平台；构建可扩展的仿真框架 魔视智能（上海）极目智能职位： 车辆决策算法工程师 零跑科技职位： 算法工程师 要求： 定位算法模块，基于GPS/IMU的航伟推算算法，视觉定位算法 阿里巴巴（人工智能实验室）职位： 仿真算法工程师 吉利Volvo上海研发中心中智行（南京）l4 解决方案 同元软控（苏州）国产CAD/CAE产品供应商 华为2012华为海思（上海）职位： 软件测试 一汽红旗职位： 车联网构架设计师 要求： T-box端-云构架，v2x 潜在人选： 车联网企业： 斑马、亿伽通、博泰、百度车联网团队、飞驰镁物、哈曼、四维图新、梧桐车联 新势力： 蔚来、小鹏、威马 职位：软件算法、系统工程师 潜在人选： 上汽人工智能实验室 英伟达 福特-argo ai momenta, plusai 职位： 数据挖掘工程师 要求： 大数据建模分析，用户数据、车辆数据、驾驶员数据等 潜在人选： 浪潮 曙光 华为云 阿里云 百度 华域汽车滴滴无人车美团无人车职位： 仿真工程师 一汽大众职位：决策算法工程师 veoneer职位：adas软件开发工程师 易航智能职位： 控制算法工程师 三一无人驾驶无人码头 职位： 算法工程师 易高美职位： hpmap仿真工程师 要求： 大批量仿真数据自动化生成；设计分布式仿真系统底层架构，3D引擎编辑器工具链开发；实现仿真系统场景渲染；对大批量及各种随机虚拟数据自动化脚本工具开发。OpenGL/Direct3D图形接口; unreal, unity引擎]]></content>
      <tags>
        <tag>self-driving</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[particle filter (2)]]></title>
    <url>%2F2019%2F04%2F03%2F%E7%B2%92%E5%AD%90%E6%BB%A4%E6%B3%A2-2%2F</url>
    <content type="text"><![CDATA[前一篇 介绍贝叶斯滤波的数学原理和蒙特卡洛定位的算法。本篇将介绍基于序贯重要性采样。粒子滤波的思想就是采用一个加权粒子分布去近似后验概率分布p(x) 蒙特卡洛积分定义一连续随机变量X, 其概率密度分布函数为 p(X); 定义Y=f(X)， 则随机变量Y的数学期望： 实际中，概率密度分布p(X)未知，如何保障所采样的点服从p(X) 直接采样通过对均匀分布采样，实现对任意分布的采样。 任何未知概率密度分布的累积概率函数cdf都映射在[0-1]区间，通过在[0-1]区间的均匀采样，再函数z = cdf(y)求逆，即是符合真实 y的概率密度分布的采样点。 但如果cdf()函数未知或无法求逆，直接采样不可行。 接受-拒绝采样用一个已知概率分布函数q(X)去采样，然后按照一定的方法拒绝某些样本，达到近似p(X)分布: p(x_i) &lt;= k p(x_i) 该采样的限制是确定参数k。 重要性采样在一定的抽样数量基础上，增加准确度。未知p(x), 在已知概率密度分布的q(x)上采样{x_1, x_2, … x_n}后估计f的期望： 定义新的随机变量： 关于原随机变量Y在未知概率分布p(x)下的期望，转化为新的随机变量Z在已知概率分布q(x)下的期望。已知概率分布，即知道如何采样。这里 p(x)/q(x) 就是权值。 so the posterior expectations can be computed as: as the importance weights can be defined as: the problem is we can’t get p(x|z) , but a loosed (unnormalized) importance weights as: then do normalized from it: so the posterior expectation is approximated as: sequential importance sampling(SIS)consider the full posterior distribution of states X_{0:k} given measurements y_{1:k} : consider the sequential of q(x): then the unnormalized importance weights can be as: namely: the problem in SIS is the algorithm is degenerate, that variance of the weights increases at every step, which means the algorithm will converget to single none-zero (w=1) weight and the rest being zero. so resampling. sequential importance resampling(SER)resampling process: 1) interpret each weight as the probability of obtaining the sample index i in the set x^i 2) draw N samples from that discrete distribtuion and replace the old sample set with the new one. SER process: 1) draw point x_i from the q distribution.2) calculate the weights in iteration SIS and normalized the weights to sum to unity3) if the effective number of particles is too low, go to resampling process]]></content>
      <tags>
        <tag>control</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[partical filter]]></title>
    <url>%2F2019%2F04%2F02%2Fpartical-filter%2F</url>
    <content type="text"><![CDATA[localizing the vehicle involves determing where on the map the vehicle is most likely to be by matching what the vehicles see to the map. Markov localization or Bayes Filter for localization is the generalized filter. thinking of the robot location as a probability distribution, each time the robot move, the distribution becomes more diffuse(wide). by passing control data, map data, observation into the filter will concentrate(narrow) the distribution at each timestep. state spacex = f(x, v) (1) z = h(x, w) (2) v, w is the process noise, measurement noise respectfully, and each is in the normal Gaussian distribution. Bayes filter derivation (b) consider the multiply rule of probability: p(a, b) = p(a|b) p(b) lhs of equation(b) is: given x_k, assuming z_k is independent from all previous measurements z_{1:k-1}: Markov Localizationin which the true state x is unobserved, and the measurements z is observed.assuming 1st order Markov, the probability of current true state: p(x_k | x_{0:k-1}) == p(x_k | x_{k-1}) (3) similarly, the measurement is only dependent on current state, which is a stochastic projection of the true state x_t, : p(z_k | x_{0:k}) = p(z_k | x_k) (4) (3) is referred to as motion model, and (4) as measurement/observation model. the classical problem in partially observable Markov chains is to recover a posterior distribution from all avilable sensor measurements and controls in all timesteps. Especially, for the localization problem here is to obtain the system current state posterior p(x_k | z_{1:k}) based on the all existing measurements, which can be solved by Bayes Filter. ps. the propability distribution of current state is also depend on other known inputs, e.g. map data, control data. predictionfrom Bayes filter equation, p(x_k | z_{1:k-1}) need get first, which is the prediction step. physically, it used to estimate the system state based on all previous measurements. consider x_{k-1} as the random variable, the integration of pdf p(x_k, x_{k-1} | z_{1:k-1}) about x_{k-1} is p(x_k | z_{1:k-1}) consider the multiply rule: by 1st order Markov assuming, the first item in integral can reduced: p(x_k | x_{k-1}) is determined by the system, which obey the same distribution of process noise. p(x_{k-1} | z_{1:k-1}) is known, as the posterior state at timestep k-1. this is where the recursive process. updateusing equation (b) to update the current posterior state. the denominator of (b) is a constant coeffient. p(z_k | x_k) is the likelihood paramter, decided by measurement.]]></content>
      <tags>
        <tag>control</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无迹卡尔曼滤波]]></title>
    <url>%2F2019%2F03%2F31%2F%E6%97%A0%E8%BF%B9%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%2F</url>
    <content type="text"><![CDATA[非线性系统： x = f(x, w) （1） z = h(x) + v （2） 随机信号 w, v分别是过程噪声和观测噪声 CTRV 状态方程对于const turn rate and velocity magnitude (CTRV )场景： x = (px, py, v, phi, \dot{phi}) 固定速度和转动速率约束，即： 考虑 dv/dt == 0 , dphi^2\dt^2==0 且\psi是时间的函数, 上述第一项即： 从原状态空间到预测空间，由方程（1),（2）可见，过程噪声w是状态x的非线性项；而z关于观测噪声v是线性的。ukf实际采用增广状态变量sigmax = [x, w]. 过程噪声w包括径向加速度和角加速度 [w_a, w_phi]， 且w不是时间的函数 , 对上述第一项可展开： 预测空间对比扩展卡尔曼 ekf采用一阶线性化近似。无迹卡尔曼ukf，将原状态空间的特征采样点(sigmax)映射到预测空间，采用预测空间里的状态变量f(sigmax)的均值、方差的加权推广作为先验状态估计x^- 和先验误差P^-。 其中权值表述： $$ w = lamda / ( lamda + ns) when i==1 $$ $$ w_i = 0.5/(lamba + ns) when i!=1 $$ $$ X^- = sum(w_i * f(sigmax) ) $$ $$ P^- = sum(w_i * (f(sigmax) - x).^2) $$ 观测空间将原状态空间的特征采样点(sigmax)映射到观测空间，采用观测空间里的状态变量h(sigmax)的均值、方差的加权作为先验观测值Z^- 和观测值先验误差S^-，使用与预测空间同样的权值。 $$ Z^- = sum(w_i * h(sigmax) ) $$ $$ S^- = sum(w_i * (Z^- - z).^2) + R $$ 卡尔曼滤波表示： 后验估计（真实状态变量值）与先验估计（预测空间的状态变量值）的差异，可表示为真实观测值与观测空间里的先验观测值的差异的增益 K。 $$ x - x^- = K (z - Z^-) $$ （3） 可见，卡尔曼增益K在衡量状态误差与观测误差之间的相关性。定义预测空间与观测空间的相关系数： T = sum(w_i * (X^- - x)(Z^- - z)) K = T / S^- （4） ukf算法有（4）， （3） 分别更新卡尔曼增益和状态变量， 预测空间里的先验误差更新由： P = P - KSK^t ps: 在非线性的处理上，线性化或者布点采样都是常用的思路。也是ekf与ukf的区别。 link1 link2]]></content>
      <tags>
        <tag>control</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CarND(term2): Extended Kalman Filter]]></title>
    <url>%2F2019%2F03%2F31%2FCarND-term2-Extended-Kalman-Filter%2F</url>
    <content type="text"><![CDATA[sensor measurementRadarradio detection andranging, using radio waves to measure the distance to objects as well as their velocity and angle. Radar used a lot in preventing collions, parking assistance, cruise control. and Radar isn’t affected by weather conditions. while Radar can’t tell an object’s shape correctly. and Radar can’t detect objects if they are out of their line of sight. the Radar measurement data in EKF proejcct is 3D position and velocity vector (ro, theta, ro_dot) in polar coordinates. Lidarlight detection and ranging, using near-infrared light to scan objects and create 3D map of the enviroment. it’s 360-degree view and can track movements and their directions. but it also depends on weather conditions and can’t detecting the speed of other vehicles well. the Lidar measurement data in EKF proeject is 2D position vector (x,y) in Cartesian coordinate system. compare Radar vs Lidar server - client networkUdacity simulator communicate with EKF controller through websocket. in simulators(Udacity carsim, Carla) running time, the message channel between simulator server and external controller need to be open all the time. so the simulator feed the controller with sensor data, and the controller feedback simulator with controlling data. uwebSocketbuilt once uwebSocket, webSocket protocol providing full-duplex communication channel between server and client through a singlt TCP connection. it allows the server to send content ot the client without being first requested by the client, and allowing messages to be passed back and forth while keeping the conenction open. sensor raw dataevery data slice includes a either Lidar or Radar raw measurement and a ground truth measurement. The state variable x is described in Cartesian coord, so for Radar measurement processing, there is a coordinate transfer from Cartesian to polar, and which lead it nonlinear, requiring Extended Karman Filter. EKF controllerthe client side is the EKF controller, which process the sensor measurement. define system state `x_` , state priori covariance `P_`, state transition matrix `F`, process covariance `Q_`, measurement gain matrix &apos;H&apos; measurement covariance &apos;R_&apos; kalman filter gain &apos;K&apos; as discussed in previous blog: 12345678910111213141516171819 void KalmanFilter::Predict()&#123; x_ = F * x_ ; P_ = F * P_ * F.transpose() + Q_ ;&#125;void KalmanFilter::Update(const Vector &amp; measurement)&#123; if(EKF) h = toPolar(x_); y = measurement - h ; else y = measurement - H * x_ ; K = P_ * Ht / (H * P_ * Ht + R_); x_ = x_ + K * y ; P_ = (I - K*H) * P_ ; &#125;]]></content>
      <tags>
        <tag>control</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卡尔曼滤波]]></title>
    <url>%2F2019%2F03%2F30%2F%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%2F</url>
    <content type="text"><![CDATA[状态方程状态变量 $x$ 满足, 其中 u为控制变量： $$ x = A x_prev + B u_prev + w_prev $$ (1) 观测变量 $z 满足： $$ z = H x + v $$ (2) 随机信号 $w$ 和 $v$ 分别表示过程激励噪声和观测噪声，假定相互独立，且服从正态分布。 定义状态变量的先验估计 $x^-$， 即基于之前状态对当前状态的预测值； 定义后验估计 $x^$，即已知当前观测值所计算的当前状态变量。 定义先验误差 $e^-$, 后验误差 $e^$, 满足： $$ e^- = x - x^- $$ (3) $$ e^ = x - x^ $$ (4) 卡尔曼滤波表示： 后验估计（观测值所推导的状态变量值）与先验估计（预测的状态变量值）的差异，可表示为观测值与以先验估计为输入的观测值的差异的增益 K。 $$ x^ - x^- = K ( z - H x^- ) $$ (5) K可由先验误差的协方差 P、观测噪声的协方差R 和观测增益H表示: $$ K = P^- H^t / ( HP^-H^t + R ) $$ (6) 可见： 1） 当R 趋于0时， k 趋近于 h 的逆，此时 x^ = x。即当观测误差很小，观测值趋近真实值。 2） 当P趋于0时，即预测值趋近真实值。 算法设计卡尔曼滤波器用反馈控制估计过程状态（变量）： 滤波器估计某一时刻的状态（时间更新/预估），然后以（含噪声的）测量变量获得反馈（测量更新/校政）。 时间更新，当前时步状态先验估计 x^- 及先验误差协方差近似P^-: $$ x^- = A x^-_prev + B u_prev $$ (7.1) $$ P^- = A P^_prev A^t + Q $$ (7.2) 其中 $ P(w) ~ N(0, Q) $ 测量更新，使用(6)更新卡尔曼增益K, 使用（5)更新后验状态变量x^和当前步先验误差协方差值 P^： $$ P = ( I - KH ) P^- $$ (8) 控制器调参测量误差一般可观测得到；而过程误差q需要通过与一个已知误差的在线滤波器对比调整系数。调参一般是离线过程。一般当过程误差和卡尔曼增益会快速收敛并保持常数。但测量误差受环境影响不易保持不变。 扩展卡尔曼当观测值与系统状态变量 或 系统本身是非线性关系，方程(1), (2)变非线性函数。 $$ x = f(x_prev, u_prev, w) $$ (1.2) $$ z = h(x, v) $$ (2.2) link]]></content>
  </entry>
  <entry>
    <title><![CDATA[paper reading-Carla an open urban driving simulator]]></title>
    <url>%2F2019%2F03%2F30%2Fpaper-reading-Carla-an-open-urban-driving-simulator%2F</url>
    <content type="text"><![CDATA[CARLA used to support training, prototyping, validation of self-driving models, including perception and control. CARLA is usded to study the performance of three approaches, 1) classic modular pipeline that comprises a vision-based perception module, a rule-based planner, and a maneuver controller; 2)a deep network that maps sensory input to driving commands via imitaion learning; 3) end-to-end reinforcment learning. all approaches make use of a high-level topological planner. the planner takes the current position of the agent and the location of the goal as input, and use A* algorithm to provide a high-level plan. this plan advises the agent to turn left/right, or keep straight at intersections, but not provide a trajectory neither geometric info. which is a weaker form of common GPS. simulation engineCARLA simulates a dynamic world and provide a simple interface between the world and an agent that interacts with the world. CARLA is designed as a server-client system, where the server runs the simulation and renders the scene, the client API is responsible for interaction between the agent and the server via sockets. the client send commands and meta-commands to the server and receives sensor readings in return. the comands control the vehicle and includes steering, accelerating, and braking. meta-commands controls the behavior of hte server, e.g. resetting hte simulation, modifying the sensor suite. environmentthe static 3D world, such as buildings, traffic signs, and the dynamic objects such as vehicles, pedestrains. the behavior of non-player characters is based on standard UE4 vehicle model(PhysXVehicles), and extended with a basic controller to govern NPC’s behavior: lane following, respecting traffic lights, speed limits, and decision making at intersections. pedestrainspedestrains navigate the streets according to a town-specific navigation map, which conveys a location-based cost, which is designed to encourage pedestrains to walk along sidewalkd and marked road crossing, but allows them to cross road at any point. sensorscamera parameters include 3D location, 3D orientation with respect to the vehicle’s coordinate system, field of view, and depth of field. the semantic segmentation pseudo-sensor provides 12 semantic classes: road, land-marking, traffic sign, sidewalk, fence, pole, wall, building, vegetation, vehicle, pedestrain, and other. a range of measurements associated with the state of the agent. ? measurements concerning traffic rules include the percentage of vehicle’s footprint that impinges on wrong-way lanes or sidewalks, as well as states of the traffic lights and speed limit at the current location of the vehicle. CARLA provides access to exact location and bounding boxes of all dynamic objects. autonomous drivingthe agent interacts with the environment over discrete time steps. at each time step, the agent gets an observation, which is a tuple of sensory inputs, and must produce an action, which represents steering, throttle, brake. modular pipelinethe pipeline includes: perception, planning, continuous control. local planning is critical based on visual perception. perceptionusing semantic segmentation network based on RefineNet to estimate lanes, road limits, and dynamic objects. and a classification model is used to determine proximity to intersections. the local plannercoordinates low-level navigation by generating a set of waypoints, near-term goal states that represents the desired position and orientation of the car in near future. the rule-based state: 1) road-following, 2) left-turn, 3) right-turn, 4) intersection-forward, 5) hazard-stop. transitions between states are performed based on estimates provided by the perception module and on topological info provided by the global planner. continuous controllerusing PID controller, which inputs current pose, speed, a list of waypoints, and outputs steering, throttle, and brake. carla release9.11) enable client to detect collisions and determine lane changes : sensor.other.collision, sensor.other.lane_detector, 2) access to the road network, waypoints nearby current vehicle and define user navigation algorithms: Map 3) support new map created from external RoadRunner/VectorZero, in OpenDriven map standard 9.21) simulation of traffic scenarios by Scenario Runner. e.g. following leading vehicle, stationary object crossing, dynamic object crossing, opposite vehicle running red light, vehicle turn right/left etc 2)upgraded ROS bridge 3) vehicle navigation from client side: BasicAgent, navigate to a point given location while dealing with other vehicles and traffic lights safely; RoamingAgent, drives around making random choices when presented to multiple options 9.31) new town and new pedestrains 2) no rendering mode, a 2D map visualization tool that display vehicles, traffic lights, speed limits, pedestrains, road, etc. help to improve the server framerate 3) traffic light class in client TrafficLightState 4) new sensors. ObstacleDetector, a simple raycast sensor to detect something in front of the ego vehicle and what is it; and GlobalNavigationSatelliteSystem, attach to ego vehicle and get its geolocation, which is based on the geo-reference define in OpenDriven file associated with each map. 9.41) allow client side to change physics properties of vehicle or their components in runtime WheelsPhysicsControl 2) logging and playback system, which includes a camera-following mode to follow a target actor while replaying the simulation, and can replay situations from different viewpoints. and the logging query engine allow users to query different types of events. 3) random streaming port, which makes it possible to stream sensor data in a secondary port 4) import maps, replace maps as tar.gz files in “ExportedMaps” folder]]></content>
      <tags>
        <tag>self-driving</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paper reading-autonoVi: AV planning with dynamic maneuvers and traffic constraints]]></title>
    <url>%2F2019%2F03%2F29%2Fpaper-reading-autonoVi-AV-planning-with-dynamic-maneuvers-and-traffic-constraints%2F</url>
    <content type="text"><![CDATA[this is the advanced driver module in Vi-sim simulation platform. this driver module algorithm pipeline: 1) a route plan by graph-search over the network of roads 2) rules based guiding trajectories generation(traffic and lane following rules) 3) set of candidate trajectories(control inputs) generation and evaluated by vehicle dynamic model and collision free model 4) most feasible trajectory evaluated through optimization vehicle state spacethe full state of a vehicle updates: X = (x, y, v, theta, throttle, steering, behavior) the vehicle updates its plan at a fixed palnning rate dt; at each pllaning step, the vehicle computes a target speed v and target steering theta to be achieved by the control system S(u, X) determine if a set of control is feasible, given current state of the vehicle, S(u, X) will return false if the given input u cause a loss of traction or control. sensing and perceptionthe sensing module provide an approximation of the center line of lane, closet point on the lane center to the ego-vehicle, and friction coefficient. route choice and behavior statebehavior set includes merging, right turn, left run, keep straight. the behavior state of the vehicle is described as a finite-state machine(turn left, turn right, merge left, merge right), which restrict potential control decisions and adjust the weight of the cost function. guiding paththe ego-vehicle computes a set of waypoints along the current lane at fixed time intervals. how to create the path based on waypoints collision avoidancedefine obstacles domain for each neighbor of the ego-vehicle, which is defined as all controls that could lead to collision. the obstacles domain and the set of dynamic infeasible domain form the boundary of collision-free space for the ego-vehicle. trajectory samplingthe exact obstacle domain is not computing time efficent, instead here use a sampling strategy around theta and v to determin a feasible control. each sample is referred to as a candidata control u_c. trajectory cost functiononce the set of suitable control candidates has been computed, the most feasible control will be selected by minimizing the cost function for each sample point i : C = sum_i{ C_path(i) + C_cmft(i) + C_mnvr(i) + C_prox(i) 1) path cost, defined as success at tracking its path and the global route. 2) comfort cost, C_cmfg = ||vel_acc|| + ||theta_acc|| 3) maneuver cost, penalize lane changes C_mnvr = lane_change 4) proximity cost, prevent the ego vehicle from passing close to neighbors. control inputone PID controller to driven current speed to match the target speed; another PID controller drives the current steering angle to match the target.]]></content>
      <tags>
        <tag>self-driving</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未来5年在哪里(6)]]></title>
    <url>%2F2019%2F03%2F29%2F%E6%9C%AA%E6%9D%A55%E5%B9%B4%E5%9C%A8%E5%93%AA%E9%87%8C-6%2F</url>
    <content type="text"><![CDATA[广州之行投自动驾驶，隐约有些不安全感。比如，激光雷达、定位l3+的HDMap, 仿真环境，l4全栈解决方案。一旦l3+以上的自动驾驶方案短期内不会量产，做这些方向的创业团队、产品投入都会”死“。 国内所有行业的激烈竞争，造成包括互联网公司、主机厂、创业团队，都强烈需要落地产品。而对于一个遥遥无期，5～10年，甚至更久以后才能实现的产品的技术研发投入是所有公司不能承受之轻。相反，对能快速落地的产品、应用场景，也是各方发力的地方。比如， l1 ~ l2.5 的 adas 产品。 在国外主机厂侧重研发；国内主机厂侧重落地。也是回国感受到的落差。朋友讲，国内主机厂对供应商的依赖很重。长城的情况大概就是，l3以下的adas产品软硬件全栈由供应商提供，主机厂自身连标定/调参都不参与😓。主机厂的趋势是慢慢自己做，也是国内汽车人的机会吧。相比，福特，通用都是15+万员工的规模，国内自主品牌主机厂的员工规模在1/20。另外，国内主机厂员工大多是dre角色。 行业走近了，都是深水。想轻轻松松工作，就是表面划水。对行业风险缺乏判断、或者不能承受行业风险的，想挑容易的活儿，那在哪行都待不长。所以啊，年轻人就要在压力环境下活着。 汽车创业了解到一些汽车行业的创业者，比如做汽车云、车载服务、以及自动驾驶软硬件方案。可能因为创业方向本身只是依托于自驾、智能网联车等具体应用场景，其所创的技术只是一些在其他领域成熟或新的技术。比如，云计算、移动操作系统、视觉AI、5G等技术在汽车载体上的转化应用。 所看到的汽车领域的创业，更像是一个技术转化。而源于汽车领域自身的新创意，似乎只在博世、大陆等成熟技术积淀的企业里面逐步推进的。而且行业内新应用场景的标准定义也是由这些大厂主导的。比如，AutoSar, LTE-V2X, ADAS前装需求定义等等。 没有行业积淀的汽车创业，看着叫心悬，这样都敢玩！他们最好的命运可能是被主机厂收购，但是更大可能是被互联网巨头挤掉，无声无息。从广州回家的路上想到：自己曾经也是有梦想的人，面对现在的市场环境，也许能去个大平台做点事，就聊以自慰了。 创业 本是个挺好的事儿，但必须有强大的信念，觉得这事儿一定能成。只想搞个概念移植，那是注定要凉。]]></content>
  </entry>
  <entry>
    <title><![CDATA[paper reading- autono Vi-Sim simualtion platform]]></title>
    <url>%2F2019%2F03%2F28%2Fpaper-reading-autono-Vi-Sim-simualtion-platform%2F</url>
    <content type="text"><![CDATA[introduction of Vi-Sim data generation, allowing exports of traffic data and virtual sensor data on the vehicle, which can be used in training DL by generating automatically labelled classification and control data dynamic traffic conditions, with varying vehicles, pedestrians, lighting, weather rapid scenario construction simulation modules Vi-Sim is divided into 8 extensible modules. roads represented by center line, #lanes, directions, surface friction. the roads can quick constructed by drawing splines on the landscape road network provides connectivity information of road and traffic infrastructure. the road network provides routing and localization purpose. infrastructure represents traffic lights, signage, and any entities that will modify the behavior of vehicles on the road. environment represents the time of the day, weather, rain conditions, road friction etc. non-vehicle traffic basically pedestrains and cyclists in the map. both are following safe traffic rules. data capture this module used for logging data of the environment as well as sensor data from ego vehicle driving modulesvehicle represented as a physical-driven entity with specific tire, steering, sensor parameters. the vehicle has 3 components: * control is provided with steering, throttle, brake inputs; * dynamics is implemented in Nvidia physX engine; * perception component is a ray-cast with configurable uncertainty, detection time, classification error rate, and sensor angle/range. a vehicle can equip multiple sensors. the perception component provides interface to a generic camera interface and Monte Carlo scanning ray-casts, which can be extended to Lidar/camera based NN claassifiers. driver driving decision module, who fuses information from road network and vehicle’s sensor to make decisions. currently there are 3 driver models * lane-following driver, which employs control command like lane-keeping ADAS * manual driver, allows a human drive the vehicle * autonoVi driver, use optimization-based maneuvering with traffic constraints to generate advanced behaviors limitations lack of calibaration configuration to replicate specific sensors driver modules are limited to hierarchical, rule-based approaches real traffic conditions thoughts1) sensor components in simulation, e.g. Lidar, camera, Radar 2) sensor calibration in simulation, Apollo and Carla may has some good suggestions 3) multi-agents environment 4) distributed framework to ensure real time multi-agents simualtion]]></content>
      <tags>
        <tag>self-driving</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paper reading-distributed simulation platform for autonomous driving]]></title>
    <url>%2F2019%2F03%2F28%2Fpaper-reading-distributed-simulation-platform-for-autonomous-driving%2F</url>
    <content type="text"><![CDATA[to test newly developed algorithms, due to the massive amount of simulation data, need a distributed simulation platform based on Spark distributed framework. simulation based on synthetic data, used in control and planning simulation based on real data playback, used to test function and performance of different components in autonomous driving system, each functional module in ROS is deployed as a node, the communication between nodes rely on the messages with well-defined formats. so the test of each module is independent, we can develop simulation module for each functional module. anatomy of simulatorthere should be a dynamic model of the car, a vehicle dynamic model; then the external environment is needed, which includes static and dynamic scenes. the simulator can decompose external environment into basic elements, and rearranges the combination to generate a variety of test cases, each simulating a specific scenario. e.g. the position, speed, next step command of the barrier vehicle can give different basic elements. ROS based simulatorto use the real traffic data to reproduce the real scene requires a distributed simulation platform. ROSBAG, record from Topic and replay message to Topic. the Record function is to create a recording node in ROS, and call the subscribe method to receive ROS message to all Topics, and then write the message to Bag file. the Play function is to establish a play node, and call the advertise method to send message in bag to specified Topic. Spark distributed platformthe Spark driver launch different simulation applications, e.g. localization algorithms, object recoginization algorithms, vehicle decision-making and control algorithms etc, then allocate resources to each Spark worker, who first reads the RosBag data into memory and launches a ROS node to process the incoming data. the interface between Spark and ROS is through Linux pipe, basically data written to the write end of the pipe is buffered by the kernel until it is read from the read end of the pipe. two problems: 1) Spark only support text-based data consuming; 2) Spark memeory to ROBag Binary data streamingthe core Spark data structure is resilient distributed dataset (RDD). to process and transform binary data into a user-defined format and transform the output of Spark computation into a byte stream, even further to a generic binary file(HDFs) 1) encode and serialize the binary files(image, lidar input data) to form a binary byte stream 2) de-serialize and decode the binary stream, according to interpret byte stream into an understandable format and perform target computation 3) the output then be encoded and serialized before passed in RDD partitions(e.g. HDFs), and returned to Spark driver data retrieval through ROSbag cachetwo things: reading from memory through ROSbag play, and writing to memory through ROSbag record. solution: design a memoryChunkedFile class, derived from ChuckedFile class, to read/write memory rather than files.]]></content>
      <tags>
        <tag>self-driving</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[paper reading-perception, planning, control and coordination for autonomous vehicles]]></title>
    <url>%2F2019%2F03%2F27%2Fpaper-reading-perception-planning-control-and-coordination-for-autonomous-vehicles%2F</url>
    <content type="text"><![CDATA[Lidar Perception point cloud based approach, directly use the raw sensor data for further processing. usually applied a voxel-based filtering to reduce the number of points feature based approach, extract parametric features out of the point cloud, and represent the environment usign extracted features (out of date) grid based approach segmentation algorithmscluster points into multiple homogeneous groups. edge based method region based method, cluster neighborhood points based on certain criteria model-based / parametric method, graph based method detection algorithmscategorize each cluster into different objects, the information in each cluster is mainly from spatial relationship and Lidar intensity of the points. Visionusually deal with road detection and on-road object detection. Road Detectionlane mark detection lane line feature extractionbasically identify the pixels that belong to lane line marks. fitting the pixels into different models estimate the vehicle pose(lateral position and moving orientation) based on the fitted model. road surface detectioninform the self-driving car on the location of free space where it can drive without collision. usually three ways: feature based detection first identify the feature points or patches in the original image; based on the identified features, either model fitting or segmentation kind of algorithms will be applied to identify the road surfaces. feature based learningfirst extract a set of features associated to pixels or image patches, then train a classifier based on the features to assign a road or non-road label to the pixels or patches deep learning on-road object detectionmainly concerns vehicle and pedestrain object classes, and mainly with deep learning based approaches, whose pipeline usually like: 1) the proposal bounding boxes needs to be generated around the input image 2) each proposal box will be sent through the CNN network to determine a classification and fine tune its bounding box location Fusionsensor fusion betweeen Lidar and camera is necessary to make the best use of these devices and achive a robust environment perception result. Localizationthe problem of estimating the ego vehicle’s pose, can divided into 2 sub-problems: pose fixing problem and dead reckoning problem. pose fixing problem is to predict a measurement given a pose, e.g. a map. dead reckoning problem, the state is related to the observation by a set of differential equations, and these equations has to be integrated in order to navigate. map aided localization algorithm use local features to achieve highly precise localization. e.g. SLAM. a key event in smoothing based SLAM is loop closure, basically when features that have not been seen for a while are observed again from the sensor readings. when a loop closure is detected, the error caused by imperfect odometry can then be removed, and a substantial portion of the map can be updated. approaches to semantic mapping can be categorized into three ways: object based, appearance based, and activity based. appearance based semantic mapping, interpret sensor readings to construct semantic information of the environment object based semantic mapping, use the occurrence of key objects to build a semantic understanding of the environments, where object recognition and classification is important. activity based semantic mapping, relies on information about the activities of the agents around the ego vehicle. Planningmission planningperformed through graph search over a directed graph network, which reflects road/path network connectivity. behavioral planningdecision making to ensure the vehicle follows any road rules and interacts with other agents in a conventional, safe manner. motion planningthe process of deciding on a sequence of actions to reach a specified goal, typically based on avoiding colisions on a sequence of actions to reach a specified goal. combinatorial planning, builds a discrete representation of the real environment, and finds a complete solution. sampling-based planning, utilizes a collision checking module to conduct discrete searching over samples drawn from the configuration space, which rely on random sampling of continuous spaces and the generation of a feasible trajectory graph where feasibility is verified through collision checking of nodes and edges to connect these nodes . planning in dynamic environments decision making structures for obstacle avoidance to monitor regions along the intended path for potential obstacle collisions, where these regions are labeled as “critial zones”, and checking against the trajectories of all nearby vehicles to determine a “time to collision”. planning in space-time control space obstacle represnetations rather than checking for collisions directly in robot’s configuration space, directly plan in the control space by prohibiting certain control actions which are predicted to lead to collision. incremental planning and replanninga means of incrementally generating sub-goals, a new plan is generated as often as a new sub-goal is defined. iteratively replanning to generate new solution trajectories presents a potential opportunity to carry over knowledge from previous planning iterations to subsequent planning iterations. Controlfeedback controle.g. proportional-integral-derivative(PID) controller, the limitation of feedback-only control, is has delayed response to errors. model predictive controltrajectory generation combined trajectory generation and tracking separate trajectory generation and tracking 1) trajectory generation, to find an entire control input, which corresponds to some desired state trajectory. can be dealed as a two point boundary value problem, with a starting state and a final state. 1.1) sensor based trajectory generation 1.2) dynamic based trajectory generation trajectory tracking geometric methods pursues a point along the path that is located at a certain lookahead distance away from the vehicle’s current position. the input is waypoints, rather than smooth curves. model based methods kinematic model based controllers performs well at low speed applications, but the error increase as the vehicle speed and curvature rate of path increases. dynamic model based controllers performs well for higher speed driving applications summarythis is an overview of self-driving car system. From a job-hunting view, the algorithms details are more important and better with some practial experience. paper link]]></content>
      <tags>
        <tag>self-driving</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[book reading: 第一本无人驾驶技术书]]></title>
    <url>%2F2019%2F03%2F27%2Fbook-reading-%E7%AC%AC%E4%B8%80%E6%9C%AC%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E6%8A%80%E6%9C%AF%E4%B9%A6%2F</url>
    <content type="text"><![CDATA[一些方案 基于gps/imu融合的定位 基于视觉的定位 基于点云的定位 基于视觉的物体识别与跟踪 基于lidar的物体识别与跟踪 基于点云的定位简化概率问题：已知t_0 时刻的点云信息，以及t_1时刻，无人车位置的先验概率分布，求无人车位置的概率分布。 贝叶斯法则: $$ P(X_t) = P(Z_t | X_t ) \cdot \ \vec(P(X_t)) $$ $\vec(P(X_t))$ 是汽车当前位置的概率分布； $P(Z_t | X_t)$ 是当前位置下观察的点云概率分布。 ROS based systemROS是基于消息传递通信的、分布式多进程框架。Topic发布、接受是一种异步通信方式； Service服务是一种利用同步通信请求/回复交互的分布式系统。 传感器Lidar 环境感知： 通过雷达扫描汽车周围的环境3d模型。运用相关算法比对上一帧和下一帧，从而匹配环境中的其他车辆或行人 slam定位：实时扫描地图，与高精地图中的特征物比对，实现导航及精准定位。 供应商： Velodyne 毫米波雷达 可用工作频段 24ghz、77ghz, 波长 1 ～ 10 mm。77ghz物体分辨率较24ghz提高2～4倍，测速和测距精度提高3~5倍。电磁波频率越高，距离和速度的检测解析度越高。 供应商 射频芯片：24ghz成熟供应（博世、飞思卡尔）； 77ghz没有对中国开放 雷达数据处理芯片：恩智浦，意行半导体 摄像头 高动态 中低像素 适合温度范围 -40 ～ 80 度 防磁抗振 寿命长 计算平台 计算单元与计算负载 GPU执行卷积任务最有效，DSP执行特征提取最有效。 移动端soc架构 I/O子系统与前端传感器交互；DSP负责图像处理流以进行特征提取；由GPU进行目标识别和其他深度学习任务；由一个多核CPU完成规划、控制和互动的子任务；由FPGA进行动态重构以分时共享的方式完成传感器数据压缩上传，物体跟踪和流量预测等。计算部件和I/O部件之间通过共享内存进行数据通信。 系统安全安全问题：强磁场干扰IMU；假大功率的gps信号；干扰激光雷达，在无人处周围放置强反光物；干扰高精地图的更新； ros系统劫持、通信修改。obd-2入侵， 充电桩入侵，车载cd入侵，蓝牙入侵。 Spark与ROS的分布式模拟平台基于合成数据的模拟；基于真实数据回放的模拟。 高精地图]]></content>
      <tags>
        <tag>self-driving</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未来5年在哪里(5)]]></title>
    <url>%2F2019%2F03%2F26%2F%E6%9C%AA%E6%9D%A55%E5%B9%B4%E5%9C%A8%E5%93%AA%E9%87%8C-5%2F</url>
    <content type="text"><![CDATA[深圳之行来深圳前只说见见朋友。而工作在这里的年轻人，都在讲述着让我陷入焦虑的故事。对国内的年轻人、行业选择、工作地点有了接近真实的了解。可能是朋友的分布在各个地方不同，深圳的年轻人最明显的感受是干劲儿足，而且对未来充满了希望。没有白走的路。 在美帝的最后一段时间有接触面试：阿里巴巴人工智能实验室、美团无人车、硅谷的自动驾驶创业团队， zoox, cruise, tosimple, drive.ai，当时只是隐约感觉不适应。工作内容、技能要求，都不在我的雷达里。 过去来讲，是选择性忽略行业常识。对互联网人、金融人的自信、高薪比较回避，也因为在国外相对生活无忧、高新安逸的环境。而这些行业领头平台对个人成长的价值，也被忽略了。当用常识去看世界，对互联网平台的成长是非常感兴趣。 实际上，平均2～3年，在华为、腾讯等国内领军互联网平台的年轻人可以独立带项目了。相比，在国外工作的头三年，大部分还在为身份焦虑，或者假期哪里玩而晒朋友圈。 站在快速迭代的行业ceo角度讲，比如互联网、金融行业，都越来越校招，使用应届毕业生，其创造的价值和投入的成本确实更划算。除非有突出和无法复制的核心。所以，工作中一定要保持积累，否则离开了平台，又缺少技能积累，很快失去竞争力。甚至一些“曲线救国”的规划，会抓紧到大平台“偷学”完成，然后迅速跳更期望的位置。 回国的朋友说，国内同龄年轻人，对行业技能的积累，比国外回来的要高一两个层次。记得两年前的一个中午，站在上海张江高科园区，看到黑压压的年轻人涌出办公楼，那一刻的感受是蛮绝望的。当时我兴庆不在国内工作。没意识到危机，就先被危险吓到～ 行业分布在美帝的几年，对美帝的产业分布会有些认识。比如，汽车制造业在密西根；石油能源行业在德州；互联网、智能、医疗等在硅谷湾区、波士顿等。对国内的行业分布，也是这次来深圳才慢慢听到的。之前对地域的认识只有南北方区别。北京是互联网、外企聚集地；上海和周边也是外企聚集地，特别汽车行业的产业链全覆盖；深圳广州从加工制造起身，电子硬件产业链完整，也有腾讯、华为等互联网链条。成都、重庆、武汉也集中一批软件产业和汽车制造业。 为什么一定要到行业top的公司去实践，想必是一个常识。虽然平台是带不走的，这里面的管理文化、优秀的同事、解决的行业问题、做的产品、见到的客户等等都会烙印在个人身上。 为什么一定要去top的行业去实践，也是同样的常识。对于没有明确兴趣和职业方向的年轻人，top的行业是能帮忙迅速完成鉴定的。这就比如年轻人当初一定要去一线大城市，就是想去见识下，不为别的。是骡子是马，在top行业溜一圈就有底了。 产品方向过去几年在技术岗没有明显成就，所以快30岁就考虑转产品岗位了。这真是一个危险的信号。以前的解读是，反正技术不会干一辈子，总要横向扩展。实际上，相比单纯的技术方向如果不出众，转产品岗只会越走越低。因此，年纪的危机感也加重了。不再像一个初出茅庐的年轻人愿意去挑战，而是求安稳的心态。越缺少专注，越容易被不重要的问题困扰。记得刚回来找工作，我对薪资待遇是念念不忘，而不在能做成什么事。现在要保持一个学习者同时给企业创造价值的心态。 很多朋友了解我不到30岁，都觉得有些问题考虑的过早了。应该继续放手搏一搏。长线来讲，现在还是积累的年纪。选择回避，去一个非技术的岗位、去一个二线城市、甚至换一个不知深浅的行业，都不是明智的。 也不要思考这种弱智问题，诸如，35岁以后干什么呢？ 以前很擅长谈vision, 没有行业积累，不能低下去踏实做事情，会是回国就业的障碍。 阿里巴巴，2018年统计员工9万，其中85%月薪资在20k ～ 50k 腾讯，2017年统计员工人数4万，其中88%月薪资在20k~50k 百度，2017年统计员工人数近4万，其中70%月薪资在20k~50k 滴滴，2019年统计员工人数为1.3万，其中71%月薪资在20k～50k 华为，2017年统计员工人数为17万，其中55%月薪资在20k~50k 国内top行业和行业top公司的薪资情况，half million的样子。回归常识吧。 参考，OEM自动驾驶研发工程师薪资（年） 长城（保定） 30万 + 长安（重庆） 40万 + 吉利（杭州） 40万 + 广汽（广州） 35万 + 公司性质主机厂、外资供应商、国内领头互联网企业、创业团队，也都有接触到了。从最开始很happy有主机厂的offer，到慢慢听到猎头讲，国内oem的尿性。领头互联网内部也是小股作战，同时又有平台的优势；优秀的创业团队比较吸引资本，都非常棒。相比，外资供应商是体系成熟、个人自由、但核心内容不一定在大陆，所以适合做跳板，迅速完成积累然后跳出。]]></content>
  </entry>
  <entry>
    <title><![CDATA[未来5年在哪里(4)]]></title>
    <url>%2F2019%2F03%2F18%2F%E6%9C%AA%E6%9D%A55%E5%B9%B4%E5%9C%A8%E5%93%AA%E9%87%8C-4%2F</url>
    <content type="text"><![CDATA[如果衣食无忧、每天和快活的人在一起，谁还去努力奋斗呢。 – by me 从北京回来写下： 在一线城市的优势就是对政策的敏感，能够提早做布局。相比，三四线更多是跟随和被影响。 上层可以很自然向下扩展，但下层很难上去。不论是产品、概念、服务。比如，提到英语培训机构，会想到 新东方，而不会是 钟祥少儿英语。 新东方从北京发展到武汉市自然而然的；但定位在钟祥的少儿英语，甚至不会逆向到荆门。其他包括互联网服务业、造车新势力等等。 起点决定了发展上升空间。 底层会有很多直接面向终端人群的利弊。比如一个家电品牌在某村的供销商，必然跟当地人很熟。只是在中国只要发展到一定阶段，就会碰到“天花板”。造成这些地方（下层）的生意，处于一个“长不大也饿不死”的阶段。 底层的生意也容易受壁垒保护，毕竟除了概念、体制可以低成本渗透，企业运营管理要做到三四线是相当沉重的。所以，三四线可以肆无忌惮地复制品牌，或者同类小生意林立。比如，服装、餐饮等等。 之前考虑，为什么中国没有像Mc Donald’s, Wendy’s的全国连锁店，只看到了模式复制的成本。其实更深应该是两国体制不同。美国整体运营环境较为平坦；而中国是有上下层的。政治模式决定经济模式，所以，美国的品牌容易横向扩展，标准在哪里都可以建立；而中国的品牌都需要从上到下，游戏规则只会在上层建立。 一些不安分的理想青年，大约不想只参与游戏，被割韭菜，所以才要努力在现有的格局上捅窟窿。昌兄说，有朝一日，中国如美国，都是百年老店了，年轻人也就会逆来顺受，接受命运的安排，兴许人生也更轻松。 在三四线做点小生意，不求闻达于诸侯，苟且偷生不好吗？ 作为一个无产者，犯不上考虑这些问题。作为有产者，如何保证财产安全，就是底层忧虑的根源。对个人产权缺乏保护是任何奋斗且成功的青年都会担心的。而唯一的途径，就是通过更多途径赚钱，积累财富。雪球越滚越大，像一只无形的鞭子。受益者也许是国家，兴百姓苦，亡百姓苦。]]></content>
  </entry>
  <entry>
    <title><![CDATA[apollo planning module]]></title>
    <url>%2F2019%2F03%2F03%2Fapollo-planning-module%2F</url>
    <content type="text"><![CDATA[决策规划, 根据导航信息及车辆的当前状态，在有限时间内，计算出一条合适的轨迹。 Lattice Planner Sample candidate trajectories Assign costs Select lowest-cost trajectory, to satisfy constraint &amp; collision check in each cycle Output Frenet 坐标定义沿路面的一条光滑参考线（路面中心线）， 汽车位置坐标由纵向偏移量，横向偏移量表示。纵向坐标，由汽车质心在参考线上的投影点，到参考线起点的长度s表示；横向坐标， 由投影点到汽车质心的距离l表示。 在Frenet坐标下，汽车的朝向、速度、加速度可由横、纵向偏移量的一阶导、二阶导表示。另外，由车辆动力学控制方程可知，横向的偏移量变化率与纵向速度相关，即横向运动是由纵向运动诱发的。 生成轨迹分别由初始（当前）横向、纵向的状态信息（位置、速度、加速度），和下一时刻的横向、纵向状态信息（位置、速度、加速度），可以得到Frenet坐标下的一个轨迹点。通过一系列的时间点t0，t1, … tn, 可以得到一系列的轨迹点p0, p1, … pn， 即形成一条轨迹。 轨迹集合采样轨迹采样，本质上是通过在解空间随机布点，然后贪婪搜索，筛选最低cost function value的点，即为可行轨迹。 横向偏移量由动力学方程可由纵向偏移量唯一决定，即从控制方程上，每个scenario可以变成由纵向偏移量当唯一自变量的控制方程，从而保证有唯一最优解或者无解。但实际上，由纵向偏移量唯一表示的控制方程，需要满足不同scenario的约束条件，即一个带约束条件的优化问题。随机算法是一个鲁棒性很强的方法，而且大部分情况下，至少可以得到一个可行解。apollo中横向轨迹、纵向轨迹分别采样。 apollo的横向轨迹的采样，由内部自定义三种横向偏移量： -0.5， 0， 0.5； 同时，设计到达这些横向偏移量的纵向位移： 10， 20， 40， 80. 两层循环即可得到一个轨迹集合。由此定义的横向轨迹不一定符合运动学、动力学约束。 apollo的纵向轨迹的采样，考虑巡航、跟车、超车、停车等scenario。 比如，巡航场景，通过两层循环采样。外层循环将速度从零到速度上限按等间距均匀遍历，内层循环由1s-8s均匀遍历。对于停车的场景，末状态的速度、加速度是0. ST-Graph横坐标是时刻，纵坐标是障碍车的车头、车尾的位置。st图将描绘障碍车进入当前车道到离开当前车道所占据的位置区域。自驾车必须确保与障碍车所占据位置有重合。跟车，即在被占区域的下方，或超车，即在被占区域的上方。 由跟车或超车，即可采样各个时刻的纵向偏移量，然后同理横向偏移量采样，形成纵向轨迹集合。 轨迹cost轨迹规划的约束条件： 达到目的、 横向偏移代价（尽量沿着道路中心行驶）、碰撞代价、符合交规、平稳舒适（横向加速度代价）、 纵向加速度代价（激烈加速）、向心加速度代价（转弯场景）。 对于换道场景，对当前车道、目标车道的参考线做一次采样，并找到最低cost的轨迹。可以设计换道cost 。 EM plannerexpectation maximum(EM) ， 最大期望算法，在概率模型中寻找参数最大似然估计或最大后验估计，其概率模型依赖于无法观测的隐性变量。 首先，计算期望（e)， 利用对隐藏变量的现有估计值，计算其最大似然估计值；然后，最大值m， 最大化在e步上求的的最大似然值来计算参数的值。step-2 的参数被用于下一个 step-1 的计算。 em planner 会迭代对路径path、速度velocity进行优化。基于当前步的path和对其他运动物体的预测，优化当前步的速度；然后基于这个新的速度，再优化path。迭代直到收敛。 EM Planner 相比 Lattice Planner，利用了更多当前时间步的状态信息，在每个local timestep 都得到一个可行解。一系列的局部解，相当于弱形式，如果解空间存在可行解，局部解的迭代最终也将给出系统的可行解 12345bool Plan(const common::vehicle_state::VehicleState &amp;vehicle_state, const bool is_on_auto_mode,const double publish_time, std::vector&lt;common::TrajectoryPoint&gt;]]></content>
      <tags>
        <tag>apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[apollo control module]]></title>
    <url>%2F2019%2F03%2F02%2Fapollo-control-module%2F</url>
    <content type="text"><![CDATA[纵向控制通过控制刹车、油门实现对车速的控制。由一个级联控制器和标定表构成。级联控制器包括：位置PID闭环控制器， 速度PID闭环控制器。标定表即速度-加速度-刹车-油门命令 标定表。 123456Status LonController::ComputeControlCommand( const localization::LocalizationEstimate *localization, const canbus::Chassis *chassis, const planning::ADCTrajectory *planning_published_trajectory, control::ControlCommand *cmd) 其输出是油门\刹车命令cmd. 位置PID闭环控制器输入变量：期望位置 + 当前实际位置 输出变量：速度补偿量 速度PID闭环控制器输入变量：速度补偿 + 当前位置-速度偏差 输出变量：加速度补偿量 速度-加速度-刹车/油门命令 标定表输入变量： 加速度补偿量 + 规划驾速度， 车速 输出变量： 油门／刹车控制量 1234void LonController::ComputeLongitudinalErrors( const TrajectoryAnalyzer *trajectory_analyzer, const double preview_time , SimpleLongitudinalDebug *debug) CarSim/Simulink 与 apollo 连结 ？ 横向控制通过调节方向盘转角实现对航向的控制，由一个前馈控制器和反馈控制器组合，实现车辆动力学模型和lqr 模型。 12345Status LatController::ComputeControlCommand( const localization::LocalizationEstimate *localization, const canbus::Chassis *chassis, const planning::ADCTrajectory *planning_published_trajectory, control::ControlCommand *cmd) 前馈控制器输入变量：道路曲率 输出变量：方向盘前馈控制量 前馈控制变量实现补偿道路曲率对稳态误差的影响。 反馈控制器输入变量： 期望航向角 输出变量： 方向盘反馈控制量 12345678910111213141516171819// update status matrix void LatController::UpdateStateAnalyticalMatching( SimpleLateralDebug *debug)// cal lat error double LatController::ComputeLateralErrors( const double x, const double y, const double theta, const double linear_v , const double angular_v, const TrajectoryAnalyzer &amp;trajectory_analyzer, SimpleLateralDebug *debug)void LatController::UpdateMatrix() void common::math::SolveLQRProblem() // gain matrix steer_angle = steer_angle_feedback + steer_angle_feedforward 控制模块更新cmd 后，发送给canbus模块。 MPC 模型mpc的实现依赖于过程的动态模型。对时域内，每个当前时刻进行优化，求取每个时刻的最优控制解，从而得到整个时域的优化解。 基于线性化的预测 实际系统状态-控制方程（系统状态变量、控制变量）具有时域非线性（二次项等）。首先对该系统进行线性近似，从而可以实现通过当前状态变量、控制变量对下一个时刻系统状态和控制的预测。 滚动优化 设计符合约束条件的目标函数，为状态、控制的离散的能量二次方程。优化的目标就是在每个时刻，寻找最优控制变量，使得目标函数最小。MPC相当于给出每个时刻的局部最优控制值，整个时域的最优控制就是一个控制序列。 控制更新 每个优化的输出即每个时步的控制增量，用于更新当下时步的系统控制变量。 LQR 模型lqr 给出时域系统的全局最优解， 其目标函数是积分函数。相比较，lqr 相当于加权伽辽金方法，给出弹性体的全局最优解，对应强形式的控制方程，解空间非常狭小，甚至不存在。而mpc 相当于有限元方法，给出弹性体每个单元的局部解，对应弱形式的控制方程，每个单元的解空间span可张。理论上弱形式在极限情况给出的解就是强形式的解。 数值方法上，lqr相当于直接法，mpc相当于迭代法。直接法给出控制方程的唯一真实解；迭代法给出近似解，但近似解可收敛到系统的真实解。 车辆模型运动学模型给出车辆纵向控制变量，即车辆模型刚体质心参考点及航向角的控制方程；动力学模型给出车辆横向控制变量。 由运动学和动力学模型给出了整车状态-控制方程，采用mpc or lqr 算法求解控制变量，即实现车辆控制。]]></content>
      <tags>
        <tag>apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自驾初创团队]]></title>
    <url>%2F2019%2F02%2F26%2F%E8%87%AA%E9%A9%BE%E5%88%9D%E5%88%9B%E5%9B%A2%E9%98%9F%2F</url>
    <content type="text"><![CDATA[name CEO start-date business funding 宏景智驾 刘飞龙(北美oem 背景） 2018-8 L4 Tier1供应商 天使轮 ¥4千万 赢彻科技 翟学魂 2018-9 临港物流 - 拓疆者 隋少龙（北美背景） 2018-4 无人挖掘机 - 驰加科技 王明彦（国内oem 背景） 2017-10 低成本后装解决方案 - plus ai 刘万千 2017-3 AI 方案？ - 纽励科技 徐雷（特斯拉） 2017—1 视觉方案 ？ - momenta 曹旭东 2016-7 视觉方案 c轮 $2亿 极木科技 祁卫（亿航） 2016-7 机器人方案 - 驭势科技 吴甘沙(intel) 2016 芯片方案 ？ - 易航智能 陈禹行（吉大） 2015-8 汽车动力学、控制软件 b轮 ¥2.2亿 青飞智能 孙一飞（上交） - 园区短距自驾解决方案 天使轮 ¥千万 环宇智行 李明（武大） 自驾解决方案 天使轮 ¥千万 行深智能 安向京 - 自驾整体解决方案 - 畅行智能 张祖峰（苏州清华） 物流自驾解决方案 天使轮 ¥千万 图森未来 陈默 2015-8 自驾卡车、视觉、ai d轮 $0.95亿 纵目科技 唐锐 2013 环视adas供应商 c轮 ¥1亿 禾多科技 倪凯（清华） 2017-3 L3.5 自驾解决方案 a轮 $千万 牧月科技 杨庆雄（景驰） 2018-6 - 天使轮 ¥5千万 深兰科技 陈海波 2012-8 ? a+轮 ¥3亿 武汉光庭 朱敦尧 2011 智能网联 上汽并购 主线科技 张天雷 2017-3 港口卡车（天津港） - 创昂tron 邓恒（国内oem 背景） 2018-4 天使轮 $百万 畅风加行 ？ 2018-4 L3 解决方案 - 小马智行 楼天城 2016-12 ai ? a+ 轮 智行者 韦忠亚 2015-5 ？ b+ 轮 鹰驾科技 郑智宇 2015-8 adas 视觉软硬件 a轮 ¥千万 盟识科技 邱长伍 - 矿山、港口、园区自驾解决方案 - 飞步科技 何晓飞（滴滴） 2018-4 车载 ai 系统 - 文远知行 韩旭（百度） - - a+$千万 拿森电子 陶喆 2016-3 汽车电控 b轮 $1亿 auto brain 李明喜 2017-5 自驾解决方案（长城合作） - 踏歌智行 余贵珍（北航） - 特定场景自驾解决方案 pre-a ¥千万 云天励飞 陈宁 - 视觉 ai 芯片 - 有光科技 朱积祥 - 图像方案 - 云洲智能 张云飞 - 无人船 c轮 ¥4亿 西井科技 谭黎敏 - ai 芯片，智能医疗、港口 自动驾驶供应链中，ai算法、芯片、传感器（毫米波、激光、相机）等创业公司不计，传统主机厂、供应商内部相关团队不计。独立的小股团队也不计。直接把自动驾驶解决方案当作团队vision的有将近40家公司，分别来自电子芯片、人工智能、传统主机厂等不同背景。 每年估计烧十几个亿，市场还是有很多热情。2019年也许会死掉很多。另外，对市场时机需要敏感。几个海龟团队都是2018年才开始的。]]></content>
  </entry>
  <entry>
    <title><![CDATA[apollo self driving car]]></title>
    <url>%2F2019%2F02%2F22%2Fapollo-self-driving-car%2F</url>
    <content type="text"><![CDATA[apollo self-driving carHD mapswhere to define the center-meter fidelity level maps, with landmarks, and even the height dimension as well, which is used as the guiding map and also the global coordinate to locate the vehicle in the world. how to keep HD maps updated is a big invest. Baidu has hundreds service cars in China to collect the natural highway HD map data, even still to 2020. LocalizationSLAM tech is a robot maping the world at the same time localizing itself in the world. with HD maps prepared first, self-driving car only need localize itself at every timestep. and the common idea is comparing a few local landmarks with the corresponding global landmarks, then transfer the local vehicle position to its global position in HD map. LiDAR localization either based on the cloud points matching from continous timestamps; or calculating the error between the LiDAR points with the HD maps points; or based on the Karman filter, which give the highest possibility of the location of vehicle always accessible but not easy to construct, especially requiring HD maps. Visual localizationbased on particle filters, which give the most likely location of the vehicle. Perceptiondetection &amp;&amp; classificationwhere the object located, and classify it. detection CNN to find the object in the image; then use classification CNN to classify it. or use a combined CNN to detect and classify at same time. trackingtracking helps when detection failed; also tracking helps to identity the object, so when objects overlapped in the image, still can tell which is which. Predictionmodel based predictiondata driven predictionafter prediction, then generate the trajectory. Planningtransfer the world to graph, and find routings in the graph. routing is a global path, comparing to trajectory is the local way. Vehicle controllinear quadratic regulator PID model predictive control]]></content>
      <tags>
        <tag>apollo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where am I in next 5 years(6)]]></title>
    <url>%2F2019%2F02%2F14%2Fwhere-am-I-in-next-5-years-6%2F</url>
    <content type="text"><![CDATA[things changes faster than I expected, already in China for two weeks. The first few days with family, that was precious, and the last spring festival at home was 5 years ago. life in ChinaI am searching jobs in China now, the recruiters are highly efficient. almost in 24hrs, a reply return; and they prefer wechat rather than email, Liepin ranther LinkedIn. on the other hand, I went to tongji hosptial at Wuhan for a doctor appoitment, but stay in the line waiting most time. People are everywhere, even in a third-class city, like my hometown, I can only find two caffe shop to sit down and use the free wifi; the skyline buildings are everywhere, the evening scene feel like in the movie: Matrix. in USA, I never touch the real China, which is attracting but concerned. As many of my friends in USA, we always talking about China, but never take a move back to China. Till the moment I stand in China, things are real. In general, if people looking for a stable middle-class, USA definitely is a better choice, with few career pressure, 8 hrs a day, 20 days PTO a year, large house with green grass, and income is about 2 times highly as the same engineering in China, without considering 996 in China. people back to China must think big, rather than looking for a stable income. self-driving in ChinaOEM level: Changcheng, Audi, Volkswagen, Geely, xiaopeng, Beiqi, and many names I few heared before, are investing in new energy, intelligent vehicles, and self-driving cars and expending, the market sounds high to hell. there are about 500 start-ups focusing on component supply chain, e.g. in-vehicle sensors, network communication infrastructure, platform solutions, AI algorithms to chips design, specilized scenario applications(mining, seaport, airport, logistics, warehousing, city bus, city-cleaners) it was the best of times, it was the worst of times. many start-up companies will die so sure, but the market is the training course for next BIG. The second half of 2018 is my time to feel everything is accelerated.]]></content>
  </entry>
  <entry>
    <title><![CDATA[review planning pipelien in self-driving car]]></title>
    <url>%2F2019%2F01%2F22%2Freview-planning-pipelien-in-self-driving-car%2F</url>
    <content type="text"><![CDATA[when understanding planning in self-driving car, all other modules make sense. perception layerwith all concepts such as lidar, radar, camera, sensors, GPS, CAN, data fusion, computer vision, SLAM, AI-based detect/tracking algorithms, they are all perception related, which helps the car to understand itself and the surroundings. perception first helps the car understand itself located in the world; then helps to predict the intensions of other vehicles/pedestrains around. behavior layerthere are two steps here: behavior predictation, behavior planning. based on the prediction info of other agents intensions from previous timestep/configuration, the behavior predictation module predicts current behavior of the self-driving car, which usually implemented either by model based methods or data driven method (AI-trained), and which output all the possible feasible maneuvers for current timestep. the car choose only one maneuver at each timestep/configuration, and the behavior planning module is used to weight all the feasible maneuvers from the behavior predictation, and find the most-likely maneuver, which usually is implemented based on a cost function with constraints. the all possible manuever is also called trajectory planning, and the choosen manuever is also called motion planning, which is locally-space and time-depended. control layersince motion planning, then send the command to vehicle control actor and update the car physically. end-2-end motion planningdeep learning is also used to demo end2end motion planning. e.g. from camera output to vehicle control output frame to frame, while many situations may not be trained in the model, so not that realisty. path/routine planningthe motion planning pipleline above is happening every timestep for self-driving car and locally. at high-level is path/routine planning, bascially given the start point and destination point. there are a few algorithms, like global graph search, random tree, incremental graph search. reinforcement learing in simulatorprevious blog, it is also popular to learn behavior in simulation environement and train with reinforcement learning. simulation in self-drivinghow simulation tool chain can accelerate self-driving development ? usually simualtion enviornemnt can help to verify and test the perception, behavior, control algorithms. if working with reinforcement learning, a virtual simulator is required also. what else ?]]></content>
      <tags>
        <tag>self-driving</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where am I in next 5 years]]></title>
    <url>%2F2019%2F01%2F21%2Fwhere-am-I-in-next-5-years%2F</url>
    <content type="text"><![CDATA[I love reading autographies, especially these with life-time stories. it’s a window to explore kinds of life possibilites. and recently I readed &lt;&lt; the only girl &gt;&gt;, Robbin at Rolling Stone magazines in 1970s. I remember some toughts about life meanings. there are three kinds: 1) to crazy satisfy yourself, or pursue a free life, live the way you really want. e.g the freelancer; 2) ladder up to the higher social class, which is happening a lot in developing countries, and to be rich and success is the guarantee; 3) enjoy the beauty of nature and civilazation in this short period of life time. the last two meanings can not be done immediately, to crazily or desperately satisfy self, is then the easiest way to fight against the fucking environment. like when getting tired of this busy world, I behave more like a hippie, no big deal to anything, and kill time on drama, books, or drugs or sex. the hippie lifestyle is momental, it creats a space to seperate from daily troubles; after a few days or nights, I am back to real life, continuing on career stuff. so take it, the reality for me, as born in Asian developing country, with traditional family responsibility, is pursuing career, and of course it helps to take a break, and enjoying hippies, but don’t take it as the life-time way. mostly of my inner voices are: either busy to live or busy to die; problem-solving skills, leadership; to figure out how the economy machine functions in small and big roles; and be the smart guy in market and at office. and no need with another degree or matured platform to be problem-solvingable or leadershipable. these skills are in everywhere.]]></content>
  </entry>
  <entry>
    <title><![CDATA[未来五年在哪里（3)]]></title>
    <url>%2F2019%2F01%2F13%2F%E6%9C%AA%E6%9D%A5%E4%BA%94%E5%B9%B4%E5%9C%A8%E5%93%AA%E9%87%8C%EF%BC%883%2F</url>
    <content type="text"><![CDATA[在美国开长途，沿途总是遇见wendy’s, McDonald’s， auto zone 等等连锁店。也不论在toledo等中部小城市，还是芝加哥、纽约等国际大城市，这些店也到处都有。甚至costco商店在底特律，布法罗，哥伦布，三番等城市的商品布局摆放都是一摸一样的。 中国很少有这种在从三四线城市到一线城市都连锁的服务品牌，除了重资产的，比如商业地产（万达广场）， 酒店，大型购物超市，阿里仓库，烟草局等。而餐饮、汽修、家装等等基本都是地方特色。 美国各州相对很独立。比如，buffalo wings 从布法罗开到了全美国， kfc 从肯塔基开到了全美国。把产品、模式从一个地方复制到另一个地方很容易实现。而且不仅产品本身，其背后的供应链也同样反映了平坦。所以是整个体系很成熟，容易实现规模效益，从而正向强化成功。 中国地方性壁垒比较高，一个成功的产品、模式难轻松复制。好处是发展了很多地方性的特色服务。当然对资本而言是不经济的。好奇麦当劳进入中国，是怎么做供应链的，如何在不规范、体系不成熟的环境下复制美国模式的。 一个顶级成功的商业，应该是建立系统。然后，利润就在系统运营和管理中流淌出来。就像顶级的造车公司，是能够把研发、生产、销售等subsystem打通，建立一个造车system的公司。这也是matured market 的特征，系统成熟运作，利润稳定地流淌。emerging market 就处于探索建立系统的过程。一般是从新科技、产品subsystem出发，因为商业模式、市场等subsystem比较好从已经有的成熟体系里借鉴，然后融合、打通。 中国出现了两种特有的经济行为：外卖和淘宝。他们的价值就是打通原本因为地域壁垒很难复制的产品。互联网不存在地域壁垒，所以有效最优化资源，并实现规模效益。相比，美国不存在大范围的外卖、淘宝，因为产品复制在地域上很容易。 商业的本质，就是建立一套稳定运转的系统，不论中美。因为美国的资本、商业环境、企业规范、地方行政等方面的成熟，即游戏规则已经稳固且清晰，成功是更容易的。相比，在中国，就需要官商结合重资本打开局面。因此在中国，赚大钱更容易。]]></content>
  </entry>
  <entry>
    <title><![CDATA[未来五年在哪里(2)]]></title>
    <url>%2F2019%2F01%2F04%2F%E6%9C%AA%E6%9D%A5%E4%BA%94%E5%B9%B4%E5%9C%A8%E5%93%AA%E9%87%8C-2%2F</url>
    <content type="text"><![CDATA[很多汽车公司（供应商，oem）都有大量职位招：CAN, control, EE 背景的同学。相反，cae产品却很少出现在供应商的招聘中。先给个预判：汽车电子处于草莽时代。 汽车电子首先，汽车电子，不论硬件、软件，都很面向产品。出来的直接可以拿到市场去卖。另一方面，这类产品又很成熟，不论是电子元器件，汽车网络，摄像头等传感器，控制算法都不是新技术，而更像是一次“组合创新”。基于已有部件，在新的应用场景，重新组合，研发需求本身很低。 即使前沿应用场景，比如自动驾驶，其实是需要重新定义很多基础部件，包括通信协议、ai算法、传感器的融合、路面设备等，必然有很多研发需求，但目前的自动驾驶大多在现有adas基础上的迭代，还没有真正的超越。 另外，因为各个终端产品的差异性，市面上会出现各种解决方案。这是一个行业的草莽时代，各家都自立山头。还没有出现几家鼎力。 由于应用层的需求，而不是研发需求，汽车电子需要熟练的软件/硬件工程师去拼装产品。这也是ME, EE偏控制方向的同学，在汽车行业就业的窗口期。 汽车CAECAE行业的黄金期是80年代到2000年，当时也是各个解决方案在市场上乱飞，甚至应用商（汽车厂等)内部都有独立的CAE开发团队，而且做了很牛逼的产品。那个年代，CAE算是emerging tech，很吸引投资和就业。到现在，这样的窗口期已经结束，北美几大CAE厂商三足鼎立： 加州msc, 密西根altair, 匹兹堡ansys，还有一些小众厂商。还有就是更大只的PLM厂商： 西门子， 达索等。 整个行业处于成熟期。产品的研发、市场、客户都已经形成了模式。应用行业也基本稳定，民用品：汽车、电子消费品、医疗等，军用：航空航天、核物理等。当然，未来会拓展新的应用领域，以及需求新产品研发。 虽然整个行业处于成熟期，进入门槛很高了。实际上，如果不在大厂里，CAE还是辅助的。有接触到设计制造供应商，都会使用CAE分析，但经常是Design engineer 顺带跑一下cae分析。也可以看到供应商更需要直接面向产品的设计工程师，而不是CAE应用工程师。 大厂里面有CAE研究部门，尝试新的分析场景；CAE支持部门，包括部署、debug、用户支持；以及CAE工程师。]]></content>
  </entry>
  <entry>
    <title><![CDATA[未来五年在哪里]]></title>
    <url>%2F2018%2F12%2F21%2F%E6%9C%AA%E6%9D%A5%E4%BA%94%E5%B9%B4%E5%9C%A8%E5%93%AA%E9%87%8C%2F</url>
    <content type="text"><![CDATA[两种思维不同的思维反映了不同的背景。面对一个商业想法，一个对细节严肃的工程师，首先会估量自己对讨论的领域是否足够熟悉，然后会考虑技术上是否可行。马云说他是阿里巴巴最不懂技术的人，却能够把握大方向；相反往往问题没解决，责怪技术不够的，会陷入用一个技术解决另一个技术的游戏中，而远离了大方向。 张首晟教授有分享在知识信息爆炸的时代该怎么学习。因为最优秀的书籍也已经多到一个人一辈子都读不完了，所以重要的是抓住道(principle)。举个极端的例子，如果地球毁灭，最后一个人只能带1kb 的信息离开地球，这个信息该是什么，能够保证人类文明不断流。 道与术的例子， 日本远海70公里发生了地震，多久巨浪会到达海岸线？一个细节严苛的学流体力学仿真的研究生，要跑一套cfd程序，考虑近似若干边界初始条件，然后花一两天调试，运行得到结果。而一个有物理常识的人，大概能估计几个跟巨浪速度有关的变量，就可以得到一个近似结果。 我的经验就是太容易过分依赖技术（本质是一种惰性，想回避该用人脑的分析），而忘了新技术的初衷，单纯为了迭代技术本身而发展新技术。世界正在把太多新技术太快速地塞进普通人的视野，不要说思考这些新技术到底意味什么，甚至这些新技术到底将如何产业化，进入普通人的生活都没有清晰。 很长时间，我对工程仿真技术有这样的误区。我已经忽略了cae本身要解决的问题，而只是沉迷在cae技术本身。或者说是，从研究（学生）到商业（职场）的角色没有转变过来。而商业需要的是一个能够打穿新技术与产品落地。他／她可以不懂技术的深度，但一定有广度和连结，能觉察到新技术可以在哪里发挥价值。 越来越感受到，思维会决定行为，而具有倾向性的行为会强化思维。一个没有商业经验的且受过高等技能教育的年轻人，会倾向强调技术，放大其重要性，而看不到其在企业经济大方向上的不合理性。比如，工程师倾向使用最新的技术在产品开发中，但企业定位可能是一款廉价快速打入市场的产品。这时候，在工程师看来完美的合理方案，于企业战略就是不合理的。 emerging market emerging matured platform start up large business management new matured involving multi-role single-role stability high-risk low-risk working env shining mediocre creativity knowledge-based manage-based 由新知识引导的商业创新，比如，生物科技，基因技术，新材料，量子计算，人工智能，核物理等，首先很容易给人带来极大的快感，特别让年轻人欲罢不能， 更吸引投资、社会关注。但是，emerging tech存在周期性：从新技术到产品的会有很长的空窗期。历史上电气时代（1830 - 1860年），在爱迪生开发电灯泡之后，数百家电气公司迅速出现，但20年内大部分被淘汰掉；铁路公司，PC电脑, 汽车制造，消费电子，包括最近的AI、自驾车行业，都体现着emerging market的规律：早期快速极度膨胀，然后几年内极度跌落，再慢慢恢复理性。 经济学上还有一个概念，就是新技术带来的就业远不能弥补旧行业消失造成的失业。时间久了，emerging market也会成为matured market。 团队选择emerging tech非常强调先发优势。很多新知识引导的商业创新，源自学校研究第一梯队，他们本身就是某项技术的原创团队，具有极强的先发优势，而且因为新知识门槛，被市场快速复制的可能性极低。比如，机器人、柔性可穿戴电子器件、基因检测、ai等等。 普通人的第一次团队选择，大多是在高校完成的。聪明人跟对了团队，在博士期间就可以引领emerging market。《新资本论》中提到，21世纪，劳动力与资本收益分配是1:7。 稍微感受下，知识经济将明显比资本有更高收益。 如果错过了第一次团队选择，普通人很难有后发优势，没钱没技术。所以，除非对该领域具有极强的认同感，执着的信仰，否则想在创业团队谋一份职业，可能是误判。 现实与认知之间的矛盾，往往反映一个人还没成熟。我的假象包括：创业团队更锻炼人，更吸引眼球，站在风头浪尖上，然而没有一个因素是因为我对该领域的认同感，不过是渴望它附加的虚荣。另外，个人成长动力不该仅源自环境，而必须是内心。环境在满足基本需求后，只叫人不讨厌它了；但爱上它，必须是从心发出的。 普通人的第二次团队选择，大多是在职场完成的。明确自己该要什么，不该要什么，也许对普通人选择matured market更友好。一方面是老生常谈的大企业病：成熟平庸。但是，创新成功并不都是声名噪动，也有闷声发大财。 成熟行业或成熟企业的创新，也许不是产品／技术本身，而在体系和管理。 而在一个成熟行业待不少于5年，才有可能了解系统，接触到管理。写到这里，不由又盘算要不要读MBA了，正好遇到明年经济糟糕。 – 感谢Selena]]></content>
  </entry>
  <entry>
    <title><![CDATA[insertion sort list]]></title>
    <url>%2F2018%2F12%2F18%2Finsertion-sort-list%2F</url>
    <content type="text"><![CDATA[leetCode 147, this is another example when solving problem, either find a good data structure, which looks like stand in a higher dimensions with additional DOF, or define the routines on the given data structure. additional set123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657struct classcomp &#123; bool operator() (const ListNode* lhs, const ListNode* rhs) const &#123;return lhs-&gt;val &lt; rhs-&gt;val;&#125;&#125;; class Solution &#123;public: set&lt;ListNode*, classcomp&gt; labels ; ListNode* insertionSortList(ListNode* head) &#123; while(head)&#123; labels.insert(head); head = head-&gt;next ; &#125; head = labels[0]; ListNode* node = labels[0]; for(int i=1; i&lt;labels.size(); i++)&#123; node-&gt;next = labels[i]; node = node-&gt;next ; &#125; return head; &#125;&#125;;``` basically `unordered_set` has ordering by default, so how about first inserting each element from the list to set, then set the next pointer for each element, which take additional space, but did the job straight forward ## single linked listsince single linked list can't access the previous node, so define prev pointer and current pointer, and every insertaion needs do the compare from frist element to the previous element. ```c public class Solution &#123; public ListNode *insertionoSortList(ListNode *head)&#123; ListNode *result = nullptr ; if(head == nullprt || head.next = null)&#123; result = head ; return result ; &#125; ListNode *dummy = new ListNode(0); ListNode *cur = head ; ListNode *next, *pre; while(cur != nullptr)&#123; next = cur-&gt;next ; pre = dummy ; while(pre.next != nullptr &amp;&amp; pre.next-&gt;val &lt; cur-&gt;val)&#123; pre = pre.next ; &#125; //return the position where cur node should insert cur-&gt;next = pre-&gt;next ; pre-&gt;next = cur ; cur = next ; &#125; &#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lru cache design]]></title>
    <url>%2F2018%2F12%2F18%2Flru-cache-design%2F</url>
    <content type="text"><![CDATA[leetCode 146, for non-CS background, this kind of problem is out of mind, what is talking about, but I know at all it is about design a data structure to meet some requirements: first a hash map data structure for key, value operations, e.g. get(), put(); but normal hash map can’t track the most recent used element, so either find a data structure, which can track the recently used element in the hash map; or define some routines to do it. a data structure to catch recently usedeach get(), put() will operate on one special element, and that element should be marked as recently used, and the next element is the least recently used element, which can be overlapped in next operation. stack and queue have some property to track the most recent element, but they are one-way, not straight forward to manage two neighbor elements. double linked list is a good choice to track both the most recent element and the least most recent element. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950struct node&#123; int val ; int key ; Node *pre ; Node *next ; public Node(int value_, int key_) &#123; val = value_; key = key_ ; pre = NULL ; next = NULL; &#125;&#125;class LRUCache &#123; public: list&lt;node*&gt; recent ; unorder_map&lt;int, node*&gt; hash ; int capacity ; LRUCache(int cap): capacity(cap) &#123;&#125; node* get(int key)&#123; if(hash.find(key) != hash.end())&#123; recent.remove(hash[key]) recent.push_front(hash[key]); return hash[key] ; &#125; return -1 ; &#125; void put(int key, int value)&#123; if(hash.find(key) != hash.end())&#123; recent.remove(hash[key]); hash[key] = value; recent.push_front(hash[key]); &#125; node* tmp = new node(value, key); hash[key] = tmp ; recent.remove(tmp); recent.push_front(tmp); if(hash.size() &gt;= capacity)&#123; node *tmp2 = recent.back(); hash.erase(tmp2-&gt;key); &#125; &#125; &#125; routines to track recently usedin this way, the hash is still needed, but define routine to set the latest updated node always at front. void setHead(Node* n){ n.next = head ; n.pre = null ; if(head != null) head.pre = n ; head = n ; if(end == null) end = head; //only 1 element } when solving real problems, either has a good understand about special data structure, which can solve this problem, or the raw way is to implement routines based on the exisiting input]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where are you in next 5 years (4)]]></title>
    <url>%2F2018%2F12%2F18%2Fwhere-are-you-in-next-5-years-4%2F</url>
    <content type="text"><![CDATA[in the nude“only after the tide has faded, know who is in the nude”, the wise said. distributable resources(social relationship, capital, core tech, market vision) define the success of a man in the world. in normal days, people feel good about themselves, like they can take things in control and looks well, these factors are ignored, and crisis is under the hood; when situation changes, the crisis appears, then people feel unexpected surprise. how crisis is so close along with us for a long time, and get igored for a long time ? another word, “standing in the wind, elephant can fly to the sky”, when market is good, normal people make money from stock. it is not him become smart, worse he is not prepared for the coming bad times. with no money, no social relations, and no core tech standing in the world, I should be humble to dirt, rather talking like everything is in control. for many young immigrants, the breakthrough is through education and learn core skill, and earn money and gradually being successful. this evening, watched Jack Ma speech, some ideas: in age 20 - 30, the best thing is to find a good boss and learn from him or the team; from age 30 - 40, try something for yourself, either to start a business or go for a art design degree; from 40 - 50, make sure to do things yourself most good at. life is previous and short, no waste. find out my contribute to the world, and do it. the right thingI shared my thoughts with a friend, that I thought AV was the future in vehicle industry, so even though I had no experience in control algorithms, computer vision, sensor hardware, I will find a way in; on the other side, I am pretty familiar with CAE software products development and applications, how I choose ? my friend said, neither. job is to make money. Have to say, I am still focusing too much on the strong or the weak, the right or wrong. spent too much energy to find the line to divide future into simple right choic and wrong choice. I remembered another good friend, said I am used to pre-define or label people, but forget every similar story could have many different reasons and results. if there is a unique right thing in the world, then everyone must follow it, but since the right thing/decision for each person is different, even though the world drive people to be similar, I should realize in every situation, every step, it is ok to have a different right thing, rather than holding on the unique rightness]]></content>
  </entry>
  <entry>
    <title><![CDATA[word break with dfs & bfs]]></title>
    <url>%2F2018%2F12%2F17%2Fword-break-with-dfs-bfs%2F</url>
    <content type="text"><![CDATA[leetcode 139 dfstraversing string ,and split it one char by next, if find the splited left word in dict, recursiving the remaining right substring. in this way, it will make sure find a solution, but also traversing all unnecessary possibilites. and need design a class variable to stop the dfs() 123456789101112131415161718192021bool found = false;bool dfs(string s, unordered_set&lt;string&gt;&amp; dict)&#123; string left, right ; if(s.size() == 0 || s.empty()) &#123; found = true; return found; &#125; for(int i=0; i&lt;=s.size(); i++) &#123; left = s.substr(0, i); right = s.substr(i, s.size()-i); if(dict.find(left) != dict.end()) &#123; dfs(right, dict); &#125; &#125; return found;&#125;; bfsas mentioned above, dfs goes to all possibile branches, which is not required. bfs is like a greedy way, to find out one working solution and done. also need keep track of searched left sub-strings, since the remaining right sub-strings may can not find a matched from dict, then the left sub-string is not acceptable, so the left sub-string need move one char further. 1234567891011121314151617181920212223242526272829303132 bool bfs(string s, unordered_set&lt;string&gt;&amp; dict)&#123; int len = s.size(); string s1, q, left, right; queue&lt;string&gt; sq; sq.push(s); string tmp ; while(!sq.empty())&#123; tmp = sq.front(); sq.pop(); int i=0; s1 = s ; while(!s1.empty() &amp;&amp; i &lt;= s1.size()) &#123; if(tmp == s)&#123; left = s1.substr(0, i); right = s1.substr(i, s1.size()-i); &#125;else &#123; left = s1.substr(0, i+tmp.size()); ///will dead-cycle right = s1.substr(i+tmp.size(), s1.size()-i-tmp.size()); &#125; i++; if(dict.find(left) != dict.end()) &#123; q += left ; sq.push(left); s1 = right; i = 0; &#125; &#125; &#125; this bfs is not good design.a pretty simple sample code]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where are you in next 5 years(3)]]></title>
    <url>%2F2018%2F12%2F15%2Fwhere-are-you-in-next-5-years-3%2F</url>
    <content type="text"><![CDATA[at the end of 2018, I was lay off from GM after only a couple months. in the middle of 2018, I was planning to jump out from the traditional CAE group, to try the new autonomous vehicle. but a few things I missed when made that decision: the big environmenthow long will the traditional automotive industry stay in a sort of good shape? the answer now is not long. from Oct 2018, both Ford and GM publicly lay off over 15%, the vehicle market at both China and NA were significantly down from Q3; even earlier the manufactoring robotic supplieres mentioned their 2019 order were almost zero. so layoff employees is almost destined. in economics, consumer index is the reason, employment/unemployment rate is the result, not the reverse. and there is a delay from consumer index to unemployment, about 3 ~ 6 month. so when the market is done, a few month later, the unempolyment rate will show up. an even biggger environment, the trade war among China and USA raise the cost, fear both the consumers and the investors. not only vehicle market, consumer electronics (e.g. apple), internet(e.g. Google), retail industry(e.g. Alibaba) and as closely related to lologistics, chips, energy, housing, finance all go down. the winter is coming. Sooo scary, hate Trump ! new techs in vehiclefor a new stuff in market, the trend is starting extremely high, then low to bottom, then go to rationality. it happens to AI, autonomous vehicle(AV) market. starting from 2016, billions invest in, every step looks promising, revolution. but 2 years now, even Waymo said it can’t make AV in bussiness. on one way, OEMs can’t be lay behind, so buy startups, on the other way, they can’t all invest in AV, which has no mature market strategy. the more invest, the higher risk. for people who want to eat this AV cake, cold cold. how to face the changing worldhave to say, there is no well-prepared in this quick-changing world, plan is always out of date. at the middle of year, I thought I made the right decision to leave Ford CAE group, join GM autonmous group, now put myself in a poor situation. I usually have a mind, that this thing has to, must to be done in this and only this way; this situation is and has to be dealed in this and only this way; this person is and has to be treated in this and only this way. I know this is the poor mindset. they say “poor people make poor decisions”, thanks to warn me up. e.g. * so high risk to depend on one single incoming resource * no stable business, keep humble and keep foolish * be positive, be felxible.]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[clone graph with dfs & bfs]]></title>
    <url>%2F2018%2F12%2F14%2Fclone-graph-with-dfs-bfs%2F</url>
    <content type="text"><![CDATA[leetcode 133, the solution is traversing the graph, so either bfs or dfs should work. dfs works like a stack, take an example when processA is running, inside processB is invoked, then processA hang, and go into processB; as processB is running, inside processC is invoked, then processB hanged, and go into processC. e.t.c. so the finished order is from innerest to outest. dfs will always traverse all possibilities, then return to the outest layer. in clone graph, e.g. #0, 1, 2 #1, 2 #2, 2 dfs process as: first deal with first line, element 0, which trick element 1, so process goes to second line, and trick element 2, so go to third line(done), then return to second line(done), then return to first line, trick second neighbor 2 go on… bfs works different, during processA running, processB is invoked, will still run processA to done, but also push processB to job queue, which will run next time. so using bfs, usually has a queue variable to mark unfinished jobs. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 struct UndirectedGraphNode &#123; int label ; vector&lt;UndirectedGraphNode *&gt; neighbors ; UndirectedGraphNode(int x) : label(x) &#123;&#125;;&#125;;//graph traversing by bfsUndirectedGraphNode *cloneGraph(UndirectedGraphNode *node)&#123; if(!node) return nullptr ; UndirectedGraphNode *c_node = new UndirectedGraphNode(node-&gt;label); queue&lt;UndirectionGraphNode*&gt; qlist ; unorder_map&lt;int, UndirectionGraphNode*&gt; map; map[c_node-&gt;label] = c_node ; qlist.push(c_node); UndirectedGraphNode cur, neighbor = nullptr; while(!qlist.empty())&#123; cur = qlist.front(); qlist.pop(); for(int i=0; i&lt;cur-&gt;neighbors.size(); i++)&#123; neighbor = cur-&gt;neighbors[i]; if(map.find(neighbor-&gt;label)) &#123; c_node-&gt;neighbors.push_back(neighbor); &#125;else&#123; UndirectedGraphNode *tmp = new UndirectedGraphNode(neighbor-&gt;label); c_node-&gt;neighbors.push_back(tmp); map[tmp-&gt;label] = tmp ; qlist.push(tmp); //bfs idea: find new node, push it to queue and deal // with it in next while loop &#125; &#125; &#125; return map[c_node-&gt;label]; &#125; //dfs void dfs(UndirectedGraphNode\* node, unorder_map&lt;int, UndirectionGraphNode*&gt;&amp; map) &#123; UndirectedGraphNode * c_node = nullptr; if(!map.find(node-&gt;label))&#123; c_node = new UndirectedGraphNode(node-&gt;label); map[c_node-&gt;label] = c_node; &#125;else&#123; c_node = map.find(node-&gt;label); &#125; UndirectedGraphNode* nei; for(int i=0; i&lt;node-&gt;neighbors.size(); i++)&#123; nei = node-&gt;neighbors[i]; if(map.find(nei-&gt;label))&#123; c_node-&gt;neighbors.push_back(nei); &#125;else&#123; dfs(nei, map); &#125; &#125; &#125; UndirectedGraphNode *cloneGraph(UndirectedGraphNode *node)&#123; unorder_map&lt;int, UndirectionGraphNode*&gt; map; dfs(node, map); return map[node-&gt;label]; &#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[palinedrome partition with dfs & bfs]]></title>
    <url>%2F2018%2F12%2F13%2Fpalindrome-partition%2F</url>
    <content type="text"><![CDATA[parlindrome partitionleetCode 131 a sample code : 12345678910111213141516void dfs(int depth, string s)&#123; if(depth == s.size())&#123; v.push_back(v1); &#125; if(depth&lt;s.size())&#123; for(int i=depth; i&lt;s.size(); i++)&#123; //left substring if(palindrome(s.substr(depth, i-depth+1)))&#123; v1.push_back(s.substr(depth, i-depth+1)); dfs(i+1, s); v1.pop_back(); &#125; &#125; &#125; &#125; 1) each col in the table is one way to partition the string.e.g. aab. col_1 , left string a is palindrome, v1=[a]; feed right string ab to dfs(i+1, s)(depth=0, i=depth) 1 2 3 a a a a a a b b b 1.1) col1_1, left string a is palindrome, v1=[a, a];feed right string b into dfs(i+1, s) (depth=1, i=depth) 1 2 a a b b 1.1.1) b will push into v1, make v1=[a, a, b], feed into dfs(i+1, s) (depth=2, i=depth), which will return since depth==s.size(). the above dfs()(depth=2, i=depth) returned, the immediate next step is b pop out from v1; also now is the finished of dfs()(depth=1, i=depth), so the immediate next step is the second a pop out. 1.1.2) so now go to (depth=1, i=depth+1), push ab into v1, making v1=[a, ab] . but ab is not palindrome, return immediately, then pop out ab. 1.2) at this time, the very outside dfs()(depth=0, i=depth) is all done, so pop the first a in v1; and go to (depth=0, i=depth+1); then (depth=0, i=depth+2)… recursive of DFSanother example of recursive dfs. leetcode 129 sum root of leaf numbers dfs is used to find all the solutions, in a way to go through each branch in the same level first, then go into the next level. to traverse all solutions(branches), also need to mark traversing/traversed branches. so usually need: to push -&gt; current traversing element to pop -&gt; traversed element and a container to hold all solutions. if design recursive with returned value, consider the critical condition. e.g. what suppose to return when the last element, and usually design the returned value as local variable in each recursive function, rather than a global variable. one more thing is about the traversing direction, from left to right end, then when coding make sure the direction is consistent at all times. BFS to find mini cutsDFS is used to solve the kind of problem: traversal all possible solutions; leetcode 132 askes for the mini cuts, once find out the mini-cuts solution, done, no traverse all possibilities. 1234567891011121314151617181920// define done, cut as class member variable void bfs(string s, bool&amp; done)&#123; int len = s.length(); string left, right; int i =0; while(!done &amp;&amp; i&lt;len)&#123; left = s.substr(0, len-i); //starting from the longest left string right = s.substr(len-i, i); if(palindrome(left))&#123; cut++; if(palindrome(right)) &#123; done = true ; &#125;else &#123; bfs(right, done); &#125; &#125; i++; &#125;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[surrounded regions]]></title>
    <url>%2F2018%2F12%2F13%2Fsurrounded-regions%2F</url>
    <content type="text"><![CDATA[leetCode130, like go game. how to design the solution, at first it is naive to traverse with two for loops, then there will be too many if statement to specify, and not clear to seperate these if statements. three ideas behind a sample solution. using addtional status variablein lower space the problem is difficult to analysis, then from a higher space, the problem is clear and easy. e.g. trakcing the O in the board, how to mark them ? keep O will not tell the marked ones and the original ones. so using M to mark these already traversed, it make the situation much more clear starting from the critial domainat first, no idea where is a good start point, but the trick point is at the boundary, only the cells at boundary with O will keep O; all the O not on the boundary either connect to the boundary Os or they will be Xs. traversing with queueif not queue, to detect these O cells need two for loops, then deal with these O cells again need another two for loops. for loop is a global handling, while queue list is a local way, no need to take all cells in consideration, but only the cells in queue. queue should be a good way to traverse whenever the operation is not deal with all the elements. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374//extending from the boundary 'O', any extened will keep same statuevoid process(int i, int j, vector&lt;vector&lt;char&gt;&gt;&amp; board)&#123; int height = board.size(); int width = board[0].size(); std::pair&lt;int, int&gt; p; queue&lt;std::pair&lt;int, int&gt;&gt; Q ; Q.push(p(i,j)); board[i][j] = 'm'; while(!Q.empty())&#123; p tmp = Q.front(); Q.pop(); i=tmp.first; j=tmp.second; if(i!=0 &amp;&amp; board[i-1][j] == 'O')&#123; board[i-1][j] = 'm'; Q.push(p[i-1][j]); &#125; if(i!= width-1 &amp;&amp; board[i+1][j]=='O') &#123; board[i+1][j] = 'm'; Q.push(p[i+1][j]); &#125; if(j!=0 &amp;&amp; board[i][j-1]=='0') &#123; board[i][j-1]='m'; Q.push(p[i][j-1]); &#125; if(j!=height-1 &amp;&amp; board[i][j+1]=='O') &#123; board[i][j+1] = 'm'; Q.push(p[i][j+1]); &#125; &#125;&#125;void sol(vector&lt;vector&lt;char&gt;&gt;&amp; board)&#123; int height = board.size(); int width = board[0].size();//tracking the boundary 'o' and mark them as 'm' for(int i=0; i&lt;width; i++)&#123; if(board[i][0] == 'O')&#123; //bottom boundary board[i][0] = 'm' ; process(i, 0, board); &#125; if(board[i][height-1] == 'O') &#123; board[i][height-1] = 'm' ; process(i, height-1, board); &#125; &#125; for(int j=0; j&lt;height; j++)&#123; if(board[0][j] == 'O')&#123; board[0][j] = 'm'; process(0, j, board); &#125; if(board[width-1][j] == 'O') &#123; board[width-1][j] = 'm' ; process(width-1, j, board); &#125; &#125; for(int i=0; i&lt;width; i++) for(int j=0; j&lt;height; j++)&#123; if(board[i][j] == 'O') board[i][j] = 'X'; if(board[i][j] == 'm') board[i][j] = 'O'; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hash table]]></title>
    <url>%2F2018%2F12%2F12%2Fhash-table%2F</url>
    <content type="text"><![CDATA[the ideas behind hashtable is: 1) input the key to hash function, output the bucket index; 2) adding the element to the bucket[idx]. usually design the bucket[idx] as a linked list, allowing mulitply keys in the same bucket, which is called “collesion chaining”. 3) hashtable has three basic operators: insert/put, search/get, and remove. the memory usage of hashtable is continuous bucket array, then each bucket is a linked list. when first thought about the “continue array”, really is a vector, then why need hash function. That’s the point, hashtable allows the benefits of both vector and linked list. a few interesting topics about hash. 1)why prime numbers? the fundamental mathematical operations with prime numbers generally result in numbers who’s bit biases are close to random. in other word, when multiply or add a set of randome numbers by a prime number, the resulting numbers when as a group, statistically analyzed at their bit levels should show no bias towards being one state or another. in comupter science, pseudo random number generator has bit bias. 2) string hash/scattering,basically the hash functions should deal with each chracter in the input string, so no information about this string will be missed, and the information entropy after hashing operator suppose increase. 3) Blizzard hash function. not all hash function deal collision conflict with linked list, here is the example. 4) hash map benchmark performance review one feeling at this moment, so many brilliant and deep-focusing guys there, stay foolish and stay humble. std::unordered_mapthere is map vs unordered_map : map | unordered_map Ordering | increasing order | no ordering | (by default) | Implementation | Self balancing BST | Hash Table search time | log(n) | O(1) -&gt;Average | | O(n) -&gt; Worst Insertion time | log(n) + Rebalance | Same as search Deletion time | log(n) + Rebalance | Same as search basically map works for traversal, pre/post element access; unordered_map is quick in once search,insertion, deletion. here is a dictionary demo exampleword ladder, hash table is used to find a special word from dictionary. the benefit of unorder_set is O(1) find. so design a unorder_set to store the dict. in the following example, each character position in the word requires 25 times search of the dict. also every marked word from the dict, should not be searched second time. another variable is used to track the list of one_character_diff from current word, it’s like BFS. so design as a queue, which only need take care the neighbor two layers. 12345678910111213141516171819202122232425262728293031323334353637int sol(string start, string end, vector&lt;string&gt;&amp; wordList)&#123; int length = 2 ; unordered_set&lt;string&gt; dict ; foreach word in wordList: dict.insert(word) queue&lt;string&gt; one_diff_list; // initial by pushing start one_diff_list.push(start); while(!one_diff_list.empty())&#123; int size = one_diff_list.size(); for(int i=0; i&lt;size; i++)&#123; string word=one_diff_list.front(); one_diff_list.pop(); for(int i=0; i&lt;start.length(); i++)&#123; char oldChar = word[i]; for(char c='a'; c&lt;='z'; c++)&#123; if(c == oldChar) continue ; word[i] = c ; if(dict.find(word) != dict.end())&#123; if(word == end) &#123; //find the match return length; &#125; one_diff_list.push(word); dict.erase(word); &#125; &#125; word[i] = oldChar; &#125; &#125; length++; &#125; return 0; &#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[reinforce learning in simulator]]></title>
    <url>%2F2018%2F12%2F01%2Freinforce-learning-in-simulator%2F</url>
    <content type="text"><![CDATA[reinforcement learning from David Silver. In autonomous vehicle training, more and more practices dependent on simulator training e.g. carla RF an open source architecture used often is OpenAI GYM each agent has state, observation, action, which can be defined in state_space, observation_space, action_space. background 1) infinite or finite : in real case, state, observation space are easily to be infinite, e.g. in every frame, the agent has a different environment, which means a different state. the elements in action_space may be limited, e.g. turn left, turn right, accelerate, brake. etc. 2) continuous or discrete : when driving a car, the control is continuous, namely, a continuous function a time t. on the other hand, like play GO game, the action is not time related, each action is discrete to another. 3) locally or globally perception for a grid world game, the agent knows the whole world; but when a car running in a city, it can only percept the environment locally. this has a big difference when make decision the following talks about on-line policy RL, which means the agent will follow some policy(high-level). e.g the velocity limit, no collision with another car etc to training agent know how to drive, often need define environment reward, used to update the policy(detail-level), e.g. when the agent in stateA, policyI will be used. but keep in mind, neither the human nor the agent know exactly at first, which is the best(detail-level) value for the chosen policy, and the input (state, policy/action) is not even accurate so the learning process is actually to iterate in each episode to update the table (state, action), in which the policy is updated hidden, and which is usually called Q-value. after training, the (state, action) is better to handle the simulation environement. so the high-level computing flow: 123456789101112 s0 = env.step(agent) a0 = agent.follow_policy(s0) while not is_done: s1, r1, is_done, info = agent.act(a0) old_q_value = env.get_Q(s0, a0)cur_q_value = env.get_Q(s1, a1) measure = r1 + gamma * cur_q_value new_q_value = old_q_value + alpha * (measure - old_q_value) env.set_Q(s0, a0, new_q_value) s0, a0 = s1, a1 real case while loop is basically update policy, so next time in a certain state, the agent will performance better. but there is a problem, most real problem don’t have a Q-table, since the state space is infinite. 1) linear space approximator the real state space is high-dimension even infinite-dimension, mathmatically it’s OK to use a linear space to be as close as possible to the real space (Hilbert space). e.g. in elastic mechanics, the finite element space can approximate any accuracy to the continuous elastic space. so the idea is to construct the linear space base vector based on existing sample state, then all state can be descriped as a linear combination of the base vector. 2） neuro-network aproximator for nonlinear fitted application, to construct a neuro-network to describe the state space. how to train the network and how to make sure it is robost and convergence is another topic]]></content>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pYTHON again]]></title>
    <url>%2F2018%2F10%2F27%2FpYTHON-again%2F</url>
    <content type="text"><![CDATA[Pick python up from a link for new position: type12type(123)isinstance(instance_name, class_name) @propertytransfer get()method in a class to a decorator define function123def my_abs(x): if not isinstance(x, (int, float)): raise TypeError('bad operand type') fun decorator12@decoratordef fun() filter1234def is_odd(n): return n%2 == 1 list(filter(is_odd, [1, 2, 3, 4]) lambda1list(map(lambda x: x*2, [1, 2, 3, 4])) slice12L = [1, 2, 3, 4, 5]L[-2:] #[4, 5] list generation1[x*2 for x in range(1, 5)] class &amp; instance123456789class s(object): def \__init__(self, name): self.name = name def print_s(self): print('%s:' %(self.name)) s1 = s("john")s1.print_s() customized classdynamic language, so the instance of any class can be added any other attributes. 123456789class s(object): def \__init__(self, name): self._name = name def \__str__(self): return 's object(name: %s)' % self._name def \__getattr__(self, attr): if attr == 'attr1': return lambda: attr1.value raise &amp; except1234567891011import loggingtry: print('try...') r = 10/0 print('result: ', r)except ZeroDiisionError as e: print('except', e) logging.exception(e)finally: print('finally..') IO stream1234567891011f = open('test.log', 'r')print(f.read(size))f.close() #or with open('test.log', 'r') as f: printf(f.read(size)) for line in f.readlines(): print(line.strip()) picklingserializaion/marshalling/flattening and reverse 123456import pickleimport jsond = dic(name='zj', age='18')pickle.dumps(d)json.dumps(d)]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[the OK and not OK in my life]]></title>
    <url>%2F2018%2F10%2F11%2Fthe-OK-and-not-OK-in-my-life%2F</url>
    <content type="text"><![CDATA[go ahead 12345678&lt;table cellspacing=&quot;0&quot; style=&quot;border: 1px solid #333333; margin: 10px;&quot;&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot; style=&quot;border: none; font: bold 16px sans-serif; background: #ffddbb; color: #000000; padding: 5px; margin: 0px; text-align: center;&quot;&gt;This Is My Life, Rated&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 18px sans-serif; text-align: left; border: 1px solid #333333; border-left: none; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Life:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 18px sans-serif; text-align: left; border: 1px solid #333333; border-left: none; border-right: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/grebar.gif&quot; height=&quot;12&quot; width=&quot;124&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 6.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Mind:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/greblubar.gif&quot; height=&quot;12&quot; width=&quot;134&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 6.7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Body:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/blubar.gif&quot; height=&quot;12&quot; width=&quot;156&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 7.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Spirit:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/blupurbar.gif&quot; height=&quot;12&quot; width=&quot;176&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 8.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Friends/Family:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/orbar.gif&quot; height=&quot;12&quot; width=&quot;46&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 2.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Love:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/redbar.gif&quot; height=&quot;12&quot; width=&quot;16&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 0.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Finance:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/greblubar.gif&quot; height=&quot;12&quot; width=&quot;142&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 7.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot; style=&quot;border: none; border-top: 1px solid #333333; font: bold 14px sans-serif; background: #ffeedd; padding: 5px; margin: 0px; text-align: center;&quot;&gt;&lt;a href=&quot;http://www.monkeyquiz.com/life/rate_my_life.html&quot; style=&quot;color: #0000ff;&quot;&gt;Take the Rate My Life Quiz&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; I am not a socialized man, period]]></content>
  </entry>
  <entry>
    <title><![CDATA[Btree max path sum]]></title>
    <url>%2F2018%2F10%2F02%2FBtree-max-path-sum%2F</url>
    <content type="text"><![CDATA[leetCode 124. the first idea is recursive from root to bottom leaf, and return the max from left or right at each node. 1234567891011121314151617int subsum(TreeNode* node)&#123; int max_left = 0, max_right =0; if(node-&gt;left) max_left = subsum(node-&gt;left); else return std::max(node-&gt;val, subsum(node-&gt;right)); if(node-&gt;right) max_right = subsum(node-&gt;right); else return std::max(node-&gt;val, subsum(node-&gt;left)); sum += node-&gt;val + std::max(max_left, max_right); return sum;&#125; this will get the max sum branch from top to bottom, but can’t consider the other branch, and there is case when the max sum branch is actually smaller than a subtree sum. so here needs to consider the subtree sum as well, since the root tree can be consider as a subtree, so after implmenting subtree sum, actually no need to consider the other branch sum. 123456789101112131415161718192021222324252627282930313233343536373839404142int subsum(TreeNode* node, std::priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt; &gt;&amp; s)&#123; if(node==nullptr) return 0; int max_left=0, max_right=0; int sum=0; int subtree_sum = 0; if(node-&gt;left)&#123; max_left = subsum(node-&gt;left, s); subtree_sum += max_left; &#125;else &#123; subtree_sum += node-&gt;val; return std::max(node-&gt;val, subsum(node-&gt;right, s)); &#125; if(node-&gt;right)&#123; max_right = subsum(node-&gt;right, s); subtree_sum += max_right; &#125;else&#123; subtree_sum += node-&gt;val; return std::max(node-&gt;val, subsum(node-&gt;left, s)); &#125; sum += node-&gt;val + std::max(max_left, max_right); if(node-&gt;right != nullptr || node-&gt;left != nullptr) subtree_sum += node-&gt;val; else subtree_sum -= node-&gt;val; if(subtree_sum &gt; sum)&#123; s.push(subtree_sum); cout &lt;&lt; "s.top= " &lt;&lt; s.top() &lt;&lt; "\n" &lt;&lt; endl; while( sum &gt; s.top()) &#123; s.pop(); &#125; &#125; return sum; &#125; passing priority_queue s as reference, so if subtree\_sum is bigger than the top-bottom branch sum, then it will be pushed into s; but pop out the elements smaller than current branch sum in each recrusive routing. finally, compare the largest elemnet in s with top-bottom branch sum.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[when pure loop doesn't work out]]></title>
    <url>%2F2018%2F10%2F01%2Fwhen-pure-loop-doesn-t-work-out%2F</url>
    <content type="text"><![CDATA[leetCode 115: given a string S and a string T, count the number of distinct subsequences of S which equals T. Input: S = &quot;babgbag&quot;, T = &quot;bag&quot; Output: 5 Explanation: As shown below, there are 5 ways you can generate &quot;bag&quot; from S. (The caret symbol ^ means the chosen letters) babgbag ^^ ^ babgbag ^^ ^ babgbag ^ ^^ babgbag ^ ^^ babgbag ^^^ first thoughtfor each alpha in T, traversing S, find a match, return; then move forward for next alpha in T and traversing S again, 1234567891011121314151617181920212223242526272829303132int sol(string&amp; s1, string&amp; s2)&#123; string::iterator sit1, sit2, nait; string notagain; int count=0; for(nait = s2.begin(); nait != s2.end(); nait++)&#123; notagain.push_back(*nait); sit1 = s1.begin(); sit1_last = s1.begin(); while( sit1 != s1.end()) &#123; for(sit2=s2.begin(); sit2 != s2.end(), sit1 != s1.end(); sit1++) &#123; if(*sit1 == *sit2) &#123; tmp.push_back(*sit2); sit2++; &#125; if(tmp.compare(s2) == 0) &#123; count++; break; &#125; &#125; sit1 = st1_last++; &#125; &#125;&#125; this is a failed trail. Since this kind of problem really can’t be solved by purely nested for-loop. think about, at the last level (traverse S to get g), there needs one for-loop, then the previous level or the level above (traverse S to get a) needs another loop. and each “a” needs one for-loop to traverse all possible “g” in S again. and the top level (travers S to get “b”) is another for-loop, and each “b” need another for-loop to traverse “a”. and this is only three levels (b-&gt;a-&gt;g) basically if implementing tree traversing with for-loop, since tree structure has many branches to the end, since even each sub-branch needs a for-loop, there will be exponent disaster of for-loop to cover all branches. second thoughtswhat’s the different mindset? recursive. when dealing with many-branches-travsersing (e.g. a tree strucutre), recursive is nature to think. since recursive only consider the neighbor two level branches. for this example, inside each recursive need a for-loop to catch all possible positions of the satisfied character, and stack is need to, when visiting a new character from T need poush, and when find out a T, then need to pop out the last character. during breadth traversing tree, either using a pure recursive or using stack with a while-loop. but here it needs a for-loop and stack inside each recursive. (a little complex) 1234567891011121314151617181920212223242526272829303132333435void rec(string&amp; S, string&amp; T, string::iterator tc, std::stack&lt;char&gt; ss, int&amp; nums )&#123; if(tc == T.end()) return ; for(int i= 0; i&lt;S.size(); i++) &#123; if(S[i] == *tc) &#123; ss.push(*tc); if(ss.size() != T.size()) &#123; string cur_s = S.substr(i+1); rec(cur_s, T, ++tc, ss, nums); --tc; ss.pop(); &#125;else &#123; cout &lt;&lt; "found one\n" ; nums++; ss.pop(); &#125; &#125; &#125;&#125;int sol(string&amp; S, string&amp; T)&#123; string::iterator tit = T.begin(); std::stack&lt;char&gt; ss ; int nums =0; rec(S, T, tit, ss, nums); return nums; &#125; TODO: there suppose be a general pattern for this kind of problem. third thoughtsif the problem is too complex to handle at first, more memory always make it looks simple, using containers to split the content. with 2 for-loops to create #num of buckets to store positions of each alphaet in T 123456789101112131415161718192021int sol(string&amp; s1, string&amp; s2)&#123; int length = s2.size(); std::map&lt;char, vector&lt;int&gt;&gt; smap; std::vector&lt;int&gt; pos; string::iterator sit; char alpha ; for(i=0; i&lt;s2.size(); i++) &#123; alpha = s2[i]; int i=0; pos.clear(); for(sit = s1.begin(); sit != s1.end(); sit++) &#123; if( alpha == *sit) &#123; pos.push_back(i++); &#125; &#125; smap.insert(std::pair&lt;char, vector&lt;int&gt;&gt;(alpha, pos); &#125; b 0, 2, 4 a 1, 5 g 3, 6 after get the map, then play the combinations games. that’s actually still a recursive problem.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Btree traversal]]></title>
    <url>%2F2018%2F10%2F01%2FBtree-traversal%2F</url>
    <content type="text"><![CDATA[Btree traversal is obvious to implement in recursion. here are non-recursion implementation, which needs std::stack or std::queue data structure to store the next level nodes in both deep-first-search idea and breadth-first-search idea, link. these are good examples of using stack, queue. usage in leetCode114, flatten a BTree to a linked list 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192void preorder_print(TreeNode* leaf)&#123; if(leaf == nullptr) return; std::stack&lt;int&gt; s; TreeNode* tmp ; s.clear(); // s.push(leaf); while(!s.empty()) &#123; tmp = s.pop(); cout &lt;&lt; tmp-&gt;value &lt;&lt; ', ' ; if(leaf-&gt;right != nullptr) s.push(leaf-&gt;right); if(leaf-&gt;left != nullptr) s.push(leaf-&gt;left); &#125; &#125;void inorder_print(TreeNode* leaf)&#123; std::stack&lt;int&gt; s ; s.clear(); TreeNode *tmp; while( !s.empty() || leaf!=nullptr) &#123; if(leaf != nullptr) &#123; s.push(leaf); leaf = leaf-&gt;left; &#125;else &#123; tmp = s.top(); s.pop(); cout &lt;&lt; tmp-&gt;value &lt;&lt; ', ' ; leaf = leaf-&gt;right; &#125; &#125;&#125;void postorder_print(TreeNode* leaf)&#123; std::stack&lt;int&gt; s ; s.clear(); TreeNode *lastNodeVisited = nullptr ; TreeNode *peekNode = nullptr; while( !s.empty() || leaf != nullptr) &#123; if(leaf != nullptr) &#123; s.push(leaf); leaf = leaf-&gt;left; &#125;else &#123; peekNode = s.top(); if(peekNode-&gt;right != nullptr &amp;&amp; lastNodeVisited != peekNode-&gt;right) leaf = peekNode-&gt;right; else &#123; cout &lt;&lt; peekNode-&gt;value &lt;&lt; ', '; lastNodeVisited = s.top(); s.pop(); &#125; &#125; &#125;&#125;void bfs_print(TreeNode* leaf)&#123; std::queue&lt;int&gt; q ; q.clear(); q.push(leaf); TreeNode *node; while( ! q.empty()) &#123; node = q.front(); q.pop(); cout &lt;&lt; node-&gt;vaue &lt;&lt; ', '; if(node-&gt;left != nullptr) q.push(node-&gt;left); if(node-&gt;right != nullptr) q.push(node-&gt;right) &#125;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[construct a self balanced BStree]]></title>
    <url>%2F2018%2F09%2F24%2Fconstruct-a-self-balanced-BStree%2F</url>
    <content type="text"><![CDATA[leetCode 109 construct a height-balanced Binary Search tree from input array(sorted or not). a self-balanced BStree, which means the left and right kid of each node have no more than 1 height difference, also named as AVL tree. There are three basic routines in implementation of AVL tree: right tree rotate, left tree rotate, and insert. and each TreeNode requires an additionly height value. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556TreeNode* rightRotate(TreeNode* leaf)&#123; if(leaf==nullptr) return leaf; TreeNode* root_left = leaf-&gt;left ; TreeNode* left_right = root_left-&gt;right ; root_left-&gt;right = leaf; leaf-&gt;left = left_right; return root_left; &#125;TreeNode* leftRotate(TreeNode* leaf)&#123; if(leaf==nullptr) return leaf; TreeNode* root_right = leaf-&gt;right; TreeNode* right_left = root_right-&gt;left; root_right-&gt;left = leaf; leaf-&gt;right = right_left; return root_right;&#125;TreeNode* insert(TreeNode* root, int key)&#123; if(root==nullptr) return (new TreeNode(key)); if(key &gt; root-&gt;val) root-&gt;right = insert(root-&gt;right, key); else if(key &lt; root-&gt;val) root-&gt;left = insert(root-&gt;left, key); else return root; root-&gt;height = std::max(height(root-&gt;left), height(root-&gt;right)) + 1 ; int balance = height_dif(root); if(balance &gt; 1 &amp;&amp; key &lt; root-&gt;val ) //new key inserted in left sub &#123; return rightRotate(root); &#125; /* keep in mind, -1 &lt;= last_balance &lt;= 1 only key &lt; root-&gt;val, will it possible that current_balance &gt; 1 */ if(balance &lt; -1 &amp;&amp; key &gt; root-&gt;val ) &#123; return leftRotate(root); &#125; return root; &#125; at the very first coding I natively pass node pointer by reference: TreeNode* insert(TreeNode* &amp;root, int key) root-&gt;right = insert(root-&gt;right, key); since assigned insert() back to the same node pointer again, if passing by reference, each insert will clear the memory-write the same memory all the time, and can’t generate. what actually happen in insert is creating a new object. the structure pointer inside structure definition is the trick here. when define root node, both leftand right nodes are nullptr, so argument root-&gt;right is nullptr, but the returning root-&gt;right is actually pointing to a node structure memory. also nullptr can’t be dereferring, basically since nullptr doesn’t point to any meaningful object, to dereference a null pointer will cause runtime or immediate crash.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[construct BTree from pre/in/post-order input]]></title>
    <url>%2F2018%2F09%2F19%2Fconstruct-BTree-from-pre-in-post-order-input%2F</url>
    <content type="text"><![CDATA[pre&amp;in-order inputleetCode105 : given preorder and inorder traversal of a tree, construct the binary tree. sol: each top node in Btree, has left-branch and right-branch, and each branch is a similar-structure subtree. so every time pop out the top node, and recursive the two subtrees, which return as the left kid and right kid of current top node. the recursive stopped when the list is empty(in real case, this means the node has only either left or right kid); or stopped when only one element in the list(in real case, the node has both kids, so left or right subtree has only one element). 12345678910111213141516171819202122232425262728293031323334353637TreeNode* sol(list&lt;int&gt;&amp; pre, list&lt;int&gt;&amp; in) &#123; if(pre.empty() || in.empty()) &#123; return nullptr; //empty left/right node &#125; if(pre.size() == 1 &amp;&amp; in.size() == 1) &#123; return new TreeNode(pre.front()); &#125; int root = pre.front(); pre.pop_front(); TreeNode* root_node = new TreeNode(root); list&lt;int&gt;::iterator in_it, pre_it; in_it = std::find(in.begin(), in.end(), root); if(in_it == in.end()) //only one node in inorder list now, wont happen &#123; return (new TreeNode(in.front())); &#125; int idx = std::distance(in.begin(), in_it); list&lt;int&gt; in_left_subtree(in.begin(), in_it); list&lt;int&gt; in_right_subtree(++in_it, in.end()); in.erase(in_it); pre_it = pre.begin(); std::advance(pre_it, idx); list&lt;int&gt; pre_left_subtree(pre.begin(), pre_it); list&lt;int&gt; pre_right_subtree(pre_it, pre.end()); root_node-&gt;left = sol(pre_left_subtree, in_left_subtree); root_node-&gt;right = sol(pre_right_subtree, in_right_subtree); return root_node; &#125; in each recursive step, I am using exteral containers, same stragey in scramble string. is there a one-swap way? post/in-order inputleetCode106 1234567891011121314151617181920212223242526272829TreeNode* sol(list&lt;int&gt;&amp; in, list&lt;int&gt;&amp; post)&#123; if(in.empty() || post.empty()) return nullptr; if(in.size() == 1 || post.size() == 1) return (new TreeNode(in.front())); // return the left || right kid //first find out the tree root, the last element in post-order int root_v = post.back(); TreeNode* root = new TreeNode(root_v); post.pop_back(); //find root_v in inorder list&lt;int&gt;::iterator in_lit = std::find(in.begin(), in.end(), root_v); //create subtrees recursive int left_length = std::distance(in.begin(), in_lit); list&lt;int&gt; in_left_sub(in.begin(), in_lit); list&lt;int&gt; in_right_sub(++in_lit, in.end()); in.erase(in_lit); list&lt;int&gt;::iterator post_lit = std::next(post.begin(), left_length); list&lt;int&gt; post_left_sub(post.begin(), post_lit); list&lt;int&gt; post_right_sub(post_lit, post.end()); root-&gt;left = sol(in_left_sub, post_left_sub); root-&gt;right = sol(in_right_sub, post_right_sub); return root ;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[construct BTree from breadth-order input]]></title>
    <url>%2F2018%2F09%2F19%2Fconstruct-BTree-from-breadth-order-input%2F</url>
    <content type="text"><![CDATA[first there should be a queue or stack to store the next layer elements, as the tree go deeper, there are many branches, which requires a contianer to track what’s the elements in next layer. stack always pop out the top element(FILO), which actually set the input elements in a reversed order as tree elements; queue can pop out the first element(FIFO), which can set the input elements in the same order in tree elements. so here pick std::queue. the input array can used std::vector, each time pop_front(), which basically read the array in order. and each pop_front element constructs a new TreeNode. if the layer container is empty(), then it’s the root layer; else it’s a branch layer. growing the tree in each branch layer, need update the next layer container. for each new inserting element, either insert to left or right of node A in parent layer or insert to the A’s sibling node B. then pop out the node which already has both kids. when traversling to the last node in parent layer, and if both the kids are filled-in, then there is a turning point, need to swap next_parent layer as parent layer. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152void insert_kids(std::queue&lt;TreeNode*&gt;&amp; parents, std::queue&lt;TreeNode*&gt;&amp; next_parents, TreeNode* p)&#123; if(parents.empty()) return ; TreeNode* father = parents.front(); if(!father-&gt;left) &#123; father-&gt;left = p; if(p) next_parents.push(p); &#125;else if(!father-&gt;right) &#123; father-&gt;right = p; if(p) next_parents.push(p); &#125;else &#123; parents.pop(); if(parents.empty()) // turning point, if returned then p will be lost &#123; parents.swap(next_parents); &#125; insert_kids(parents, next_parents, p); &#125; &#125;TreeNode* breadth_construct(list&lt;int&gt;&amp; arr)&#123; TreeNode *p, *root ; int x ; std::queue&lt;TreeNode*&gt; parents, next_parents; while(!arr.empty()) &#123; x = arr.front(); arr.pop_front(); p = (TreeNode*) new TreeNode(x); if(parents.empty()) &#123; parents.push(p); root = p ; continue; &#125;else if( !parents.empty()) //at this step, parents still has 1 element, but after insert_kids, parents is empty. then &#123; insert_kids(parents, next_parents, p); continue; &#125; &#125; return root; &#125; how to deal with NULL during struct constructure? if both (int x) and (TreeNode* p) constructor are defined, which will lead to ambisious when new TreeNode(NULL). 1234567891011121314151617181920212223242526struct TreeNode &#123; int value ; struct TreeNode *left ; struct TreeNode *right; //TODO: how to implement copy assignment in structure ? TreeNode(TreeNode* p) &#123; if(p == NULL) &#123; value = 0; left = NULL; right = NULL; &#125;else &#123; value = p-&gt;value; left = p-&gt;left; right = p-&gt;right; &#125; &#125; TreeNode(int x): value(x), left(NULL), right(NULL) &#123; &#125;&#125;;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[print combinatorics]]></title>
    <url>%2F2018%2F09%2F19%2Fprint-combinatorics%2F</url>
    <content type="text"><![CDATA[combinatorics related algorithms e.g. unique BST(leetCode95), Permutations(46), Unique Path(62). Give an integer m, how many different combinations can have? mathematically, it’s a permutation P_m^m or combination C_m^n problem, the total number is easy to calculate, but how to write a code to print out each combination elegantly ? one core step: how to generate a new combination(k+1) array by inserting one new element into the current combination(k). e.g. {1, 2} --&gt; {3, 1, 2}, {1, 3, 2}, {1, 2, 3} here is basically insert 3 at (k+1) positions, and each new position will generate a new combination with (k+1) size. depends on the problem, choose either vector(to support random access) or list (to support O(1) insert or delete) as the container. one tip here, how to erase one element from std::list while iterating ? 1234567891011121314151617181920212223242526272829303132333435363738394041vector&lt;list&lt;int&gt;&gt; next_layer(vector&lt;list&lt;int&gt;&gt;&amp; layer, int c)&#123; if(layer.empty()) &#123; list&lt;int&gt; tmp ; tmp.push_back(c); layer.push_back(tmp); return layer; &#125; vector&lt;list&lt;int&gt;&gt; next_layer_v, cur; for(int i=0; i&lt;layer.size(); i++) &#123; list&lt;int&gt;::iterator lit ; list&lt;int&gt; arr = layer[i] ; cur.clear(); for(lit = arr.begin(); lit != arr.end(); lit++) &#123; arr.insert(lit, c); //insert c in front of lit cur.push_back(arr); lit = arr.erase(--lit); // erase c, which is 1 step in front of lit, and must return lit here, else lit will become non-refereable &#125; next_layer_v.insert(next_layer_v.end(), cur.begin(), cur.end()); &#125; return next_layer_v; &#125;void sol(int num)&#123; vector&lt;list&lt;int&gt; &gt; layer, last_layer; list&lt;int&gt; cur_list ; for(int i=0; i&lt; num; i++) &#123; layer = next_layer(last_layer, i); last_layer = layer; &#125; print_vec_list(layer);&#125; this implementation is more clear than what I did in Permutation while the memory of many last layers vector]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[object creating in C/C++]]></title>
    <url>%2F2018%2F09%2F11%2Fobject-creating-in-C-C%2F</url>
    <content type="text"><![CDATA[construct an objectthe compiler will define a default constructor with no parameters, if there is no user defined default constructors. usually the parameters for user defined(UD) default constructors should have default values. directly call the UD constructor will create an object; call the UD through new keyword will create an object pointer. 12345678910111213141516struct TreeNode&#123; int val; TreeNode *right ; TreeNode *left; TreeNode(int x=0): val(x), left(NULL), right(NULL)&#123;&#125;; //user defined constructor TreeNode(const TreeNode *cp) //copy constructor &#123; val = cp-&gt;val; right = cp-&gt;right; left = cp-&gt;left; &#125;&#125;TreeNode node1; TreeNode node2(100);TreeNode *node_p = new TreeNode(10); create an object in pure Cnew operator do two things: allocate memory for a C++ class object, then call the object’s constructor to initialize this object. basically, new packages memory management of objects and objects initialization. while in pure C, since there is no object constructor, after malloc memory for the structure, either call an initial function or manually initialize this structure member variables. 123456789101112131415161718192021222324TreeNode &#123; int val; TreeNode *right ; TreeNode *left;&#125;int main()&#123; TreeNode *p = (TreeNode*) malloc( sizeof(struct TreeNode)); p-&gt;val = 0; p-&gt;right = NULL; p-&gt;left = NULL ; &#125;``` ## construct an object array beyond creating one object (pointer), how to create object array. ```c int nums = 5;TreeNode tree_array[nums];TreeNode *tree_p = (TreeNode*) new TreeNode[nums]; be aware, each element in tree_array has the whole memory of TreeNode structure; and tree_p++ will go to next TreeNode structure, tree_p[i] is also a whole memory of TreeNode structure. create an object array in pure C12int nums = 5;TreeNode *tree_p = (TreeNode*) malloc(nums * sizeof(TreeNode)); basically malloc will return a pointer to a block of memory, but it’s not responsible to initialize this block of memory. the rule of fiverule of three is about how to manage dynamically allocated resources in C++. why it is necessary? 1) when parameter B is copying by value from A, if no user defined copy constructor, the compiler will do a shallow copy from A to B by default, in which a new pointer point to the same content address. at the end of function call, the parameter B is out of scope, so destructor is called, and A is still there. but at the end of the main function, A is out of scope, need deallocating, then error is B already deallocate the content of A. with a user defined copy constructor, B will get a deep copy of A, so no sharing content, no problems when deallocating either B or A. 2) if no user specified assignment constructor, a shallow copy happens, then error-potential. and assignment constructor (operator=) can be implemented with copy constructor. 1234567int main()&#123; TreeNode node1; TreeNode node2 = node1; //actually a copy-construct, same as node2(node1) TreeNode node3 ; node3 = node1 ; //a compiler assignment-construct by default(shallow copy)&#125;]]></content>
      <tags>
        <tag>C++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrabmle string]]></title>
    <url>%2F2018%2F09%2F11%2Fscrabmle-string%2F</url>
    <content type="text"><![CDATA[scramble string at leetCode 87. sol: get all possible scrambled strings of s1, then compare if s2 is in it. for 1-char: scramble(&quot;a&quot;) --&gt; &quot;a&quot; for 2-chars : scramble(&quot;ab&quot;) --&gt; &quot;ba&quot; for 3-chars: scramble(&quot;abc&quot;) --&gt; &quot;bac&quot;, &quot;cba&quot;, &quot;acb&quot;, &quot;cba&quot; for 4-chars: scramble(&quot;abcd&quot;) --&gt; (a | bcd) + (ab | cd) + (abc | d) for 5-chars: scramble(&quot;abcde&quot;) --&gt; (a | bcde) + (ab | cde) + (abc | de) + (abcd | e) from the enumaration, there is always a left-substring and a right-substring, and recursive in each substring. consider the push_back order, there are two: left-&gt;\right and right-&gt;\left at each two slibings. additional routines: how to do substring join and how to delete duplicate string from string-vector. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859 string join(string&amp; sub1, string&amp; sub2) &#123; string res; res.reserve(sub1.size() + sub2.size()); string::iterator it; for(it = sub1.begin(); it != sub1.end(); it++) res.push_back(*it); for(it = sub2.begin(); it != sub2.end(); it++) res.push_back(*it); return res; &#125; //TODO: keep in mind the transfer function, and how to design it vector&lt;string&gt; scramble(string&amp; s) &#123; string ls, rs; vector&lt;string&gt; vls, vrs, vcurs; if(s.size() == 1) &#123; vcurs.push_back(s); return vcurs; &#125; for(int i=1; i&lt;s.size(); i++) &#123; ls = s.substr(0, i); rs = s.substr(i, s.size()); vls = scramble(ls); vrs = scramble(rs); for(int m=0; m&lt; vls.size(); m++) for(int n=0; n &lt; vrs.size(); n++) &#123; vcurs.push_back(join(vls[m], vrs[n])); vcurs.push_back(join(vrs[n], vls[m])); &#125; &#125;/*how to delete duplicated string from vector&lt;string&gt; */ std::sort(vcurs.begin(), vcurs.end()); vcurs.erase( std::unique(vcurs.begin(), vcurs.end()), vcurs.end()); return vcurs; &#125; int main()&#123; string s1 = "abcd" ; vector&lt;string&gt; outs = scramble(s1); for(int i=0; i&lt;outs.size(); i++) cout &lt;&lt; outs[i] &lt;&lt; endl; return 0;&#125; How to write a completed code, meaning, always take care the boundaries correctly, no missing situations. It’s easy to start from scratch and achieve somewhere, but hard to be completed.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how dynamic programming works]]></title>
    <url>%2F2018%2F09%2F04%2Fhow-dynamic-programming-works%2F</url>
    <content type="text"><![CDATA[leetcode 64(Mini Path Sum): Given a m x n grid filled with non-negative numbers, find a path from top left to bottom right which minimizes the sum of all numbers along its path. the first thought is to build a tree： 1 / \ 1 3 / \ / \ 4 5 1 5 / /\ / /\ 2 1 2 1 1 2 while this is not a balanced tree, no regular tree way to maintain. Then what else solution? Dynamic Programming is a strategy to solve a simple problem at first, then find the rules(status transfer from previous state to current state) for the remaining problems. step1: the simpler problem, or as initial/boundary condition. e.g. only one row, or only one col, what’s the solution. step2: in general m rows, n cols, how to get the iterative rules after step1. 123456789101112131415161718192021222324252627282930313233343536373839int sol(vector&lt;vector&lt;int&gt; &gt;&amp; mat)&#123; vector&lt;vector&lt;int&gt; &gt; dp; int row = mat.size(); int col = mat[0].size(); for(int i=0; i&lt;row; i++) dp[i][0] += mat[i][0]; for(int j=0; j&lt;col; j++) dp[0][j] += mat[0][j]; for(int i=1; i&lt;row; i++) for(int j=1; j&lt;col; j++) dp[i][j] = min(dp[i-1][j], dp[i][j-1]) + mat[i][j]; return dp[row-1][col-1]; &#125;int main()&#123; vector&lt;int&gt; v1, v2, v3 ; v1 = &#123;1, 3, 1&#125;; v2 = &#123;1, 5, 1&#125;; v3 = &#123;4, 2, 1&#125; vector&lt;vector&lt;int&gt; &gt; mat; mat.push_back(v1); mat.push_back(v2); mat.push_back(v3); int out = sol(mat); cout &lt;&lt; "output =" &lt;&lt; out &lt;&lt; endl; return 0;&#125; See DP solution is much clear than design the tree.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how recursive works with passing reference variables]]></title>
    <url>%2F2018%2F08%2F29%2Fhow-recursive-works-with-passing-reference-variables%2F</url>
    <content type="text"><![CDATA[leetCode 62(unique paths): A robot is located at the top-left corner of a m x n grid (marked ‘Start’ in the diagram below). The robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked ‘Finish’ in the diagram below). How many possible unique paths are there? solution: it’s easy to model as a math combination problem, assume the right-step has m; the down-step has n. so each path from top left to bottom right, has (m+n) steps totally. the total unique paths is C_(m+n)^m passing by value: 12345int sol(int rm, int rn)&#123; return rm==0 ? 1 : (rm+rn)/rm * sol(rm-1, rn);&#125; what happened if rm-1 changed to rm–? warning: unsequenced modification and access to &apos;rm&apos; what about passing as reference ? 1234int sol(int&amp; m, int&amp; n)&#123; return m==0 ? 1 : (m+n)/(float)m * sol(--m, n);&#125; if using m– : error: expects an l-value for 1st argument of sol(int&amp;, int&amp;) m– is only r-value, can’t be used as reference varaible; but –m is r-value. for m as a reference variable, –m is the way to update the content of the address. while m– more like move to the next address?]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how backtracks work]]></title>
    <url>%2F2018%2F08%2F29%2Fhow-backtracks-work%2F</url>
    <content type="text"><![CDATA[leetCode 50 (N-Queens): The n-queens puzzle is the problem of placing n queens on an n×n chessboard such that no two queens attack each other. solution: each potentional position for a queen should satisfy no attach, then traverse the 2D grids to find out all good positions; it requires to find all possible combinations, so recursive call will be used also. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106 bool one_queen_visited(int** mat, int n, pair&lt;int, int&gt;&amp; queen_idx) &#123; int row = queen_idx.first ; int col = queen_idx.second; for(int i=0; i&lt;n; i++) &#123; for(int j=0; j&lt;n; j++) &#123; if(mat[row][j] == 0) mat[row][j] = 1; else if(mat[row][j] == 100) return false; &#125; if(mat[i][col] == 0) mat[i][col] = 1; else if(mat[i][col] == 100) return false; &#125; //for left leaning for(int i=row, j=col; i&gt;=0 &amp;&amp; j&gt;=0; i--, j--) &#123; if(mat[i][j] == 0) mat[i][j] = 1; else if(mat[i][j] == 100) return false; &#125; for(int i=row, j=col; i&lt;n &amp;&amp; j&lt;n; i++, j++) &#123; if(mat[i][j] == 0) mat[i][j] = 1; else if(mat[i][j] == 100) return false; &#125; //for right leaning //down for(int i=row, j=col; i&lt;n &amp;&amp; j&gt;=0; i++, j--) &#123; if(mat[i][j] == 0) mat[i][j] = 1; else if(mat[i][j] == 100) return false; &#125; //up for(int i=row, j=col; i&gt;=0 &amp;&amp; j&lt;n; i--, j++) &#123; if(mat[i][j] == 0) mat[i][j] = 1; else if(mat[i][j] == 100) return false; &#125; mat[row][col] = 100; //queen location marked as 100 return true; &#125;int backtrack = 0; void sol(int** mat, int n, int start_j=0) &#123; std::pair&lt;int, int&gt; idx; vector&lt;pair&lt;int, int&gt;&gt; queens; vector&lt; vector&lt;pair&lt;int, int&gt;&gt; &gt; queens_v; if(start_j &gt; n) return ; //end of recursive for(int i=0; i&lt;n; i++) &#123; for(int j= ((i==0)? max(start_j, 0) : 0); j&lt;n; j++) &#123; idx = std::make_pair(i, j); if(one_queen_visited(mat, n, idx)) // find a fit queen position, store into queens &#123; queens.push_back(idx); &#125; &#125; &#125; if(queens.size() == n) &#123; queens_v.push_back(queens); int** mat_copy = new int*[n] ; for(int i=0; i&lt;n; i++) &#123; mat_copy[i] = new int[n](); &#125; for(int i=0; i&lt;queens.size(); i++) &#123; idx = queens[i]; mat_copy[idx.first][idx.second] = 1 ; &#125; for(int i=0; i&lt;n; i++) &#123; for(int j=0; j&lt;n; j++) cout&lt;&lt; mat_copy[i][j] &lt;&lt; ' ' ; cout &lt;&lt; endl; &#125; &#125; clean_mat(mat, n); sol(mat, n, ++backtrack); &#125; I did actually new memory in C++ as following: 123int** mat = (int**) new(n * sizeof(int*)); for(int i=0; i&lt;n; i++) mat[i] = (int*) new( n * sizeof(int)); which failed, then realized only malloc works in this way.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how broad first search works]]></title>
    <url>%2F2018%2F08%2F29%2Fhow-broad-first-search-works%2F</url>
    <content type="text"><![CDATA[leetCode 45 (jump game): Given an array of non-negative integers, you are initially positioned at the first index of the array.Each element in the array represents your maximum jump length at that position.Your goal is to reach the last index in the minimum number of jumps. e.g. [2, 3, 1, 1, 4] –&gt; 2 solution: at current position, bfs all the next positions it can jump to, when the back element is in next position list, then reached. 1234567891011121314151617181920212223242526272829303132333435363738394041int sol(vector&lt;int&gt;&amp; nums )&#123; vector&lt;int&gt;::iterator it, cur_it ; vector&lt;int&gt; *adj = new vector&lt;int&gt;[nums.size()]; int cur_node ; for(it=nums.begin(); it &lt; nums.end(); it++) &#123; cur_node = *it; adj[cur_node].push_back(cur_node); for(int i=1; i&lt;=cur_node; i++) &#123; cur_it = std::next(it, i); adj[cur_node].push_back(*cur_it); if( *cur_it == nums.back())&#123; it = nums.end(); //reach the last element, so return &#125; &#125; &#125; vector&lt;int&gt; tmp; int last_element = nums.back(); int mini_path = 1; for(int i=0; i &lt; nums.size(); i++) &#123; tmp = adj[i]; if(!tmp.empty()) &#123; for(int j=0; j&lt;tmp.size(); j++) &#123; cout&lt;&lt; tmp[j] &lt;&lt; ' ' ; &#125; cout &lt;&lt; endl; if(tmp.back() == last_element) &#123; return mini_path; &#125; mini_path++; &#125; &#125; return -1;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how recursive works]]></title>
    <url>%2F2018%2F08%2F29%2Fhow-recursive-works%2F</url>
    <content type="text"><![CDATA[leetCode 46 Permutations: given a collection of distinct integers, return all possible permutations. Input: [1, 2, 3] Output: [ [1,2,3], [1,3,2], [2, 1, 3], [2, 3, 1], [3, 1,2], [3,2,1] ] At first glipmse, it’s middle difficult, jump to recursive implementation. But there always confused failures, e.g. passing vector as reference to the recursive calls, and even do a deep copy of that vector, the base vector is always modified by the copied vector. This problem blocks me a whole day, actually I don’t know how to make a recursive calls work. tip1) each recursive fun has its independent local variables ; tip2) recursive calls are serialized, namely only when inside recursive fun is done, then the outside recursive will continue. tip1 helps to explain when local variables changed unexpected; tip2 helps cause I trend to think all recursive calls are parallezed running, but the real running order is serialized, so no twist. simulate how human brain solve this problem: &lt;1(fix), 2(fix), 3&gt; ; &lt;1(fix), 3(fix), 2&gt; … the first position has n potentional values, then the second position has (n-1) potentional values, etc. so design the very first implementation as: traverse all potentional values in first position, and push it; then travers all potentional values in next position, and push it; till the last position, while only one element left, and push it. so a new combination is created. 123456789101112131415161718192021222324252627vector&lt;vector&lt;int&gt;&gt; sol1(vector&lt;int&gt;&amp; nums)&#123; vector&lt;vector&lt;int&gt;&gt; idx_vector ; for(int i=0; i&lt; nums.size(); i++) &#123; vector&lt;int&gt; tmp ; tmp.push_back(nums[i]); //the first element in new created vector vector&lt;int&gt; nums1 = nums ; nums1.erase(nums1.begin()+i); //the second element in new created vector for(int j=0; j&lt; nums1.size(); j++) &#123; tmp.push_back(nums1[j]); vector&lt;int&gt; nums2 = nums1; nums2.erase(nums2.begin() + j); if(nums2.size() == 1) &#123; tmp.push_back(nums2[0]); idx_vector.push_back(tmp); tmp.pop_back(); &#125; tmp.pop_back(); &#125; &#125; return idx_vector; &#125; the first implmenation only works for fixed input , so how to design a recursive fun to make this idea more general ? it’s easy to abstract the process above: for ith position in the new combination vector, the potentional values is one less from (i-1)th position, traverse all possible values in ith position and push it, don’t forget pop it out for traversing to the next possible value; and the end of recursive is when only one element left. 123456789101112131415161718192021void sol(vector&lt;int&gt;&amp; nums, vector&lt;int&gt;&amp; tmp, vector&lt;vector&lt;int&gt;&gt;&amp; idx_vector )&#123; if(nums.size() == 1) &#123; tmp.push_back(nums[0]); idx_vector.push_back(tmp); tmp.pop_back(); return ; &#125; for(int i=0; i&lt; nums.size(); i++) &#123; tmp.push_back(nums[i]); vector&lt;int&gt; nums2 = nums; nums2.erase(nums2.begin()+i); sol(nums2, tmp, idx_vector); tmp.pop_back(); &#125; return;&#125; test: 123456789101112131415161718int main()&#123; vector&lt;int&gt; nums = &#123;1, 2, 3, 4&#125;; int size = nums.size(); vector&lt;int&gt; tmp ; vector&lt;vector&lt;int&gt;&gt; outs; sol(nums, tmp, outs); vector&lt;int&gt;::iterator it ; for(int i=0; i&lt; size*(size-1); i++) &#123; for(it = outs[i].begin(); it != outs[i].end(); it++) cout&lt;&lt; *it &lt;&lt; ' ' ; cout &lt;&lt; "\n" &lt;&lt; endl ; &#125; return 0;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MIT 6.S094 Deep Learning for Self Driving Cars]]></title>
    <url>%2F2018%2F08%2F10%2FMIT-s094%2F</url>
    <content type="text"><![CDATA[1 Deep Reinforcement Learning linkapps: motion planning 2 Convolutional Neural Networks linkapps: End-2-end driving task(pedestrian detect) 3 Recurrent Neural Networks linkapps: steering control through time CNN Project: DeepTeslaDRL Project: DeepTrafficFramework: ConvNetJS]]></content>
  </entry>
  <entry>
    <title><![CDATA[C++ template and STL containers]]></title>
    <url>%2F2018%2F08%2F10%2FC-template-and-STL-containers%2F</url>
    <content type="text"><![CDATA[I used C++ couple years already, but never take a close look at it. when looking back to few C++ demo works at school, I had a strong feeling at that time, to make the code running is my only goal, how it work or how to improve it, is always ignored, I am afraid in the language details, as the wisdom say: the evil is in details. after working for three years, I feel the necessary and urgent to back to the language itself(e.g. Linux, C/C++) as the first step to move forward in application development. Frameworks, engineering-based APIs are more close to final products, making them easy to be attracted, compared to how the details implemented. like the mechanical undergradute students, who first-time run ABAQUS with beatiful visulized results, feels so good. anyway I have to delay the short satification or self-feeling-good. C is clean and the applications have clear structure, C++ is more metaphysics, I even don’t know where to start. even I thought I knew C++ well, but actualy there are many details behind, e.g. allocator in STL. templatetemplate is used for generic programming, e.g. both vector and vector smell same at compiler time. Template reels off or abstract the common part “vector” as a container, and whatever type is ok to store in. function template123456789101112template &lt;class T&gt; void func(T arg)template &lt;typename T&gt; void func(T arg)template &lt;class T&gt; T add(T n1, int v)&#123;&#125;;template &lt;class T1, class T2, class T3&gt; T3 func(T1 a1, T2 a2, int arg3=3)&#123;&#125;; the actual meaning of TYPE is deduced by compiler depending on the arg passed to this function. “class” or “typename” is similar. template supports default parameters, once the i-th argument is set with default value, all arguments after it must using default values. class template123456789101112template&lt;class _Tp, class _Ref, class _Ptr&gt;class _list_iterator &#123; typedef _List_iterator&lt;_Tp, _Tp&amp;, _Tp*&gt; iterator ; typedef _List_iterator&lt;_Tp, const _Tp&amp;, const _Tp*&gt; const_iterator ; typedef _List_iterator&lt;_Tp, _Ref, _Ptr&gt; _Self ; typedef _Tp value_type ; typedef _Ptr pointer; typedef _Ref reference ; typedef _List_node&lt;_Tp&gt; _Node; &#125; feel the power of template in STL source code. STL containersreferences:&lt;&lt; the annotated STL source using SGI STL &gt;&gt; by jjHoua visitor guide to C++ allocatorthe annotated STL sourceI took several days to start, cause the first section on allocator already blocked me. why allocator ?The logic of a dynamic container doesn’t depend on the specifies of how memory is obtained; namely, the design of container classes should be decoupled from the memory allocation policy. how allocator works ?memory allocation and object construction is separated, allocator has four operations: allocate(), deallocate(), construct(), destroy(). there are std interface to allocators 1234567AllocTraits = std::allocator_traits&lt;alloc&gt; // define an allocator of type "alloc" AllocTraits::pointer p = AllocTraits::allocate(a, n) //get memory space for n objects of type T, but not construct yet AllocTraits::construct(a, trueaddress(ptr), x, y, z) ; //construct a T(x, y, z)AllocTraits::destroy(a, trueaddress(ptr)); // ~T()AllocTraits::deallocate(a, ptr, 1) ; // deallocate the space for one T object WHEN we say A is an allocator for T , where T is a type e.g. AllocatTraits::value_type. we mean, A knows how to obtain and release memory to store objects of type T. git:allocator iteratoriterator is used to build algorithms in containers. while I don’t really get the traits 1234567891011121314151617template &lt;class _Iterator&gt;struct iterator_traits &#123; typedef typename _Iterator::iterator_category iterator_category ; typedef typename _Iterator::value_type value_type ; typedef typename _Iterator::difference_type difference_type ; typedef typename _Iterator::pointer pointer; typedef typename _Iterator::reference reference ;&#125;;template&lt;class _Tp&gt;struct iterator_traits&lt;_Tp*&gt; &#123; typedef typename random_access_iterator_tag iterator_category ; typedef typename _Tp value_type ; typedef typename ptrdiff_t difference_type ; typedef typename _Tp* pointer; typedef typename _Tp&amp; eference ;&#125;; vectorstd::vector is dynamic, continous. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071template &lt;class _Tp, class _Alloc = __STL_DEFAULT_ALLOCATOR(_Tp)&gt;class vector:: protected _Vector_base&lt;_Tp, _Alloc&gt;&#123; public: typedef _Tp value_type ; typedef value_type* pointer ; typedef const value_type* const_pointer ; typedef value_type* iterator ; typedef const value_type* const_iterator ; iterator begin() &#123;return _M_start;&#125;; iterator end() &#123;return _M_finish ;&#125;; protected: _Tp* _M_start ; // the starting point of current used space _Tp* _M_finish; // the ending point of current sued space _Tp* _M_end_of_storage; // the end of total avialable space(capacity) public: explicit vector(const allocator_type&amp; __a = allocator_type()) : _Base(__a)&#123;&#125; //default constructor // construt of n elements of initial-value vector(size_type __n, const _Tp&amp; __value, const allocator_type&amp; __a = allocator_type()) : _Base(__n, __a) &#123; _M_finish = uninitialized_fill_n(_M_start, __n, __value); &#125; //copy construtor vector(const vector&lt;_Tp, _Alloc&gt;&amp; __x) :_Base(__x.size(), __x.get_allocator()) &#123; _M_finish = uninitialized_copy(__x.begin(), __x.end(), _M_start); &#125; size_type size() const &#123;return size_type(end() - begin());&#125; size_type capacity() const &#123;return size_type(_M_end_of_storage - begin()); bool empty() const&#123;return begin() == end();&#125; reference operator[](size_type __n)&#123;return *(begin() + __n);&#125; void reserve(size_type __n)&#123; if (capacity() &lt; __n) &#123; const size_type __old_size = size(); iterator __tmp = _M_allocate_and_copy(__n, _M_start, _M_finish); destroy(_M_start, _M_finish); _M_deallocate(_M_start, _M_end_of_storage-_M_start); _M_start = __tmp; _M_finish = __tmp + __old_size ; _M_end_of_storage = _M_start + __n ; &#125; &#125; void push_back(const _Tp&amp; __x) &#123; if(_M_finish != _M_end_of_storage) &#123; construct(_M_finish, __x); ++_M_finish; &#125;else _M_insert_aux(end(), __x); &#125; template&lt;class _Tp, class _Alloc&gt; inline bool operator==(const vector&lt;_Tp, _Alloc&gt;&amp; __x, const vector&lt;_Tp, _Alloc&gt;&amp; __y) &#123; return __x.size() == __y.size() &amp;&amp; equal(__x.begin(), __x.end(), __y.begin()); &#125;&#125;; liststd::list is cycling double-direction link list. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140struct _List_node_base &#123; _List_node_base * _M_next ; _List_node_base * _M_prev ;&#125;;template &lt;class _Tp&gt;struct _List_node : public _List_node_base &#123; _Tp _M_data;&#125;;struct _List_iterator_base &#123; typedef size_t size_type ; typedef ptrdiff_t difference_type ; typedef bidirectional_iterator_tag iterator_category; _List_node_base* _M_node ; //constructor _List_iterator_base(_List_node_base* __x) : _M_node(__x)&#123;&#125; _List_iterator_base()&#123;&#125;; void _M_incr() &#123; _M_node = _M_node-&gt;_M_next; &#125;; void _M_decr() &#123; _M_node = _M_node-&gt;_M_prev; &#125;; bool operator==(const _List_iterator_base&amp; __x) const &#123; return _M_node == __x.M_node ; &#125;&#125;;template&lt;class _Tp, class _Ref, class _Ptr&gt;struct _List_iterator : public _List_iterator_base &#123; typedef _List_iterator&lt;_Tp, _Tp&amp;, _Tp*&gt; iterator ; typedef _List_iterator&lt;_Tp, const _Tp&amp;, const _Tp*&gt; const_iterator ; typedef _List_iterator&lt;_Tp, _Ref, _Ptr&gt; _Self ; typedef _Tp value_type ; typedef _Ptr pointer; typedef _Ref reference ; typedef _List_node&lt;_Tp&gt; _Node; //constructor _List_iterator(_Node* __x): _List_iterator_base(__x)&#123;&#125; _List_iterator()&#123;&#125; reference operator*() const &#123;return ( (_Node*) _M_node)-&gt;_M_data; &#125; _Self&amp; operator++() &#123; this-&gt;_M_incr(); return *this; &#125;&#125;;template &lt;class _Tp, class _Alloc=_STL_DEFAULT_ALLOCATOR(_Tp)&gt;class list : protected _List_base&lt;_Tp, _Alloc&gt;&#123; public: typedef _List_node&lt;_Tp&gt; _Node; protected: _List_node&lt;_Tp&gt; * _M_node; public: list(size_type __n, const _Tp&amp; __value, const allocator_type&amp; __a = allocator_type()) : Base_(__a) &#123; insert(begin(), __n, __value); &#125; explicit list(size_type __n) :_Base(allocator_type()) &#123; insert(begin(), __n, _Tp()); &#125; protected: _Node* _M_create_node(const _Tp&amp; __x) &#123; _Node* __p = _M_get_node(); __STL_TRY &#123; _Construct(&amp;_p-&gt;_M_data, __x); &#125; return __p; &#125; public: iterator begin() &#123; return (_Node*)(_M_node-&gt;_M_next);&#125; iterator end() &#123; return _M_node; &#125; bool empty() const &#123;return _M_node-&gt;_M_next == _M_node ;&#125; size_type size() const &#123; size_type __result = 0; distance( begin(), end(), __result); return __result; &#125; size_type max_size() const &#123;return size_type(-1);&#125; reference front() &#123;return *begin();&#125; reference back() &#123;return *(--end());&#125; void swap(list&lt;_Tp, _Alloc&gt;&amp; __x) &#123; __STD::swap(_M_node, __x._M_node); &#125; interator insert(iterator __position, const _Tp&amp; __x) &#123; _Node* __tmp = _M_create_node(__x); __tmp-&gt;_M_next = __position._M_node ; __tmp-&gt;_M_prev = __position._M_node-&gt;_M_prev ; __position._M_node-&gt;_M_prev-&gt;_M_next = __tmp; __position._M_node-&gt;_M_prev = __tmp; return __tmp; &#125; void push_front(const _Tp&amp; __x)&#123;insert(begin(), __x);&#125; void push_back(const _Tp&amp; __x)&#123;insert(end(), __x);&#125; iterator erase(iterator __position) &#123; _List_node_base* __next_node = __position._M_node-&gt;_M_next ; _List_node_base* __prev_node = __position._M_node-&gt;_M_prev ; _Node* __n = (_Node*) __position._M_node ; __prev_node-&gt;next = __next_node ; __next_node-&gt;prev = __prev_node; _Destroy(&amp;__n-&gt;_M_data); _M_put_data(__n); return iterator((_Node*) __next_node); &#125;&#125; dequeuestd::dequeue can operate elements at both ends, and the memory is multi-sectional, in each memory section is linear continous, with advantage of vector and list. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155template &lt;class _Tp, class _Ref, class _Ptr&gt;struct _Deque_iterator &#123; typedef _Deque_iterator&lt;_Tp, _Tp&amp;, _Tp*&gt; iterator ; typedef _Deque_iterator&lt;_Tp, const _Tp&amp;, const _Tp*&gt; const_iterator ; static size_t _S_buffer_size() &#123;return __deque_buf_size(sizeof(_Tp));&#125; typedef random_access_iterator_tag iterator_category; typedef _Tp value_type ; typedef _Ptr pointer; typedef _Ref reference; typedef size_t size_type ; typedef ptrdiff_t difference_type ; typedef _Tp** _Map_pointer ; typedef _Deque_iterator _Self; _Tp* _M_cur ; //current point in cache _Tp* _M_first; //first point in cache _Tp* _M_last; _Map_pointer _M_node ; /* deque support multi-section memory space, in each memory section is linear continous * Map index is used to point to the memory sections */ _Deque_iterator(_Tp* __x, _Map_pointer __y) :_M_cur(__x), _M_first(*__y), _M_last(*__y + _S_buffer_size()), _M_node(__y) &#123;&#125; //default //copy difference_type operator-(const _Self&amp; __x) const &#123; return difference_type(_S_buffer_size()) * (_M_node - __x.M_node - 1) + (_M_cur - _M_first) + (__x._M_last - __x._M_cur); &#125; _Self&amp; operator++() &#123; ++_M_cur ; if(_M_cur == _M_last)&#123; _M_set_node(_M_node + 1); _M_cur = _M_first; &#125; return *this; &#125; _Self&amp; operator--() &#123; if(_M_cur == _M_first)&#123; _M_set_node(_M_node - 1); _M_cur = _M_last; &#125; --_M_cur ; return *this; &#125;&#125; /* deque has two iterator: start -&gt; the first element in first cache space; finish -&gt; the last element in last cache space */template &lt;class _Tp, class _Alloc&gt;class _Deque_base &#123; protected: _Tp** _M_map ; size_t _M_map_size; iterator _M_start; iterator _M_finish;&#125;;template &lt;class _Tp, class _Alloc = __STL_DEFAULT_ALLOCATOR(_Tp)&gt;class deque : protected _Deque_base&lt;_Tp, _Alloc&gt;&#123; public: typedef typename _Base::iterator iterator ; typedef typename _Base::const_iterator const_iterator ; protected: using _Base::_M_map ; using _Base::_M_map_size ; using _Base::_M_start ; using _Base::_M_finish ; public: explicit deque(const allocator_type&amp; __a = allocator_type()) :_Base(__a, 0) &#123;&#125; deque(const deque&amp; __x): _Base(__x.get_allocator(), __x.size()) &#123; uninitialized_copy(__x.begin(), __x.end(), _M_start); &#125; ~deque()&#123; destroy(_M_start, _M_finish);&#125; void push_back(const value_type&amp; __t) &#123; if(_M_finish._M_cur != _M_finish._M_last - 1) &#123; construct(_M_finish._M_cur, __t); ++_M_finish._M_cur ; &#125;else _M_push_back_aux(__t); &#125; void push_front(const value_type&amp; __t) &#123; if(_M_start._M_cur != _M_start._M_first) &#123; construct(_M_start._M_cur - 1, __t); --_M_start._M_cur; &#125;else _M_push_front_aux(__t); &#125; void pop_back() &#123; if(_M_finish._M_cur != _M_finish._M_first) &#123; --_M_finish._M_cur; destroy(_M_finish._M_cur); &#125;else _M_pop_back_aux(); &#125; void pop_front() &#123; if(_M_start._M_cur != _M_start._M_last -1) &#123; destroy(_M_start._M_cur); ++_M_start._M_cur; &#125;else _M_pop_back_aux(); &#125; iterator insert(iterator position, const value_type&amp; __x) &#123; if(position._M_cur == _M_start._M_cur) &#123; push_front(__x); return _M_start; &#125;else if(position._M_cur == _M_finish._M_cur) &#123; push_back(__x); iterator __tmp = _M_finish; --__tmp; return __tmp; &#125; &#125;&#125;; stackstd::stack only operate on the top element (first in last out), can’t iterate the container, the default container for stack is deque. 123456789101112131415161718192021222324252627temlate &lt;class _Tp, class _Sequence&gt;class stack&#123; public: typedef typname _Sequence::value_type value_type ; typedef typname _Sequence::size_type size_type ; typedef typname _Sequence container_type ; typedef typname _Sequence::reference reference ; typedef typname _Sequence::const_reference const_reference; protected: _Sequence c; // the fundmental container: deque by default public: stack() : c() &#123;&#125; explicit stack(const _Sequence&amp; __s) : c(__s) &#123;&#125; bool empty() const &#123; return c.empty();&#125; size_type size() const &#123;return c.size();&#125; reference top() &#123;return c.back(); &#125; void push(const value_type&amp; __x)&#123; c.push_back(__x);&#125; void pop() &#123; c.pop_back();&#125; template&lt;class _Tp, class _Seq&gt; bool operator==(const stack&lt;_Tp, _Seq&gt;&amp; __x, const stack&lt;_Tp, _Seq&gt;&amp; __y) &#123; return __x.c == __y.c ; &#125;&#125;; queuestd::queue supports only pop element from front, and push element into end, the default container is dequeue 123456789101112131415161718192021222324252627template &lt;class _Tp, class _Sequence&gt;class queue&#123; public: typedef typname _Sequence::value_type value_type ; typedef typname _Sequence::size_type size_type ; typedef typname _Sequence container_type ; typedef typname _Sequence::reference reference ; typedef typname _Sequence::const_reference const_reference; protected: _Sequence c; // the fundmental container: deque by default public: queue() : c() &#123;&#125; explicit queue(const _Sequence&amp; __s) : c(__s) &#123;&#125; bool empty() const &#123; return c.empty();&#125; size_type size() const &#123;return c.size();&#125; reference top() &#123;return c.back(); &#125; void push(const value_type&amp; __x)&#123; c.push_back(__x);&#125; void pop() &#123; c.pop_front();&#125; template&lt;class _Tp, class _Seq&gt; bool operator==(const queue&lt;_Tp, _Seq&gt;&amp; __x, const queue&lt;_Tp, _Seq&gt;&amp; __y) &#123; return __x.c == __y.c ; &#125;&#125;; priority queuestd::priority_queue is queue with priority.]]></content>
      <tags>
        <tag>c++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[design a threadpool in pure C]]></title>
    <url>%2F2018%2F08%2F02%2Fdesign-a-threadpool-in-pure-C%2F</url>
    <content type="text"><![CDATA[actually this post should be named as “pure C multithreads”, while it’s better to write some real code. a simple threadpool in pure C exposed APIsat most simple case, what a threadpool object should do? thpool_init(num_threads); thpool_destory(threapool_obj); thpool_add_work(callback, args); // so user define event callback() can be passed in; threadpool is used to assign jobs (from job list) to a thread. so joblist should be an internal class; and it’s better to package thread, job as separate class too; to add work, what kind of funcs need for joblist ? at least, to add new job(from outside) to the joblist. internal structures:123456789101112131415161718192021222324252627struct thread &#123; int id; pthread_t thread; //pthread_t is a unsigned long int; it's system assigned threadpool *thpool; //so thread know its domain&#125;struct job &#123; (void*) func(void*); // each job/task should have a callback func (void*) func_arg ; //and func args //since consider joblist as a list, it's helpful to add pointers to neighbors job* prev; job* next;&#125;struct jobqueue &#123; int num_jobs; job* front; job* rear; //some flags to support add new node(job) to the list&#125; struct threadpool_ &#123; thread* threads_array; jobqueue job_queue; // some flags &#125; consider syncronlizationwill multi threads call add_task() simutaneously? if so, jobqueue should have a mutex object; 123456 struct jobqueue &#123; int num_jobs; job* front; job* rear; pthread_mutex_t jq_mutex;&#125; during threadpool initialization, will all threads be created simultaneously and immediately? if not, there should be thread status flags (creating, exisiting-but-idle, working, died); and to update these flags need protect by mutex object; 123456struct threadpool_ &#123; thread* threads_array; jobqueue job_queue; int num_threads; //stands for the number of all existing threads pthread_mutex_t tp_mutex; &#125; this is an interesting, when design a lib, what’s in my mind. hopefully implement by the end of week.]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pure C socket]]></title>
    <url>%2F2018%2F07%2F31%2Fpure-C-socket%2F</url>
    <content type="text"><![CDATA[this is a review from GNU C lib. socket is a two-way communication channel, both read and write can be performed at either end. sys/socket.h123456789101112131415161718192021222324252627282930313233343536373839int socket(AF_INET, SOCK_STREAM, protocol); /* return fd for this new socket, or -1 as error */int close(int socket_fd); /* return 0 when close successfuly, else return -1 */int connect(int socket, struct sockaddr *addr, socketlen_t len);/* initiate a connection from (client) socket to (server) address; by default, the connection is blocking untill server respond */int listen(int socket, int n);/* n specifies the length of queue for pending connections; when the queue fills up, new clients attempting to connect will fail */int accept(int socket, struct sockaddr *addr, socketlen_t *len_ptr);/* if successfully, accept return a new socket fd, the original (server) socket remains open and unconnected; the address and len_ptr are used to return information about the name of client socket that initiated this connection */size_t send(int socket, const void *buffer, size_t size, int flags);/* param socket is the fd of current sending socket. no receiver socket explicitly defined, since connection-oriented(TCP)protocol will connect first prior to send/receive */size_t recv(int socket, const void *buffer, size_t size, int flags);/* param socket is the fd of current receiving socket */``` ## network socket I didn't realize GNU C socket I/O is so related to network socket. the missing part when reading muduo, libuv is here. The server listens the connection requests on the special server socket, then accept each incoming connection. select() blocks/sleeps the program until input is available/ready on the special server socket/fd. ```cvoid FD_ZERO(fd_set *set) /* initialized the file descriptor set to empty set */void FD_SET(int fd, fd_set *set) /* add fd to set */void FD_CLR(int fd, fd_set *set) /*remove fd from set */void FD_ISSET(int fd, const fd_set * set) /* return true(non-zero) if fd is in set; else return 0 */STDIN_FILENO ; /* file descriptor for std input “1” */ how to debug server/client code? chatRoom]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pure C I/O]]></title>
    <url>%2F2018%2F07%2F31%2Fpure-C-i-o%2F</url>
    <content type="text"><![CDATA[this is a review from GNU C programming streamtwo basic mechanism for representing the connection between your program and the file: streams &amp; file descriptors. FD is represented as objects of type int; streams are represented as FILE * objects a stream is an abstract concept reprensenting a communication channel to a file, a device, or consider it as a sequence of characters with functions to take characters out of one end, and put characters into the other end, like a pipe. file positionan integer representing the number of bytes from the beginning of the file; each time a character read or written, the file position is incremented, namely, access to a file is sequential. 12345678910111213141516171819202122long int ftell(FILE \* stream); //return file position int fseek(FILE \*stream, long int offset, int whence);/\* whence is SEEK\_SET | SEEK\_CUR | SEEK\_END \*/``` “write to a file” is always appended sequentially to the end of the file, regardless of the file position; but “read from a file” is used the current file position. which means multiple reading can happens simultaneously with an independent file pointer. In fact, each opening creates an independent file position pointer, even in the same program to open a file twice. ## std streams```c FILE *stdin ; FILE *stdout; FILE *stderr; FILE *fopen(const char *filename, const char *openMode); /* create a new stream connected to the file */ int fclose(FILE *stream) /* disconnected between the stream and the file, any buffered output is written and any buffered input will discarded */ ASCII IO123456789int fputs(const char *s, FILE *stream) ;/* write a char array into stream. this call doesn't add a newline or terminal null character */char *fgets(char *s, int n, FILE *stream);/* read n number of char array from stream, default add a newline character */ssize_t getline(char **lineptr, size_t *n, FILE *stream);/* read a whole line from stream */ block IOusually block stands for either block data or text in fixed-size, instead of characters or lines 12345size_t fread(void *data, size_t size, size_t n, FILE *stream);/* read #n block, each block has size from stream, and store in data */size_t fwrite(const void *data, size_t size, size_t n, FILE *stream);/* write #n block, each block has size from buffer data to stream */ formatted IO1234567int printf(const char *template, …); //write to std outputint fprintf(FILE *stream, const char *template, ...); write to streamint sprintf(char *s, const char *template, ...); //write to a stringint scanf(const char *template, …) //formatted read from stdinint fscanf(FILE *stream, const char *template, …) // read from stream int sscanf(const char *s, const char *template, …) // read from a string EOF1234int feof(FILE* stream) ; /* return nonzero iff end of file indicator is set for stream */int ferror(FILE* stream) ; /* return nonzero iff error indicator is set for stream */ stream bufferstream and file is not communicated character-by-character, there is a buffer for I/O. 12int fflush(FILE *stream) /* take any buffered output on stream to be delivered to the file */ file descriptor123456789101112int open(const char *filename, int flags);int open64(const char *filename, int flags) ;// allow large file mode size_t read(int fd, void *buffer, size_t size) // read from fd size bytes into buffer size_t pread(int fd, void *buffer, size_t size, off_t offset) // start reading from position “offset” size_t write(int fd, const void *buffer, size_t size) off_t lseek(int fd, off_t offset, int whence) // change the file position of fd FILE *fdopen(int fd, const char *opentype) // return a new stream for this fd synchronizing I/O1234void sync(void) ;// to ensure all operations finished before they return int fsync(int fd) ;// to ensure all data associated with the fd is written to the device not yetasync I/O, event I/O, interrupt driven I/O, GPIO …]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux at work]]></title>
    <url>%2F2018%2F07%2F26%2FLinux-at-work%2F</url>
    <content type="text"><![CDATA[bash environment/etc/profile -&gt; hold shell environment &amp; startup settings ~/.bashrc -&gt; system wide definitions for shell funcs &amp; alias ~/.bash_profile -&gt; user environment individually ususally during coapplication configuration on Mac or Linux, mostly use ~/.bashrc to add project related environment variables. regular expressions the$ :matches the line ending with “the” ^the :matches the line starting with “the” [^g]abc : search “abc” but not starting with “g” [^abc…z][0-9] : search numbers but not with alphabet in front ^[a-z] : search the line starting with low alphabet ^[^a-z]: search the line starting without low alphabet ^$ : match white space [xyz]: general match anyone from “xyz” [!xyz]: general match in opposite, neither from “xyz” shell expressions command &amp; : to run command in bg $! : current PID $# : number of arguments $1 : the first paramter $* : wildcard for all variables Linux commands ldd: check runtime lib unix2dos / dos2unix: change file format between Windows and Linux ps : print running processes in current terminal ipcs : check share memory portion in current system ipcrm -M ipc_key : remove the shared memory portion id by ipc_key top: print virtual,resident,shared memory percentage basename: e.g. basename /path/to/file -&gt; file wc -l .file: print total lines of the file df: check the usage of disk find . -type f -print0 | xargs -0 grep -l “xx” find D:\ | grep xml less .file : read the last few lines of file ln item link : soft link ln -s item link : hard link type command : check the type of command cat f1 f2 &gt; merged sort uniq comm f1 f2 : the common part of f1 and f2 diff f1 f2 : the difference of f1 and f2 2 &gt;&amp; 1: redirect std output(fd=2) to std error(fd=1) nm : check libs used in current executable(T defined, U undefined) gdbMPI gdb: (each MPI thread will have an independent terminal window) mpirun -np #cpus xterm -e gdb ./exe set breakpoint in different src: b sth.cxx:20 print an array: p (int[length]* a) add input file: set args -j input_file load src after triggering GDB: gdb file exe set args -j input_file books about Linuxbash guide for beginnerstao of regular expressionLinux programmer’s manualLinux system administrators guideC expert programmingwhat every programmer should know about CPU caches resources in multi-core optimizationunderstand CPU utilization &amp; optimizationIntel: optimization applications for NUMAIntel guide for developing multithreaded applicationsMPI parallel programming in Pythonconsiderations in software design for multi-core, multiprocessor architectureshow to optimize GEMMoptimize for Intel AVX using MKL with DGEMMGEMM: from pure C to SSE optimized micro kernela practical guide to SSE SIMDD with C++multi-core designUnix and pthread programming resources in applicationsintroduction to post processing finite element results with AVSCAE Linux: FEA inter-operabilityopen sourcing a Python project the right wayPPSSpyNastranhdfviewervalgrind postscriptstarting from 2016, I had went through each hot topic nowadays, even did some study in DL, AV, CV etc. every time the passion burst out and I promised to e.g. study a framework, or contribute an open project. in reality, the passion dies away soon. It’s like a new and very attracting concept bump out in the market, but no business model can handle it, then it dies out. downside of this learning pattern is that the fundmental is ignored. e.g. I can’t success in code interview, few experience in basic algorithms. kind of person always vision the big, but don’t realize how to reach there. it’s kind of wasting finally, just want to be focus at this moment.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pure C structure]]></title>
    <url>%2F2018%2F07%2F26%2FPure-C-structure%2F</url>
    <content type="text"><![CDATA[definition12345typedef struct gid_ &#123; double x; double y; char* name ; &#125; gid ; typedef defines “gid” as an alias name to “struct gid_ “. typedef also alias function handle/pointer, which is often used in asynchronous/event callback programming. other data encapsulation are: enum : map a list of const names to integral constants union: store many data type in one memory address initialization123gid g1=&#123;2.0, 3.0, "g1"&#125;;gid g2=&#123;.x=2.0, .y=3.0, .name="g2"&#125;;gid g3=(gid)&#123;2.0, 3.0, "g3"&#125;; in C++, structure initialization can also be done in constructor. memory alignmentfor better memory access in CPU architecture, memory alignment in structure is considered. namely: chars can start on any byte address 2-bytes shorts must start on an even address 4-bytes ints/floats must start on an address divisible by 4 8-bytes doubles/longs must start on an address divisible by 8 the size of the whole structure, is aligned to intergeral times of the max size of its member variable. e.g. sizeof(gid) = 24, not 8+8+4. to put the member variables in ascending/descending order is good practice. structure pointer arithmetic“gid++” will step forward the sizeof(gid); structure also supports self-reference: 123456typedef struct gid_ &#123; char *name ; double x; double y; gid_ *next_gid ; &#125; gid ; another common utils is structure array: 12gid gid_list[MAX_SIZE]; gid **gid_list_p ; structure as function parametersin general, structure can be passing to function by value or by pointer, but not by reference in pure C. also structure as return value from function can be value or a pointer structure in C++in C++, structure supports member functions, is same as a public class. and the initialization can be done either in constructor function or direct initialization during definition. see the difference of struct between C and C++ stdlib.h123456789101112131415161718 /* convert string s1 to an int*/ int atoi(const char* s1); /* memory op */ void* malloc(size_t size); void free(void *ptr); /* system level op */ char* getenv(const char *name); int system(const char *command); /* algorithms */ void* bsearch(const void* key, const void* base, size_t nitems, size_t size, int(*compar)(const void*, const void*)) void qsort(void *base, size_t nitems, size_t size, int(*compar)(const void*, const void*))]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pure C string]]></title>
    <url>%2F2018%2F07%2F24%2Fpure-C-string%2F</url>
    <content type="text"><![CDATA[string initializationin pure C, string is a char array terminating with NULL(‘\0’). To initialize an array of char(string) is with a string literal(a double-quotaed string). in general, the string literal is used as the initializer for an array of char; anywhere else, it is a static array of chars, which shouldn’t be modified by a pointer. 123456789101112131415161718192021222324252627282930313233/* initialize a string in C * the size of s1 is taken from the size of the initializer */ char s1[] = "hello world" ; // or char s1[12] = "hello world"; /* common errors */ char s2[]; s2 = "hello world"// error: storage size of 's2' isn't known char s2[12]; s2 = "hello world"// error: invalid array assignment /* there is no "=" operator defined for char array in C using strcpy()*/``` ## char pointer arithmetic ```c char s1[12]; *s1++ ; /* error: lvalue requied as increment operand * s3 is an array, can't modify the address of an array. the difference between pointer and array */ char* s2 = s1; *s2++;/* s2 is a pointer to s1, ++ is ok */ string.h1234567891011121314151617181920212223242526/* concatenate two strings */strcat(char* s1, const char* s2) ;strncat(char* s1, const char* s2, size_t n); /* locate the first/last occurance of char c in string s */strchr(const char* s1, int c);memchr(const void* s1, int c, size_t n);strrchr(const char* s1, int c); /* compare s1 and s2 alphabetically */strcmp(const char* s1, const char* s2); strncmp(const char* s1, const char* s2, size_t n);memcmp(const void* s1, const void* s2, size_t n);/* copy s2 to s1 */strcpy(char *s1, const char *s2); memcpy(void* s1, void* s2, size_t n);/* number of bytes, not including terminating NULL; sizeof() will inlcude the terminating NULL */strlen(const char* s1); /* find the first occurance of substring s2 in s1 */strstr(const char *s1, const char *s2);/* split string s1 into a sequence of tokens by s2 */strtok(char* s1, const char* s2); \ is replaced by in C++.and be aware of downs of C string.]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[which function is called]]></title>
    <url>%2F2018%2F07%2F18%2Fwhich-function-is-called%2F</url>
    <content type="text"><![CDATA[which function is calledwhen a derived object calls the base class member function, inside which calls another virtual member function, which is implemented inside the derived class, so which virtual member function is actually called ? 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;class Weld &#123; public: Weld()&#123;&#125;; virtual ~Weld()&#123;&#125;; virtual bool getDataIndex()&#123; std::cout &lt;&lt; "Weld::getDataIndex" &lt;&lt; std::endl; return true ; &#125; bool getInternalDataList()&#123; return getDataIndex(); &#125;&#125;;class SpotWeld: public Weld&#123; public: SpotWeld()&#123;&#125;; virtual ~SpotWeld()&#123;&#125;; virtual bool getDataIndex()&#123; std::cout &lt;&lt; "SpotWeld::getDataIndex" &lt;&lt; std::endl; return true; &#125;&#125;;class ACM2 : public SpotWeld&#123; public: ACM2()&#123;&#125;; ~ACM2()&#123;&#125;; virtual bool getDataIndex()&#123; std::cout &lt;&lt; "ACM2::getDataIndex" &lt;&lt; std::endl; return true; &#125; bool getPoints()&#123; return getInternalDataList(); &#125;&#125;;int main()&#123; ACM2 acm2 ; acm2.getPoints(); return 0;&#125; output is: ACM2::getDataIndex so the derived object always calls the member function that most closest to its own class domain first, even if this member function is called from a base class member function.]]></content>
      <tags>
        <tag>c++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[multi-core at work]]></title>
    <url>%2F2018%2F07%2F13%2Fmulti-core-at-work%2F</url>
    <content type="text"><![CDATA[NUMAuniform memory arch, all CPUs in the same sokcet shall the memory, and the memory IO is bottleneck; non uniform memory acess(NUMA), each CPU has itw own memory, inter-CPU memory access is remote. numctl cpu_node_bind MPI binding APIs memory allocation strategy in NUMA interleave: place the memory on alternating node, the first memory portion in node0, the next portion in node1 membind: forcely to allocate memory in special node CPU affinitythe benifit of CPU affinity is to reduce context switch since one special process is binded to one speical CPU, so the data required in this process (no other process data will be switched in), can always in the CPU cache. espcially for NUMA arch to access data locally. and this is specially true when the application generate a large cache footprint, e.g. in scientific computing. for general applications, CPU afinity may reduce performance, since in this way the CPU scheduler can’t work properly. CPU info/proc/cpuinfo physical id: socket indexsiblings: number of cores in each socketcore id: current core index e.g. Ford HPC CPU architecture: 2 or 4 CPU sockets group into one computing node each socket has 10 or 12 CPU cores each socket has a on-board shared memory atomic operationCPU physical mechanism: physically there is a bus #hlock pin. if #lock is added before the assembly instruction, the corresponding machine code will be pulled down during the execution of the #hlock pin till the end, basically the bus is locked only for current instruction cache coherence: the cache unit tranfered between CPU and main memory is cache line. in one socket, as slibings share L3 cache, there is an scenario, when CPU1 modified one variable, but not yet writen to main memory, and CPU2 read from main memory and did modified again, then the variable in CPU1 and CPU2 is not coherence. volatile in C, forcely to read the variable value from main memory every time, to avoid use dirty memory in cache another scenario, to achieve and cache coherence, and the same variable is read and write repeatly by multiple processes, the performance is worse, “false sharing” lock: signal, also called &quot;sleeping lock&quot;: used when the lock need to keep for a longer time spin lock: at most hold by one thread, to block other threads into critial area, used to keep for a short time. write/read lock: system performanceresident memory(res), the portion of virtual memory space that is actually in RAM; swapped memory, when the physical memory is full and the system needs more memory, inactive pages in memory moved to the shared space, and swapped usable memory in virtual memory = res memory + swapped memory mmap, to access the remote (data block) like access local RAM. voluntary context switches(vcs): when a thread makes a system call that blocks. vcs measures the frequency of calling blocked system I/O involuntary context switches(ivcs): when a thread has being runing too long without making a system call that blocks, and there are other processes waiting for CPU, then OS will switch for other CPUs. ivcs measures the CPU competition, an unfinished processed is switched off in general, as more threads, the context switch cost increase, due to the total amount of switch increase and as well each switch is more expensive, since CPU cache is limited, and each process will hold fewer data in cache. cpu_time (clock_t): the total amount of time that a process has actually used user CPU time: the amount of time spend in user space running system CPU time: the amount of time spent during kernel space running wall-clock time: the whole time from the process start to end Linux IPCinter-process communication(IPC) share memory is used in our application to cowork with MPI. while IPC helps to balance memory distributed in multi computing nodes, and MPI threads are the working horse to eat shared data. there are other IPC libs, e.g. Boost.interprocess. ftok() -&gt; to generate a IPC key, based on a special file path shmget() -&gt; generate a shared memory portion and return a shm_id shmat() -&gt; attach to the shm_id and return a pointer to that shared memory shmctl() shmdt() in design, all threads call shmget() to get a pointer to the share memory section, but actually only master thread do create the portion, others read it. since all thread can access the share memory section, it’s important to keep the first returned pointer from master thread clean/unpolluated. MPIthere are a few basic MPI APIs. in our project, to benefit both CPU and memory performance, we actually need: 1) subgroup the MPI comm, 2) bind MPI threads to sockets. MPI_COMM_GROUP() MPI_Group_incl() MPI_COMM_create() apis and numctl during run-time: mpirun -bycore -bind-to-socket -&gt; bind process to each core on the socket mpirun -bysocket -bind-to-socket mpirun numctl -membind=0 -np 32 ./run]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vehicle network]]></title>
    <url>%2F2018%2F07%2F12%2Fvehicle-network%2F</url>
    <content type="text"><![CDATA[vehicle networ is what connects the different parts together as a vehile. the lower-level basicA few basic concepts: TCP/UDP socket, CAN Bus, Ethernet, MCU register, Ip address, MAC address, Ethernet driver, network configure, how to code a ECU/MCU etc. there are EE students working on this close to physical level implementation, on how to talk with register, MCU pins and controls, and some implementing the data traffic protocol in network. While both are isolated from top applications, since no matter where the data come from, either AV application or connected vehicle or media data, doesn’t make a difference. architecture typical vehicle network architecture beyond the basic, network architecture brings a good vision to understand what makes a vehicle electronicly as a whole. and which is serving all apps with v2x, in-vehicle entertainment, AV. I was thought ECU handling events the same as web server. while they are very different. each ECU is doing only one special task. e.g. ABS ECU only dealing with ABS events, there are no many ABS events happening simultaneously to seize the ECU computing resource; however, a web server have to deal with multiplex request simultaneously, either using thread pool or asynchronous event callbacks. each ECU actually has an easy life, but the bus seems easily choked since around 100+ ECU nodes in the vehicle network. however again, typical vehicle network architecture is very matured products, without data-heavy applications arising, current CAN bus is great. smart phone in wheels?one day in future, every vehicle running on road is requesting some data from cloud seamlessly, the scenario is like billions of browsers send requests to Google server seamlessly, then the cloud may face same issues in today’s web server. Service oriented architecture(SOA) is also rising in vehicle network architeture design, but what kind of services is better locally in vehicle, and which services in cloud ? as hardwares evolution, even the computing-heavy tasks, e.g. vision based detection, path planning in AV, suppose not be a burden for local ECUs. so these services make sense locally served. except that, I only image future vehicle as a smart phone on wheels. so remote cloud server do connect to, e.g. talk to another vehicle, play online game during driving, check weather, find out a parking lot, resturant or similar, or the car company want to steal user data privately? SOA is a good move to decouple ECU modules and make the network bus light, and it’s fun to try some vehicle network architecture open project or play with ROS simulator if hardware required. but in a business view, I don’t know a good story to attract investors, namely vehicle network sounds not that blinking amazing.]]></content>
      <tags>
        <tag>vehicle network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gnu-make]]></title>
    <url>%2F2018%2F06%2F29%2Fgnu-make%2F</url>
    <content type="text"><![CDATA[websocket projects recently reviewed: uWebSocket, which is used in Udacity self-driving car term2 projects. the other is libwebsocket, which is used in automotive message broker(amb). gcc compiler optionsgcc and make: a tutorial on how to compile, link and build c/c++ projects -wall : print all warning messages -c : compile into object, by default the object has same name as the source file -o : specify the output executable filename headers(.h), static libs(.lib, .a) &amp; shared libs(.dll, .so)gcc by default, links to the shared libraries if available. the compiler search “include-paths” for headers, which is specified via -L\ option or CPATH; the linker search “library-paths” to link the program into an executable object, which is specified via -L\ or LIBRARY_PATH, in addition, need to specify the library name via -l the system default “include-paths” can be found by “cpp -v” gcc environment variablesPATH is used to search executable and run-time shared libs. (woo, this suppose to replace LD-LIBRARY-PATH)CPATH is used to search “include-paths”, it’s searched after paths specified in -I&lt;dir> options. C_INCLUDE_PATH &amp; CPLUS_INCLUDE_PATH can be used to specify C &amp; C++ headersLIBRARY_PATH is used to search linking-time “library-paths”, it’s searched after paths specified in -L\ options. the standard directories is /usr/lib Linux utils1) readelf: read ELF 2) ldconfig : by default, read /etc/ls.so.conf, sets up the appropirate symbolic links in the dynamic link dir, and then write a cache to /etc/ld.so.cache, which then is used by other programs 3) ldd: to see recursive shared library dependencies 4) file: determine file type 5) nm: list symbol table of an object file, commonly-used to check if a particular func or variable is defined in an object file. “T” indicates it is defined; “U” means undefined, which should be resolved by the linker. make &amp; cmake[gnu make] (https://www.gnu.org/software/make/manual/html_node/index.html#SEC_Contents) there are many best practical, e.g. effective cmake build libuvit’s built based on GNU autotools sh autogen.sh &quot;libtoolize: AC_CONFIG_MACRO_DIR([m4]) conflicts with ACLOCAL_AMFLAGS=-I m4&quot; fixing-solution, then make all &amp; make install, so here is libuv.so, add the directory to \$LIBRARY_PATH in ~/.bashrc build uWebSocketsit’s built based on gnu make. the tests command has dependents on libuv. since already added libuv directory to \$LIBRARY_PATH, run through. if else, errors output: cannot find -luv collect2: error: ld returned 1 exit status Makefile:xx recipe for targe &apos;tests&apos; failed make: *** [tests] Error 1 try to run ./testsBin, get another error: error while loading shared libraries: libuWS.so: cannot open shared object file: No such file or directory that’s run-time error, since libuWS.so is not included in \$PATH or speically for building/testing purpose, define $LD_LIBRARY_PATH. build libwebsocketsit’s built based on cmake. there is some dependent, but should go through well. beyond the notewhen 2-months ago, looking at amb project, which has websocket plugin module, then find uWebSocket lib, during reading this tiny lib, where libuv APIs are highly-used, and soon found out libuv is actually the event-loop in nodejs. Woo, somehow they are related. build tools are highly used in each project, but prior experience is more done by luck.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[career thoughts]]></title>
    <url>%2F2018%2F06%2F25%2Fcareer-thoughts%2F</url>
    <content type="text"><![CDATA[product data managmentan interesting meeting with material research group, these guys have some IT needs, but does’nt reach there. e.g. there are plenty of material fatigue data, including metadata, tables, S-N plots, so how to organize/manage them? one solution is from MSC Material Center[http://www.mscsoftware.com/news/msc-software-reinvents-materials-lifecycle-management-materialcenter] what triggered me is “data management” in general. In manufacturing industry, like automotive, many old style data used and storied in different departments, e.g. the material property data, load time history data for CAE department, the vehicle diagnostic logging data in vehcile control department, the vehicle dynamics records in vehicle test department. but neither are well-structured nor easy to track. two fields so far: data dashboard, requires data visulization and data mining; product lifecycle management, it’s a product driven, and may also have data dashboard needs. currently as I see, most data analysis is in bussiness driven view, not in product itself. how to accelerate product iteration through better using history products data suppose to be a big thing. on another side, industry data management is a little different than bussiness/market data. e.g. every year Ford releases a new F-150 truck, does it start out of new? no, the 2018 mois stly iterate by the 2017. so there is product data management, just managed through all component departments. maybe the questions should ask is: 1 do we get the most value from these whole product level data? 2 how to make special data manageble at subsystem level? it needs more experience in the whole process, but bring some thoughts in next career: PLM software and data management in special domain, e.g. material datacenter product. cloud CAEsince dashboard is so popluar to migrate the traditional software GUI to web/mobile app; and CAE solver can deployed in cloud, which is a better stronger reason to do user-side dashboard: with job submission, job status, and result plot/visulization sections. but why is it necessary to migrate CAE solvers in cloud? why the manufacturing product companines would like to share their prodcuts data with cloud providers? turn one step back, the most obvious reason is whenever internet is needed, e.g. communication among different end-users, cloud is good chonice; and for startup companies, who can’t afford to run jobs locally, have to migrate their calculation in cloud. I am kind of curious who is using AWS? Netflix, BMW, Autodesk! I was so suprised at first, how BMW and Autodesk would like to use AWS? anyway Netflix is data-flow based company, the core business is client-server communication, which make sense to use AWS. while BMW is using AWS for new business: connected service, all a sudden it makes sense. the car product business won’t be shared with AWS, but cloud is required as infrastructure for v2x connected service. that’s amazing. AutoDesk say a different story in cloud, since they sell CAD softwares, few people want to buy and own an expensive software but choose to pay for the service, by all meaning, this is not a new business, but AWS offer a mature channel. even though, cloud providers say they are cost-reducing, high-scalability, but I don’t think manufacturing companies will buy it due to security, instead they maintain their own clusters and share limited business in cloud. so standing in manufacturing industry, it’s better to figure out new services, which require communications through cloud, than migrate CAE solvers to cloud. that’s my second point.]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo 3]]></title>
    <url>%2F2018%2F06%2F20%2Fmuduo3%2F</url>
    <content type="text"><![CDATA[one concern yesterday: does each worker thread call loop() and run the whole active channels callback ? suppose no. let’s track the process : 123456tcpServer.start() -&gt; threadPool.start() -&gt; new EventLoopThread(eventLoopThread::threadFunc, threadName) eventLoopThread-&gt;startLoop() -&gt; thread.start() -&gt; detail::startThread() -&gt; runInThread()::func_() the real func_ during creating new eventLoopThread, is threadFunc(), in which call loop.loop(). first, this loop object is created inside this new eventLoopThread object, no issue that the loop.threadId_ is current threadID. when multiple worker threads exist, what happens ? threads A B C conns T1 T2 T3 suppose T1 is assigend to worker thread A, etc. when calling eventLoopThread A.loop(), epoll_wait() is first called and return number of active events, epoll_wait() is thread-safe, no worry. then activeChannels:HandleEvents() is called. the real executor of this handleEvents is in the TcpConnection objects, namely: T1 or T2 or T3. each TcpConnection object has its own loop-, and only the worker thread with the same loop- can execute the events. so even though threadA get the list of all active events, but only events in T1 conenction will be executed by threadA. so we can see, in per (worker) thread per epoll, each (worker) epoll looks like only return the active channels/events in current worker thread’s eventLoop. There is no conflict among multiple worker threads, since each worker threas has its own eventLoop. how about eventLoop in server/clientthe eventLoopThread is kind of triggered inside Muduo, where is Tcp server/client eventLoop triggered ? from outsiders.]]></content>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[moduo 2]]></title>
    <url>%2F2018%2F06%2F19%2Fmuduo2%2F</url>
    <content type="text"><![CDATA[The several classes defined in Moduo: TcpServer, Acceptor, TcpConnection, EventLoop, epoller, channel, eventLoopThread, eventLoopThreadPool. 1) TcpServer constructioneach TcpServer suppose have multi- tcp connections, the acceptor works as the main I/O thread, which listen the server-side I/O socket, and handle all client input connections at first, (later will assign the connection task to each worker thread from pool). so the input argument “loop” during TcpServer construction is the main I/O eventLoop. 12345678910111213141516171819202122232425TcpServer::TcpServer(EventLoop* loop, const InetAddress&amp; listenAddr, const string&amp; nameArg, Option option) : loop_(CHECK_NOTNULL(loop)), ipPort_(listenAddr.toIpPort()), name_(nameArg), acceptor_(new Acceptor(loop, listenAddr, option == kReusePort)), threadPool_(new EventLoopThreadPool(loop, name_)), connectionCallback_(defaultConnectionCallback), messageCallback_(defaultMessageCallback), nextConnId_(1)&#123; acceptor_-&gt;setNewConnectionCallback( boost::bind(&amp;TcpServer::newConnection, this, _1, _2));&#125;``` one advantage of bind/callback is to import functors to different class domain. and server has always one I/O socket, but client-socket-fd suppose be a lot. ## 2) TcpServer newConnectionEach new tcp connection, will assign a worker thread to execute the speical callback functor for this new connection, How to schedule thread in threadpool is implemented by round-robin, which are implemented as:```cioLoop-&gt;runInLoop(boost::bind(&amp;TcpConnection::connectEstablished, conn)); EventLoopThreadPool::getNextLoop() does each worker thread run EventLoop.loop(), which will call epoll_wait(), and execute all active channels? suppose no.3) TcpConnection constructioneach new client connection will reponse to a new socket fd, and a new channel. (channel is actually the container of socket fd); and the functors on this connection is also imported to channel callbacks. basically from outside, we only see channel objects, TcpConnection object is the inner class. 123456789101112131415161718192021222324252627TcpConnection::TcpConnection(EventLoop* loop, const string&amp; nameArg, int sockfd, const InetAddress&amp; localAddr, const InetAddress&amp; peerAddr) : loop_(CHECK_NOTNULL(loop)), name_(nameArg), state_(kConnecting), reading_(true), socket_(new Socket(sockfd)), channel_(new Channel(loop, sockfd)), localAddr_(localAddr), peerAddr_(peerAddr), highWaterMark_(64*1024*1024)&#123; channel_-&gt;setReadCallback( boost::bind(&amp;TcpConnection::handleRead, this, _1)); channel_-&gt;setWriteCallback( boost::bind(&amp;TcpConnection::handleWrite, this)); channel_-&gt;setCloseCallback( boost::bind(&amp;TcpConnection::handleClose, this)); channel_-&gt;setErrorCallback( boost::bind(&amp;TcpConnection::handleError, this)); LOG_DEBUG &lt;&lt; "TcpConnection::ctor[" &lt;&lt; name_ &lt;&lt; "] at " &lt;&lt; this &lt;&lt; " fd=" &lt;&lt; sockfd; socket_-&gt;setKeepAlive(true);&#125; so where are channel (read/write/error/close) handleEvent callbacks triggered? it is during the eventloop.loop, after epoller return the active events, based on the status of each revent, special handleEvent is called. 4) eventLoop constructionduring constrution of eventLoop, a new poller is created based on this eventLoop itself, also a new wakeupfd and a new wakeupChannel. the purpose of wakeup fd/channel is to immediately wake up the work thread, rather than waiting till PollTime. and the wakeupfd bind handleRead, in which read one byte to make this wakeupfd I/O readable, which then is ready for I/O. 123456789101112131415161718192021222324252627EventLoop::EventLoop() : looping_(false), quit_(false), eventHandling_(false), callingPendingFunctors_(false), iteration_(0), threadId_(CurrentThread::tid()), poller_(Poller::newDefaultPoller(this)), timerQueue_(new TimerQueue(this)), wakeupFd_(createEventfd()), wakeupChannel_(new Channel(this, wakeupFd_)), currentActiveChannel_(NULL)&#123; LOG_DEBUG &lt;&lt; "EventLoop created " &lt;&lt; this &lt;&lt; " in thread " &lt;&lt; threadId_; if (t_loopInThisThread) &#123; LOG_FATAL &lt;&lt; "Another EventLoop " &lt;&lt; t_loopInThisThread &lt;&lt; " exists in this thread " &lt;&lt; threadId_; &#125; else &#123; t_loopInThisThread = this; &#125; wakeupChannel_-&gt;setReadCallback( boost::bind(&amp;EventLoop::handleRead, this)); // we are always reading the wakeupfd wakeupChannel_-&gt;enableReading();&#125; “activeChannels” suppose to be a class variable, which is shared by eventLoop objects, but it’s ok to keep a copy for each eventLoop object to avoid multi-thread competing. and suppose epoll_wait() is thread-safe, so later during construction of eventLoopThreadPool, multi eventLoopThreads won’t conflict with “active channels” 5) epoller constructionepoller object is created during eventloop construction. since the three interface of epoll instance are thread-safe, they look like global funcs. epoll_create(), return an epfd referring to the new epoll instance, this epfd is used by all subsequent calsl to the epoll interface. epoll_wait(), return all ready events on the epoll instance referred by epfd. epoll_ctl(), traverse the red-black tree strucutre to return the existing fd, or add new fd to the tree. 6) channel constructionchannel is the container of one fd, and is related to one eventLoop. channel is not responsible to create/delete fd, the real owner of each fd is TcpConnection or acceptor. Channel object works like a pipe to send fd from inner object TcpConnection to the eventLoop. the advantage here is eventLoop is independent from connections. 7) channel:update()1234channel::update() --&gt; loop-&gt;updateChannel() --&gt; poller-&gt;updateChannel() --&gt; //poller maintain a channel list, call epoll_ctl to add/return/delete the requiring channel 8) one epoll + threadpool vs per thread per epollthe first method, one global epoll listens all new connections, and send each connection callback to a new thread to execute. method 2, to listen the server I/O socket need to bind a unique epoll, in Moduo which is the acceptor epoll. then all client connection socket will be dealt with their own worker epoll.]]></content>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[moduo 1]]></title>
    <url>%2F2018%2F06%2F14%2Fmuduo1%2F</url>
    <content type="text"><![CDATA[Moduo: A C++ non-blocking network library for multi-threaded server in Linux. C++ 11 featuresa. functional, bindin C++11, function declartion can be: 123456789 return-type func(args)//or auto func(args) -&gt; return_type// the good part of &quot;-&gt;&quot; is to use &quot;decltype&quot; to decide the return type from future. std::function&lt;return_type(arg1_type, arg2_type..)&gt; ; [](type1, type2..)&#123;&#125; ; //lambda func, anonymous func std::forward std::bind() is used to assign existed variables to func parameters during compile-time, and unassigned parameters stand as placeholders, which then replace by real parameters during running-time, and return a new func. bind() can be used to bind static func, global func, class member func. 12345678910 std::bind(global_func, 1.0, _2) ; std::bind(&amp;class:memberfunc, classPointer[this], _1); ``` ### b. multi-threads synchronized primitives Q: what is condition variable ? A: used to block one or more threads, till been notified by another thread or overtime been wakeup. But if all threads are waiting, that&apos;s a problem, so at least for one thread, the condition variable should be true. threadA.wait(condition_variable); while(;;) { threadB.do(); } threadB.notify(); threadA.do(); 1234567891011121314151617181920212223242526 Q: what is mutex? A: it works like a lock, to block any other thread to access special part of memory, at any time, only one thread can own the mutex. in reality, to define mutexLock class will manage lock/unlock automatically due to the constructor/destructor of the object. ### c. rvalue reference, universal reference, std::forward Q: why need right-value reference ? A: to use rvalue like lvalue, save object/variable copying, the detail is about move constructor. universal reference, means either rvalue reference or lvalue reference, is to declare a variable /parameter with type T&amp;&amp; for some deduced type T### d. functional template, variadic arguments basically, it&apos;s to support any type, any number of parameters in function template. ``` template&lt;typename… Args&gt; class tuple&#123;&#125; //a template class template&lt;typename T, typename… Args&gt; void func()&#123;&#125; /* Args :: a template type parameter pack, a list of parameters T :: a normal template type parameter */ func(T, args...) /* (...) at right of func parameters is meta operator used to unpack &quot;args&quot; into separate arguments */ a simple thread / thread pool libtake a look at: thread-pool basically, a task queue to store all todo tasks; a thread pool, to store the worker threads, each of which takes one task from the task queue continuously till the queue empty. racing condition happens when two threads try to take the same task simultaneously, so mutex. and all operators requrieing thread-safe should use mutex, e.g. enqueue/dequeue taskthen callback functors, how each worker thread deal with the task at hand? to design function template with variadic arguments. a simple Tcp network libtake a look at: simpleNetwork in server: socket() -&gt; bind() -&gt; listen() -&gt; accept() –&gt; send()/write() in client: socket() -&gt; connect() -&gt; recv()/send() a basic idea is that each connection, the server will create a new thread to handle it. But it consume server quickly. I/O nonblocking/event-driven &amp; multiplex1234567891011#include &lt;poll.h&gt; struct pollfd &#123;int fd; //file descriptor, non-negativeshort events; //events to watch, set by usershort revents; //returned events, return from system kernel &#125;;POLLIN | POLLPRI ; //event readPOLLOUT | POLLWRBAND ; //event writePOLLER ; //event errorPOLLHUP ; //event hang up the basic idea of multplex(Linux APIs: poll(), epoll()) is to use one single thread to listen many connections/socket/fd, once any socket is ready for I/O, the thread will execute the write/read callback. epoll() on success, return the number of revents or 0; on error return -1 123456789struct epoll_event &#123; __u32 events ; union&#123; void* ptr, //if need to store a pointer int fd, // if need to store socket fd __u32 u32, // to store general 32 bit number __u64 u64 // to store general 64 bit number &#125; data;&#125;;]]></content>
      <tags>
        <tag>c++11</tag>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[coding is the system engineering]]></title>
    <url>%2F2018%2F06%2F05%2Fcoding-is-the-system-engineering%2F</url>
    <content type="text"><![CDATA[during this week studying: automotive message broker. It’s a framework to support in-vehicle network communication, based on which many vehicle applications can build up. After jumped into the source code, soonly I found the dependent third-party libs, e.t. Qt, Glib, libwebsockets. None of these basis libs looks familiar, that’s really headache. So had to jump to learn a little about these libs first. Qt is heavy, give up on reading source code, basically to know what’s used for; Glib has a core on eventloop, after review the concept: nonblocking event I/O; and few lighter projects are found, e.g. event.js in RocketEngine. so I was happy to read js source code, but after reading nothing really keep in my head due to don’t know where to use them, neither don’t understand why these implement is necessary. maybe a bigger project with more details, so picked moduo, written by a Chinese. there is a book on this project, which started with multi-thread programming issues, no help. same problem, I am not familar with the application scenario, so can’t really catch the essential. back to the question: how to effciently read source code?1) I suppose, first to understand the application scenario2) compile and run in debug to track the data flow for projects, which you can’t see the flow by once3) if it’s a framework/foundmental libs, write demo The company IT system is not developer-friendly, git, cmake, npm, python lib are missing. that’s maybe the reason I am becoming lazy, if tools at-hand, may give a try; if not, nothing really do. The company has itself gmake system, but the bottom code never been touched. Then I compiled the demo libwebsocket, many failures bump out, during school time, I used a lot cmake, g++ with local headers, link to LD/_LIBRARY/_PATH, all out of practice for couple years. Anyway, at this moment, I realize that coding is a system enginnering. first to be really familar with OS, then the basic libs, then think about to write applications. For me, the first occupy with software is from (industry) application layer, lack of foundmental. now when to do sth, I feel hands are bounded, that push me to the root. Rome is not built in one day, OMG.]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[open source project checked]]></title>
    <url>%2F2018%2F05%2F31%2Fopen-source-project-checked%2F</url>
    <content type="text"><![CDATA[pen source projects I scatched To review how many open source projects I tried to study has been in my mind for a long time. I am always interested in new areas, new trends, and want to understand a little more, few contribution by now. One college friend, who worked at Intel China, first brought me to GTC 2008 at Beijing, where my eyes is opened first time, to know there is so many amazing works around the world. 1) HPC/FEA/CFDafter 2008, I was driven by computing mechanics more HPCG: a benchmark work to test FLOPs, which I used as a class project at Buffalo PETSC: a large sparse matrix solver, developed from Texas Austin, also met at Buffalo. the math is attracted me more and it is complex and a good learning material for C++ LibMesh: based on PETSC to do FEM. ran some demo and interested in math more GPU-SPH: GPU implementd of SPH(CFD algorithm), during 2011, GPU is popular in applied mechanics. PetIBM: immersed boundary method (CFD algorithm), used as a class project OpenFEM, OpenFOAM etc. during that period, I collected many small/big open source CFD/FEA projects, but few study. 2) Game Engineat 2011, Virtual Reality is attracting CHAI3D: my friend show me a demo, but I didn’t go through LiquidFun: google product Box2D: for fun, like LiquidFun, where cmake, configure skills played That time I also collected many other game engines from web, e.g. Unreal, skynet.. it’s so cool to be a game developer, but no time to deep in 3) Robotat 2014, robot is hot ROS: that’s my way to study the platform first, with a few study and no more SLAM: the cool concept when to uderstand the core algorithm OpenCV: used everywhere, read some docs, but not used independtely Arduino: platform, when I joined the Detroit Hacking Night(DHN) meetup RasiBerry: similar experience during DHN, later I tried to implement deep learning detection algorithm on a race car, not finished till now RTOS: go through like 2-month ago, when I feel I need more understand at embedded system. simple to understand, but not sure how can I master in practice 4) Deep Learningafter 2016, DL is so popular, many frameworks, online courses, papers bursting, no way to keep calm. TensorFlow: I thought it’s easy at first, but really didn’t go to the code, but implemented some examples Caffe: the DL framework jumped in, first knew about Google protocol buffer, very confused at that time ChatAI: I tried to add some fun in WeChat public platform 5) VehicleBuffalo Car simulator: at Buffalo lab, there was a physical car simulator, and code in OSG, cool project to learn C++ SimCar: later I had chance to know many open source/ commercial car simulators AGL: at 2017, started to view AGL updates, try to keep in mind the new trends in vehicle software fields GEVIVI: same time with AGL, interested in IVI as a sub-field openXC, SmartDeviceLink: OEM level apps 6) Web &amp; Mobileat 2017, luckly transfered to a web project, have the chance to know AngularJS, Node.js and event driven, REST, AJAX, async, many new and exciting ideas here. Hexo.io: a static blog engine web crawler: looks like a hack skill async event I/O lib: moduo, event.js top github Rankers have js projects, looks very intersting 7) OS relatedmany little tools when playing with Linux, system level, apps. One big stuff is Linux Process Communication(IPC). I used share memory in one product but never had a chance to know the big picture of IPC, later want to know about Linux network, and see socket, signal… feel connected. CMAKE: QT: Glib: MKL: intel math kernal lib, cool in first impression plugin-pattern in embedded software the good is know diversity, the short I don’t have done any contribution to combine these experince GBM]]></content>
  </entry>
  <entry>
    <title><![CDATA[W3C automotive open web platform]]></title>
    <url>%2F2018%2F05%2F22%2FW3C-automotive-open-web-platform%2F</url>
    <content type="text"><![CDATA[W3C automotive open web platformMain page: Link A clear web framework: 1) define the network communication APIs(based WebSocket protocol); 2) standarlize vehicle data; 3) define APIs to access vehicle data. Vehicle Information Service Specification(VISS)Object: to define WebSocket based APIs for a vehicle information service to enable client apps to get, set, subscribe, unsubscribe to vehicle signals, data attributesLink Vehicle Datadoc Link Object: to define a standard Vehicle Data with might be available in a vehicle 1) VehicleInterface2) VehicleCommonDataType3) VehicleConfigurationInterface (identification, sizeConfiguration, fuelConfiguration, transmissionConfiguration, wheelConfiguration, steeringWheelConfiguration)4) Running Status Interface(vehicleSpeed, wheelSpeed, engineSpeed, vehiclePowerMode, powertrain, acceleratorPedalPosition, throttlePosition, tripMeters, transmission, cruiseControlStatus, lightStatus, interiorLightStatus, horn, chime, fuel, engineOil, acceleration, engineeCoolant, steeringWheel, wheelTick, ignitionTime, gyro, brakeOperation, buttonEvent, drivingStatus, nightMode, startStopMode)5) Maintenance Interfaces(odometer, transmissionOil, transmissionClutch, brakeMaintenance, washerFluid, malfuncitonIndicator, battery Status, Tire, trouble Code, diagnostic)6) Personalization Interfaces ( languageConfiguration, unitsOfMeasures, mirror, driveMode, seatAdjustment, dashboardIllumination, vehicleSound )7) DrivingSafety Interfaces ( antilockBrakingSystem, tractionControlSystem, electroniceStabilitySystem, topSpeedLimit, airbagStatus, door, childSafetyLock, seat)8) Climate Interfaces (temperature, rainSensor, wiperStatus, defrost, sunroof, convertibleRoof, sideWindow, climateControl, atmosphericPressure)9) Vision &amp; Parking Interfaces( laneDepartureDetection, alarm, parkingBrake, parkingSensors) Vehicle Information API SpecificationObject: define a high level API for accessing vehicle signals, data attributes and communicate with in-vehicle data servers doc Link VISClient Interface used to define any on-board, off-board clients VISClientOptions Interface used to define a connection to a vehicle signal server(speicifiable by protocal, host, port) VISSubscription Interface used as return value from subscribed() methods VSS Interface used as return value from getVSS(), which should be sufficent to fully traverse the VSS tree Vehicle Information Access APIdoc Link Object: enable connectivity through in-vehicle infotainment systems and vehicle data access protocols 1) Navigator Interface: exposes the interface to vehicle information services2) Vehicle Interface: the initial entry point to get access to the vehicle information3) Zone interface: physical and logical zones4) VehicleIneterfaceCallback5) AvailableCallback6) VehicleInterfaceError (permission denied, invalid operation, timeout, invalid zone, unknown, error, message)7) VehicleInterface : the base interface to get all vehicle properties8) VehicleCOnfigurationInterface : access to static vehicle information9) VehicleSignalInterface: access to variables vehicle info10) Data Availability : available, not supported, not supported security policy, supported …]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where are you in next 5 years(2)]]></title>
    <url>%2F2018%2F05%2F18%2Fwhere-are-you-in-next-5-years-2%2F</url>
    <content type="text"><![CDATA[the billions level productThink about these guys in the world, who defined products/services used by billions people, they are more than model innovation, but really make a diffrence in most people’s life. e.g. iPhone, facebook, Google, they are not created from nowhere, but went through product iterations by iterations, and they only imerge when the tech, the market, the time all are in perfect. How many people in history achieved here? in any sense, it’s the history choose that person, not that person made history. so take it easy even you are not the 0.01%. in the promising marketmost people in their life time neither can be the next Jobs, nor Bill Gates. that’s the reality, no sad but clean expectation in the end before really in the last day of life. the second goal is easier, find a promising market and lead a small product, maybe lucky invovled in a domain market finally. You are not significant, but one of other 5000 competitors. Even this career path, however, you can’t expect the normal lifestyle: start at 25 and retire at 55 with enough 401K to death. If so, mostly you will be fired out someday in 30s or 40s. Chinese say, “if you dont plan far, you will be in trouble soon” so what may be the promising market subset in automotive software in next 5 years? generally say: 1) service, consulting; 2) self-business; 3)tech expert. in specificly saying: 1) electricity, energy infrastructure; 2) connected, cloud infrastructure; 3) autonomous vehicle.4) mobile apps, which is the carrier for the first 3. I mean the trend is so clear these days. No one can say he dont’ know where should stand in future. but where are you now? I like the model Elon Musk mentioned when do future plan: what’s your reality, what’s your goal, how to meet the gap, than focus on acting. will automotive software like mobile smartphones ?It’s interesting even now there are few third-party or independent “automotive software” companines, on opposite, in mobile market, there are lots of small or big third-party developing companines around Andriod, iOS, the mobile ecosystem is plenty and diversity. the reality in automotive field is lack of abstraction and separation between bottom hardware and top applications. in a mature mobile ecosystem, developer -&gt; end-usersin automotive software ecosystem, devleoper –&gt; OEM –&gt; end-users some auto allience is working on(AutoSAR). as developers, either gain some knowledge in hardware/control to solve the gap, or waiting for the day. what I expect on the way, may be like mobile time:1) automotive OS platform2) vehicle apps3) infrastures extending once the platform is unified, suppose many new auto branchs will emergy. like HTC, Xiaomi, Vivo, Huawei, Lenvo branches after Andriod OS. then new market stratgey is highly required, also traditional OEMs will be heavily impacted. OEM don’t like mobile ecosystemthis may happen soon or never, since OEM don’t like this trend. most possiblely, automotive software developers will highly rely on OEMs. so where will I stand in next 5-years ? OEM is good at strategy study and product integration. at a tech supplier, the benefit is more product driven experience. OEM suppose to have the advantage at automotive platform built-up, but reality is big Internet/software companies with product-level solutions, and OEM doesn’t. it is clear for me in next 5-years to jump into electric, connected, autonomous related industries, either at OEM level or supplier level. Also it is the time to do some study at automotive platform vendors.]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where are you in next 5-years]]></title>
    <url>%2F2018%2F05%2F14%2Fwhere-are-you-in-next-5-years%2F</url>
    <content type="text"><![CDATA[what industry will you be in? in every industry, the product should be the core to define all other supporting teams, the market team, the product design team, IT team, manufacture team etc. so my answer suppose to be vehicle, or maybe I even should not limit here. as an mechanical/mechanics based engieer for three years, I realized there are three aspects: 1 solid knowledge in this special field, e.g. Mechanical has concept of stress, material property; market has concept of supply chain, product strategy, customer expectation; 2 fluent with the industry tools, which give the feeling you can fix the world by it, e.g. CAD/CAE tools to mechanical, programming tools to developers; 3 passion in the product, which is the driven force to explore and creativity. Do I have passion in vehicle? Or Do I feel the pain/hurt due to any unsolved issues in vehicle? maybe no, that’s why I stay in surface even after 3-years, don’t feel the pain neither the fire. knowledge is almost the easist part, which answer “what”, the true barrier is about tools(how) and passion(why). From knowledge level, reading couple professional books will be enough to absolve the concepts in a new acknowledge. career passionBut why you want to involve in this job? most people even don’t go to why, since reality is here: after getting married, pay the house fee, kids taken after. Job is a job, to support family, period. I love family, by the way. but don’t take family as an excuse for muddy career. Is there a field that knowledge is the tool? maybe AI, so far AI products is limited, e.g. voice, image. so tools are highly overlapped with knowledge. It sounds like an easy-in field. for a while as AI maturing and becoming an common service, then AI related products will burst out in every field, then product/market/capital-driven occupy. It’s a bad strategy to chase after market hot topics to develop personal career path. Current market trend is helpful, but there is no clear next-10-year market goal; on personal level, however, you definitely need a clear next 5/10-year goal, then every small adjust should point to that goal. so basically there are two categories: knowledge-driven, which is new coming e.g. AI; market-driven, which is always matured, e.g. automotive, smart phones. I suppose the matured market, if lacking creative input(vey much based on customer needs, market trends), is going to sunset sooner or later; the knowldege-driven market is bursting on the way, and absorving/requiring more and more labors. so where I am now, and where will I be in next 5-year? How do you survive in a matured market, or are you born to be the new-comers? and is the new-comers achievable? e.g. will AI related knowledge/tools be easy to catch? if in a matured market (automotive CAE)if I dont figure out a clear 5-year goal, most possiblely I will stay very unhappy in CAE the next 5 years; also very possible I can’t tolerant the work environemnt any more, and jump to any field at that time accept me; few chance to refresh my opinions and define a CAE sub-market. there are a few concerns. First, it’s not good to change direction immidetialy anytime the market is down, that’s too risk if you don’t setup the long-term goal. Second, in a sunset field, it’s not only about salary not high, the hidden aspects includes scattered office environoment, lay-off dangerous, not been valued, which will change the person into sunset. I mean, even a sunset period still need labers to maintain, but depends on personality, not for me somehow. what may be the CAE sub-market to rise? I can feel the tools is still highly used in automotive fields, but the maturity in CAE software products requires few new development, some new try into autonomous vehicle safety will not be a burst. Another try is in cloud based environment, is more like a sub-applications for the cloud vendors, it’s kind of a pattern innovation, not a product innovation. Due to the fewer chances in mature products, the level of candicates is actually high, most openings requries PhD. the mature market is a employer market, not employees friendly. And the education system may take decades to make a shift, during the period the employee somehow have to be devalued, because of the market decide their values. if in a new market (AI)by all menas, a new market does have more chances and promising futures and all the benifits where the mature market doesn’t have. The point is how to transfer from a mature market employee to a new market employee. I mentioned before, three aspects, knowledge, tools, and passion. Love it first, and the knowledge and familar with tools will achieved. need more discussion in next time.]]></content>
      <tags>
        <tag>CAE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[what happens in automotive softwares]]></title>
    <url>%2F2018%2F05%2F07%2Fwhat-happens-in-automotive-softwares%2F</url>
    <content type="text"><![CDATA[Backgroud:Due to 6-year school experince in mechanics, I was native to jump into CAE position. But I have few willing with CAD, which is very fundemental to be a qualified Product-Design side engineer. so I am not. So I am in a CAE tools support team, where I don’t directly design, mainly in enhancement, deployment etc, where understandthe old code, and write new function code, track bugs, system configure is enough. even in the big CAE vendors companies(Altair, Dassult System), the new methodlogy invest is very possibly less than product integration and customer consultings. what’s changing:the trend of CAE tools in OEMs demenstrates less investment, not because CAE tools are less used, but the CAE methodlodgy/process is really mature; new trends are arising, e.g. connected vehicles(CV), smart city, autonomous vehicles(AV), all of which require different knowledge and mindset(from mechanical to EE/CS). In 2017 Sep, I enrolled Udacity self-driving car, which gave some knowledge(openCV, deep learning, data fusion, object detect, plan algorithm), and the problems in AV. This field is so hot that openings around everywhere, basically California companies are high-demand, looking for a strong guy, AI expert, or senior automotiveengineer; while Michigan companies are old fasion, more on system integration level, and the required skills are random. if it’s a turning pointwhile Udacity didn’t work for me and AV is too young to all-in invest.For a while I am actually back to CAE, tried to enjoy it. But bad news keep coming, less projects funded, and frustrated office environment, so I move on. this time, IoT(connected vehicles) come to mind. it is really an old topic, since 2008 at college, IBM throw the big vision: smart earth to connect everything. Decades passed, finally the infrastructure, the application levels(transport, home, offices) are prepared-well. Good for me, I track AGL, GENIVI open source projects for around a year already and had 8-months experience in mobile developement(RESTful, server-client model), all bring me some fresh idea in connected vehicles. To study the automotive embedded software system, I tracked freeRTOS first, cause it’s easy since knowldege in Linux; about applications based on RTOS, however, I have no idea, e.g. vehicle dynamics, body/engine/powertrain control components, sensors, algorithms. While they are new but not difficult, hopefully can be familar in short period. softwares in connected vehiclesThere are two sections: the vehicle development, including traditional control components, which requires professional knowledge in vehicle dynamics, ECU; Vehicle Infotainment(IVI)components, which is like mobile developement. this section already has standard architecture, e.g. AutoSar secondly the vehicle to surroundings, either cloud device, peronsal mobile devices, or other vehicles. which requires: cloud infrastructures, communication protocol, security vendors, Android/IOS mobile apps, and IoT hardware vendors. it’s a clear big market, also it presents more valuable to do business than to be an engineer in each small field. the reasons come to mind, 1)architecture is done, no big mind/theory updated ; 2) so all should be about products, the integration components to market products is virtual. on-goingCAE softwares is heavy-math/numerical algorithms demanding; on the other side, embedded softwares is like enterprise Java, more on logic flow. As the population of mobile frameworks, and standarlization in automotive embedded system, the threshold suppose become lower. On the other hand, the dependence on suppliers’ libs and the test/release on hardwares may draw the life cycle of embedded software development longer. To explore embedded softwares may not the right career path, but no doubt it’s good to know what’s happening there. Finally, Either embrace the changing or wait it come to you, I mean, both are good stragies, maybe!]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[open source car control]]></title>
    <url>%2F2017%2F09%2F05%2Fopen-source-car-control%2F</url>
    <content type="text"><![CDATA[OSCC Introgithub it’s a modular using software to interface with a vehicle’s communication network and control systems. functions: to send control commands to the vehicle, read control messages from the vehicle’s OBD-II CAN network,f and forward reports for current vehicle control state (e.g. steering angle, wheel speed) sensors: steerng wheel torque sensor, throttle position sensor, brake position sensor issues: not safe for spoofing CAN message, or hacking firmware &amp; hardwareapplication layer (API)]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231 -- CNN in computer vision]]></title>
    <url>%2F2017%2F07%2F24%2FCNN-demo%2F</url>
    <content type="text"><![CDATA[what happend in high dimensional space?Pixel-based distance on high-dimensional data can be very unintuitive. Linear Classification1) define a score function from image pixels to class scores. benefits, no need to store all data 2) SVM and Softmax 3) a loss function, measure the quality of a paricular set of parameters based on how well the induced scores agreed with the ground truth labels optimization (SGD)the loss function as a hihg-dimeonsional optimization landscape, in which trying to reach the bottom BPRectified linear unit (ReLU)Neural Networkstrain a small network, the final loss are relatively few local minima, and easy to converge, but they are high loss; if train large network, there may many different solutions, but the variance in final loss is much smaller. –&gt; all solutions are equally as good, rely less on the random initialization in practice, use regularization tech to control overfit on large train network Data Preprocessing1) mean subtraction 2) normalization 3) PCA &amp; whitening 4) weight initialization 5) regularization 5.1) L-norm regularization 5.2) Dropout Hyperparamter optimization1) initial learning rate 2) learning rate decay schedule 3) regularization strength (L2 penalty) tips: decay learning rate over the period of training; search for good hyperparameters with random search CNNlayers used to build ConvNet architectures: 1) Convolutional layer 2) ReLU layer 3) Pooling layer 4) Fully-connected layer case study: LeNet AlexNet ZF Net GoogleNet VGGNet ResNet Visulization CNNTransfer learning]]></content>
  </entry>
</search>