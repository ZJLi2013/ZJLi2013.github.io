<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[lru cache design]]></title>
    <url>%2F2018%2F12%2F18%2Flru-cache-design%2F</url>
    <content type="text"><![CDATA[leetCode 146, for non-CS background, this kind of problem is out of mind, what is talking about, but I know at all it is about design a data structure to meet some requirements: first a hash map data structure for key, value operations, e.g. get(), put(); but normal hash map can’t track the most recent used element, so either find a data structure, which can track the recently used element in the hash map; or define some routines to do it. a data structure to catch recently usedeach get(), put() will operate on one special element, and that element should be marked as recently used, and the next element is the least recently used element, which can be overlapped in next operation. stack and queue have some property to track the most recent element, but they are one-way, not straight forward to manage two neighbor elements. double linked list is a good choice to track both the most recent element and the least most recent element. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950struct node&#123; int val ; int key ; Node *pre ; Node *next ; public Node(int value_, int key_) &#123; val = value_; key = key_ ; pre = NULL ; next = NULL; &#125;&#125;class LRUCache &#123; public: list&lt;node*&gt; recent ; unorder_map&lt;int, node*&gt; hash ; int capacity ; LRUCache(int cap): capacity(cap) &#123;&#125; node* get(int key)&#123; if(hash.find(key) != hash.end())&#123; recent.remove(hash[key]) recent.push_front(hash[key]); return hash[key] ; &#125; return -1 ; &#125; void put(int key, int value)&#123; if(hash.find(key) != hash.end())&#123; recent.remove(hash[key]); hash[key] = value; recent.push_front(hash[key]); &#125; node* tmp = new node(value, key); hash[key] = tmp ; recent.remove(tmp); recent.push_front(tmp); if(hash.size() &gt;= capacity)&#123; node *tmp2 = recent.back(); hash.erase(tmp2-&gt;key); &#125; &#125; &#125; routines to track recently usedin this way, the hash is still needed, but define routine to set the latest updated node always at front. void setHead(Node* n){ n.next = head ; n.pre = null ; if(head != null) head.pre = n ; head = n ; if(end == null) end = head; //only 1 element } when solving real problems, either has a good understand about special data structure, which can solve this problem, or the raw way is to implement routines based on the exisiting input]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where are you in next 5 years (4)]]></title>
    <url>%2F2018%2F12%2F18%2Fwhere-are-you-in-next-5-years-4%2F</url>
    <content type="text"><![CDATA[in the nude“only after the tide has faded, know who is in the nude”, the wise said. distributable resources(social relationship, capital, core tech, market vision) define the success of a man in the world. in normal days, people feel good about themselves, like they can take things in control and looks well, these factors are ignored, and crisis is under the hood; when situation changes, the crisis appears, then people feel unexpected surprise. how crisis is so close along with us for a long time, and get igored for a long time ? another word, “standing in the wind, elephant can fly to the sky”, when market is good, normal people make money from stock. it is not him become smart, worse he is not prepared for the coming bad times. with no money, no social relations, and no core tech standing in the world, I should be humble to dirt, rather talking like everything is in control. for many young immigrants, the breakthrough is through education and learn core skill, and earn money and gradually being successful. this evening, watched Jack Ma speech, some ideas: in age 20 - 30, the best thing is to find a good boss and learn from him or the team; from age 30 - 40, try something for yourself, either to start a business or go for a art design degree; from 40 - 50, make sure to do things yourself most good at. life is previous and short, no waste. find out my contribute to the world, and do it. the right thingI shared my thoughts with a friend, that I thought AV was the future in vehicle industry, so even though I had no experience in control algorithms, computer vision, sensor hardware, I will find a way in; on the other side, I am pretty familiar with CAE software products development and applications, how I choose ? my friend said, neither. job is to make money. Have to say, I am still focusing too much on the strong or the weak, the right or wrong. spent too much energy to find the line to divide future into simple right choic and wrong choice. I remembered another good friend, said I am used to pre-define or label people, but forget every similar story could have many different reasons and results. if there is a unique right thing in the world, then everyone must follow it, but since the right thing/decision for each person is different, even though the world drive people to be similar, I should realize in every situation, every step, it is ok to have a different right thing, rather than holding on the unique rightness]]></content>
  </entry>
  <entry>
    <title><![CDATA[word break with dfs & bfs]]></title>
    <url>%2F2018%2F12%2F17%2Fword-break-with-dfs-bfs%2F</url>
    <content type="text"><![CDATA[leetcode 139 dfstraversing string ,and split it one char by next, if find the splited left word in dict, recursiving the remaining right substring. in this way, it will make sure find a solution, but also traversing all unnecessary possibilites. and need design a class variable to stop the dfs() 123456789101112131415161718192021bool found = false;bool dfs(string s, unordered_set&lt;string&gt;&amp; dict)&#123; string left, right ; if(s.size() == 0 || s.empty()) &#123; found = true; return found; &#125; for(int i=0; i&lt;=s.size(); i++) &#123; left = s.substr(0, i); right = s.substr(i, s.size()-i); if(dict.find(left) != dict.end()) &#123; dfs(right, dict); &#125; &#125; return found;&#125;; bfsas mentioned above, dfs goes to all possibile branches, which is not required. bfs is like a greedy way, to find out one working solution and done. also need keep track of searched left sub-strings, since the remaining right sub-strings may can not find a matched from dict, then the left sub-string is not acceptable, so the left sub-string need move one char further. 1234567891011121314151617181920212223242526272829303132 bool bfs(string s, unordered_set&lt;string&gt;&amp; dict)&#123; int len = s.size(); string s1, q, left, right; queue&lt;string&gt; sq; sq.push(s); string tmp ; while(!sq.empty())&#123; tmp = sq.front(); sq.pop(); int i=0; s1 = s ; while(!s1.empty() &amp;&amp; i &lt;= s1.size()) &#123; if(tmp == s)&#123; left = s1.substr(0, i); right = s1.substr(i, s1.size()-i); &#125;else &#123; left = s1.substr(0, i+tmp.size()); ///will dead-cycle right = s1.substr(i+tmp.size(), s1.size()-i-tmp.size()); &#125; i++; if(dict.find(left) != dict.end()) &#123; q += left ; sq.push(left); s1 = right; i = 0; &#125; &#125; &#125; this bfs is not good design.a pretty simple sample code]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where are you in next 5 years(3)]]></title>
    <url>%2F2018%2F12%2F15%2Fwhere-are-you-in-next-5-years-3%2F</url>
    <content type="text"><![CDATA[at the end of 2018, I was lay off from GM after only a couple months. in the middle of 2018, I was planning to jump out from the traditional CAE group, to try the new autonomous vehicle. but a few things I missed when made that decision: the big environmenthow long will the traditional automotive industry stay in a sort of good shape? the answer now is not long. from Oct 2018, both Ford and GM publicly lay off over 15%, the vehicle market at both China and NA were significantly down from Q3; even earlier the manufactoring robotic supplieres mentioned their 2019 order were almost zero. so layoff employees is almost destined. in economics, consumer index is the reason, employment/unemployment rate is the result, not the reverse. and there is a delay from consumer index to unemployment, about 3 ~ 6 month. so when the market is done, a few month later, the unempolyment rate will show up. an even biggger environment, the trade war among China and USA raise the cost, fear both the consumers and the investors. not only vehicle market, consumer electronics (e.g. apple), internet(e.g. Google), retail industry(e.g. Alibaba) and as closely related to lologistics, chips, energy, housing, finance all go down. the winter is coming. Sooo scary, hate Trump ! new techs in vehiclefor a new stuff in market, the trend is starting extremely high, then low to bottom, then go to rationality. it happens to AI, autonomous vehicle(AV) market. starting from 2016, billions invest in, every step looks promising, revolution. but 2 years now, even Waymo said it can’t make AV in bussiness. on one way, OEMs can’t be lay behind, so buy startups, on the other way, they can’t all invest in AV, which has no mature market strategy. the more invest, the higher risk. for people who want to eat this AV cake, cold cold. how to face the changing worldhave to say, there is no well-prepared in this quick-changing world, plan is always out of date. at the middle of year, I thought I made the right decision to leave Ford CAE group, join GM autonmous group, now put myself in a poor situation. I usually have a mind, that this thing has to, must to be done in this and only this way; this situation is and has to be dealed in this and only this way; this person is and has to be treated in this and only this way. I know this is the poor mindset. they say “poor people make poor decisions”, thanks to warn me up. e.g. * so high risk to depend on one single incoming resource * no stable business, keep humble and keep foolish * be positive, be felxible.]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[clone graph with dfs & bfs]]></title>
    <url>%2F2018%2F12%2F14%2Fclone-graph-with-dfs-bfs%2F</url>
    <content type="text"><![CDATA[leetcode 133, the solution is traversing the graph, so either bfs or dfs should work. dfs works like a stack, take an example when processA is running, inside processB is invoked, then processA hang, and go into processB; as processB is running, inside processC is invoked, then processB hanged, and go into processC. e.t.c. so the finished order is from innerest to outest. dfs will always traverse all possibilities, then return to the outest layer. in clone graph, e.g. #0, 1, 2 #1, 2 #2, 2 dfs process as: first deal with first line, element 0, which trick element 1, so process goes to second line, and trick element 2, so go to third line(done), then return to second line(done), then return to first line, trick second neighbor 2 go on… bfs works different, during processA running, processB is invoked, will still run processA to done, but also push processB to job queue, which will run next time. so using bfs, usually has a queue variable to mark unfinished jobs. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263 struct UndirectedGraphNode &#123; int label ; vector&lt;UndirectedGraphNode *&gt; neighbors ; UndirectedGraphNode(int x) : label(x) &#123;&#125;;&#125;;//graph traversing by bfsUndirectedGraphNode *cloneGraph(UndirectedGraphNode *node)&#123; if(!node) return nullptr ; UndirectedGraphNode *c_node = new UndirectedGraphNode(node-&gt;label); queue&lt;UndirectionGraphNode*&gt; qlist ; unorder_map&lt;int, UndirectionGraphNode*&gt; map; map[c_node-&gt;label] = c_node ; qlist.push(c_node); UndirectedGraphNode cur, neighbor = nullptr; while(!qlist.empty())&#123; cur = qlist.front(); qlist.pop(); for(int i=0; i&lt;cur-&gt;neighbors.size(); i++)&#123; neighbor = cur-&gt;neighbors[i]; if(map.find(neighbor-&gt;label)) &#123; c_node-&gt;neighbors.push_back(neighbor); &#125;else&#123; UndirectedGraphNode *tmp = new UndirectedGraphNode(neighbor-&gt;label); c_node-&gt;neighbors.push_back(tmp); map[tmp-&gt;label] = tmp ; qlist.push(tmp); //bfs idea: find new node, push it to queue and deal // with it in next while loop &#125; &#125; &#125; return map[c_node-&gt;label]; &#125; //dfs void dfs(UndirectedGraphNode\* node, unorder_map&lt;int, UndirectionGraphNode*&gt;&amp; map) &#123; UndirectedGraphNode * c_node = nullptr; if(!map.find(node-&gt;label))&#123; c_node = new UndirectedGraphNode(node-&gt;label); map[c_node-&gt;label] = c_node; &#125;else&#123; c_node = map.find(node-&gt;label); &#125; UndirectedGraphNode* nei; for(int i=0; i&lt;node-&gt;neighbors.size(); i++)&#123; nei = node-&gt;neighbors[i]; if(map.find(nei-&gt;label))&#123; c_node-&gt;neighbors.push_back(nei); &#125;else&#123; dfs(nei, map); &#125; &#125; &#125; UndirectedGraphNode *cloneGraph(UndirectedGraphNode *node)&#123; unorder_map&lt;int, UndirectionGraphNode*&gt; map; dfs(node, map); return map[node-&gt;label]; &#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[palinedrome partition with dfs & bfs]]></title>
    <url>%2F2018%2F12%2F13%2Fpalindrome-partition%2F</url>
    <content type="text"><![CDATA[parlindrome partitionleetCode 131 a sample code : 12345678910111213141516void dfs(int depth, string s)&#123; if(depth == s.size())&#123; v.push_back(v1); &#125; if(depth&lt;s.size())&#123; for(int i=depth; i&lt;s.size(); i++)&#123; //left substring if(palindrome(s.substr(depth, i-depth+1)))&#123; v1.push_back(s.substr(depth, i-depth+1)); dfs(i+1, s); v1.pop_back(); &#125; &#125; &#125; &#125; 1) each col in the table is one way to partition the string.e.g. aab. col_1 , left string a is palindrome, v1=[a]; feed right string ab to dfs(i+1, s)(depth=0, i=depth) 1 2 3 a a a a a a b b b 1.1) col1_1, left string a is palindrome, v1=[a, a];feed right string b into dfs(i+1, s) (depth=1, i=depth) 1 2 a a b b 1.1.1) b will push into v1, make v1=[a, a, b], feed into dfs(i+1, s) (depth=2, i=depth), which will return since depth==s.size(). the above dfs()(depth=2, i=depth) returned, the immediate next step is b pop out from v1; also now is the finished of dfs()(depth=1, i=depth), so the immediate next step is the second a pop out. 1.1.2) so now go to (depth=1, i=depth+1), push ab into v1, making v1=[a, ab] . but ab is not palindrome, return immediately, then pop out ab. 1.2) at this time, the very outside dfs()(depth=0, i=depth) is all done, so pop the first a in v1; and go to (depth=0, i=depth+1); then (depth=0, i=depth+2)… recursive of DFSanother example of recursive dfs. leetcode 129 sum root of leaf numbers dfs is used to find all the solutions, in a way to go through each branch in the same level first, then go into the next level. to traverse all solutions(branches), also need to mark traversing/traversed branches. so usually need: to push -&gt; current traversing element to pop -&gt; traversed element and a container to hold all solutions. if design recursive with returned value, consider the critical condition. e.g. what suppose to return when the last element, and usually design the returned value as local variable in each recursive function, rather than a global variable. one more thing is about the traversing direction, from left to right end, then when coding make sure the direction is consistent at all times. BFS to find mini cutsDFS is used to solve the kind of problem: traversal all possible solutions; leetcode 132 askes for the mini cuts, once find out the mini-cuts solution, done, no traverse all possibilities. 1234567891011121314151617181920// define done, cut as class member variable void bfs(string s, bool&amp; done)&#123; int len = s.length(); string left, right; int i =0; while(!done &amp;&amp; i&lt;len)&#123; left = s.substr(0, len-i); //starting from the longest left string right = s.substr(len-i, i); if(palindrome(left))&#123; cut++; if(palindrome(right)) &#123; done = true ; &#125;else &#123; bfs(right, done); &#125; &#125; i++; &#125;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[surrounded regions]]></title>
    <url>%2F2018%2F12%2F13%2Fsurrounded-regions%2F</url>
    <content type="text"><![CDATA[leetCode130, like go game. how to design the solution, at first it is naive to traverse with two for loops, then there will be too many if statement to specify, and not clear to seperate these if statements. three ideas behind a sample solution. using addtional status variablein lower space the problem is difficult to analysis, then from a higher space, the problem is clear and easy. e.g. trakcing the O in the board, how to mark them ? keep O will not tell the marked ones and the original ones. so using M to mark these already traversed, it make the situation much more clear starting from the critial domainat first, no idea where is a good start point, but the trick point is at the boundary, only the cells at boundary with O will keep O; all the O not on the boundary either connect to the boundary Os or they will be Xs. traversing with queueif not queue, to detect these O cells need two for loops, then deal with these O cells again need another two for loops. for loop is a global handling, while queue list is a local way, no need to take all cells in consideration, but only the cells in queue. queue should be a good way to traverse whenever the operation is not deal with all the elements. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374//extending from the boundary 'O', any extened will keep same statuevoid process(int i, int j, vector&lt;vector&lt;char&gt;&gt;&amp; board)&#123; int height = board.size(); int width = board[0].size(); std::pair&lt;int, int&gt; p; queue&lt;std::pair&lt;int, int&gt;&gt; Q ; Q.push(p(i,j)); board[i][j] = 'm'; while(!Q.empty())&#123; p tmp = Q.front(); Q.pop(); i=tmp.first; j=tmp.second; if(i!=0 &amp;&amp; board[i-1][j] == 'O')&#123; board[i-1][j] = 'm'; Q.push(p[i-1][j]); &#125; if(i!= width-1 &amp;&amp; board[i+1][j]=='O') &#123; board[i+1][j] = 'm'; Q.push(p[i+1][j]); &#125; if(j!=0 &amp;&amp; board[i][j-1]=='0') &#123; board[i][j-1]='m'; Q.push(p[i][j-1]); &#125; if(j!=height-1 &amp;&amp; board[i][j+1]=='O') &#123; board[i][j+1] = 'm'; Q.push(p[i][j+1]); &#125; &#125;&#125;void sol(vector&lt;vector&lt;char&gt;&gt;&amp; board)&#123; int height = board.size(); int width = board[0].size();//tracking the boundary 'o' and mark them as 'm' for(int i=0; i&lt;width; i++)&#123; if(board[i][0] == 'O')&#123; //bottom boundary board[i][0] = 'm' ; process(i, 0, board); &#125; if(board[i][height-1] == 'O') &#123; board[i][height-1] = 'm' ; process(i, height-1, board); &#125; &#125; for(int j=0; j&lt;height; j++)&#123; if(board[0][j] == 'O')&#123; board[0][j] = 'm'; process(0, j, board); &#125; if(board[width-1][j] == 'O') &#123; board[width-1][j] = 'm' ; process(width-1, j, board); &#125; &#125; for(int i=0; i&lt;width; i++) for(int j=0; j&lt;height; j++)&#123; if(board[i][j] == 'O') board[i][j] = 'X'; if(board[i][j] == 'm') board[i][j] = 'O'; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hash table]]></title>
    <url>%2F2018%2F12%2F12%2Fhash-table%2F</url>
    <content type="text"><![CDATA[the ideas behind hashtable is: 1) input the key to hash function, output the bucket index; 2) adding the element to the bucket[idx]. usually design the bucket[idx] as a linked list, allowing mulitply keys in the same bucket, which is called “collesion chaining”. 3) hashtable has three basic operators: insert/put, search/get, and remove. the memory usage of hashtable is continuous bucket array, then each bucket is a linked list. when first thought about the “continue array”, really is a vector, then why need hash function. That’s the point, hashtable allows the benefits of both vector and linked list. a few interesting topics about hash. 1)why prime numbers? the fundamental mathematical operations with prime numbers generally result in numbers who’s bit biases are close to random. in other word, when multiply or add a set of randome numbers by a prime number, the resulting numbers when as a group, statistically analyzed at their bit levels should show no bias towards being one state or another. in comupter science, pseudo random number generator has bit bias. 2) string hash/scattering,basically the hash functions should deal with each chracter in the input string, so no information about this string will be missed, and the information entropy after hashing operator suppose increase. 3) Blizzard hash function. not all hash function deal collision conflict with linked list, here is the example. 4) hash map benchmark performance review one feeling at this moment, so many brilliant and deep-focusing guys there, stay foolish and stay humble. std::unordered_mapthere is map vs unordered_map : map | unordered_map Ordering | increasing order | no ordering | (by default) | Implementation | Self balancing BST | Hash Table search time | log(n) | O(1) -&gt;Average | | O(n) -&gt; Worst Insertion time | log(n) + Rebalance | Same as search Deletion time | log(n) + Rebalance | Same as search basically map works for traversal, pre/post element access; unordered_map is quick in once search,insertion, deletion. here is a dictionary demo exampleword ladder, hash table is used to find a special word from dictionary. the benefit of unorder_set is O(1) find. so design a unorder_set to store the dict. in the following example, each character position in the word requires 25 times search of the dict. also every marked word from the dict, should not be searched second time. another variable is used to track the list of one_character_diff from current word, it’s like BFS. so design as a queue, which only need take care the neighbor two layers. 12345678910111213141516171819202122232425262728293031323334353637int sol(string start, string end, vector&lt;string&gt;&amp; wordList)&#123; int length = 2 ; unordered_set&lt;string&gt; dict ; foreach word in wordList: dict.insert(word) queue&lt;string&gt; one_diff_list; // initial by pushing start one_diff_list.push(start); while(!one_diff_list.empty())&#123; int size = one_diff_list.size(); for(int i=0; i&lt;size; i++)&#123; string word=one_diff_list.front(); one_diff_list.pop(); for(int i=0; i&lt;start.length(); i++)&#123; char oldChar = word[i]; for(char c='a'; c&lt;='z'; c++)&#123; if(c == oldChar) continue ; word[i] = c ; if(dict.find(word) != dict.end())&#123; if(word == end) &#123; //find the match return length; &#125; one_diff_list.push(word); dict.erase(word); &#125; &#125; word[i] = oldChar; &#125; &#125; length++; &#125; return 0; &#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[reinforce learning in simulator]]></title>
    <url>%2F2018%2F12%2F01%2Freinforce-learning-in-simulator%2F</url>
    <content type="text"><![CDATA[reinforcement learning from David Silver. In autonomous vehicle training, more and more practices dependent on simulator training e.g. carla RF an open source architecture used often is OpenAI GYM each agent has state, observation, action, which can be defined in state_space, observation_space, action_space. background 1) infinite or finite : in real case, state, observation space are easily to be infinite, e.g. in every frame, the agent has a different environment, which means a different state. the elements in action_space may be limited, e.g. turn left, turn right, accelerate, brake. etc. 2) continuous or discrete : when driving a car, the control is continuous, namely, a continuous function a time t. on the other hand, like play GO game, the action is not time related, each action is discrete to another. 3) locally or globally perception for a grid world game, the agent knows the whole world; but when a car running in a city, it can only percept the environment locally. this has a big difference when make decision the following talks about on-line policy RL, which means the agent will follow some policy(high-level). e.g the velocity limit, no collision with another car etc to training agent know how to drive, often need define environment reward, used to update the policy(detail-level), e.g. when the agent in stateA, policyI will be used. but keep in mind, neither the human nor the agent know exactly at first, which is the best(detail-level) value for the chosen policy, and the input (state, policy/action) is not even accurate so the learning process is actually to iterate in each episode to update the table (state, action), in which the policy is updated hidden, and which is usually called Q-value. after training, the (state, action) is better to handle the simulation environement. so the high-level computing flow: 123456789101112 s0 = env.step(agent) a0 = agent.follow_policy(s0) while not is_done: s1, r1, is_done, info = agent.act(a0) old_q_value = env.get_Q(s0, a0)cur_q_value = env.get_Q(s1, a1) measure = r1 + gamma * cur_q_value new_q_value = old_q_value + alpha * (measure - old_q_value) env.set_Q(s0, a0, new_q_value) s0, a0 = s1, a1 real case while loop is basically update policy, so next time in a certain state, the agent will performance better. but there is a problem, most real problem don’t have a Q-table, since the state space is infinite. 1) linear space approximator the real state space is high-dimension even infinite-dimension, mathmatically it’s OK to use a linear space to be as close as possible to the real space (Hilbert space). e.g. in elastic mechanics, the finite element space can approximate any accuracy to the continuous elastic space. so the idea is to construct the linear space base vector based on existing sample state, then all state can be descriped as a linear combination of the base vector. 2） neuro-network aproximator for nonlinear fitted application, to construct a neuro-network to describe the state space. how to train the network and how to make sure it is robost and convergence is another topic]]></content>
      <tags>
        <tag>RL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pYTHON again]]></title>
    <url>%2F2018%2F10%2F27%2FpYTHON-again%2F</url>
    <content type="text"><![CDATA[Pick python up from a link for new position: type12type(123)isinstance(instance_name, class_name) @propertytransfer get()method in a class to a decorator define function123def my_abs(x): if not isinstance(x, (int, float)): raise TypeError('bad operand type') fun decorator12@decoratordef fun() filter1234def is_odd(n): return n%2 == 1 list(filter(is_odd, [1, 2, 3, 4]) lambda1list(map(lambda x: x*2, [1, 2, 3, 4])) slice12L = [1, 2, 3, 4, 5]L[-2:] #[4, 5] list generation1[x*2 for x in range(1, 5)] class &amp; instance123456789class s(object): def \__init__(self, name): self.name = name def print_s(self): print('%s:' %(self.name)) s1 = s("john")s1.print_s() customized classdynamic language, so the instance of any class can be added any other attributes. 123456789class s(object): def \__init__(self, name): self._name = name def \__str__(self): return 's object(name: %s)' % self._name def \__getattr__(self, attr): if attr == 'attr1': return lambda: attr1.value raise &amp; except1234567891011import loggingtry: print('try...') r = 10/0 print('result: ', r)except ZeroDiisionError as e: print('except', e) logging.exception(e)finally: print('finally..') IO stream1234567891011f = open('test.log', 'r')print(f.read(size))f.close() #or with open('test.log', 'r') as f: printf(f.read(size)) for line in f.readlines(): print(line.strip()) picklingserializaion/marshalling/flattening and reverse 123456import pickleimport jsond = dic(name='zj', age='18')pickle.dumps(d)json.dumps(d)]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[the OK and not OK in my life]]></title>
    <url>%2F2018%2F10%2F11%2Fthe-OK-and-not-OK-in-my-life%2F</url>
    <content type="text"><![CDATA[go ahead 12345678&lt;table cellspacing=&quot;0&quot; style=&quot;border: 1px solid #333333; margin: 10px;&quot;&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot; style=&quot;border: none; font: bold 16px sans-serif; background: #ffddbb; color: #000000; padding: 5px; margin: 0px; text-align: center;&quot;&gt;This Is My Life, Rated&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 18px sans-serif; text-align: left; border: 1px solid #333333; border-left: none; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Life:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 18px sans-serif; text-align: left; border: 1px solid #333333; border-left: none; border-right: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/grebar.gif&quot; height=&quot;12&quot; width=&quot;124&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 6.2&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Mind:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/greblubar.gif&quot; height=&quot;12&quot; width=&quot;134&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 6.7&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Body:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/blubar.gif&quot; height=&quot;12&quot; width=&quot;156&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 7.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Spirit:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/blupurbar.gif&quot; height=&quot;12&quot; width=&quot;176&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 8.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Friends/Family:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/orbar.gif&quot; height=&quot;12&quot; width=&quot;46&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 2.3&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Love:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/redbar.gif&quot; height=&quot;12&quot; width=&quot;16&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 0.8&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td style=&quot;width: 85px; padding: 5px; font: bold 12px sans-serif; text-align: left; border: none; border-right: 1px solid #333333; background-image: none; background: #ffffcc; color: #000000;&quot;&gt;Finance:&lt;/td&gt;&lt;td style=&quot;width: 240px; padding: 5px; padding-left: 0px; font: bold 12px sans-serif; text-align: left; border: none; vertical-align: middle; background-image: none; background: #ffffff; color: #000000;&quot;&gt;&lt;img src=&quot;http://www.monkeyquiz.com/img/greblubar.gif&quot; height=&quot;12&quot; width=&quot;142&quot; style=&quot;border: 1px solid #000000; border-left: none; vertical-align: middle; padding: 0px; margin: 0px;&quot;&gt; 7.1&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td colspan=&quot;2&quot; style=&quot;border: none; border-top: 1px solid #333333; font: bold 14px sans-serif; background: #ffeedd; padding: 5px; margin: 0px; text-align: center;&quot;&gt;&lt;a href=&quot;http://www.monkeyquiz.com/life/rate_my_life.html&quot; style=&quot;color: #0000ff;&quot;&gt;Take the Rate My Life Quiz&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; I am not a socialized man, period]]></content>
  </entry>
  <entry>
    <title><![CDATA[Btree max path sum]]></title>
    <url>%2F2018%2F10%2F02%2FBtree-max-path-sum%2F</url>
    <content type="text"><![CDATA[leetCode 124. the first idea is recursive from root to bottom leaf, and return the max from left or right at each node. 1234567891011121314151617int subsum(TreeNode* node)&#123; int max_left = 0, max_right =0; if(node-&gt;left) max_left = subsum(node-&gt;left); else return std::max(node-&gt;val, subsum(node-&gt;right)); if(node-&gt;right) max_right = subsum(node-&gt;right); else return std::max(node-&gt;val, subsum(node-&gt;left)); sum += node-&gt;val + std::max(max_left, max_right); return sum;&#125; this will get the max sum branch from top to bottom, but can’t consider the other branch, and there is case when the max sum branch is actually smaller than a subtree sum. so here needs to consider the subtree sum as well, since the root tree can be consider as a subtree, so after implmenting subtree sum, actually no need to consider the other branch sum. 123456789101112131415161718192021222324252627282930313233343536373839404142int subsum(TreeNode* node, std::priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt; &gt;&amp; s)&#123; if(node==nullptr) return 0; int max_left=0, max_right=0; int sum=0; int subtree_sum = 0; if(node-&gt;left)&#123; max_left = subsum(node-&gt;left, s); subtree_sum += max_left; &#125;else &#123; subtree_sum += node-&gt;val; return std::max(node-&gt;val, subsum(node-&gt;right, s)); &#125; if(node-&gt;right)&#123; max_right = subsum(node-&gt;right, s); subtree_sum += max_right; &#125;else&#123; subtree_sum += node-&gt;val; return std::max(node-&gt;val, subsum(node-&gt;left, s)); &#125; sum += node-&gt;val + std::max(max_left, max_right); if(node-&gt;right != nullptr || node-&gt;left != nullptr) subtree_sum += node-&gt;val; else subtree_sum -= node-&gt;val; if(subtree_sum &gt; sum)&#123; s.push(subtree_sum); cout &lt;&lt; "s.top= " &lt;&lt; s.top() &lt;&lt; "\n" &lt;&lt; endl; while( sum &gt; s.top()) &#123; s.pop(); &#125; &#125; return sum; &#125; passing priority_queue s as reference, so if subtree\_sum is bigger than the top-bottom branch sum, then it will be pushed into s; but pop out the elements smaller than current branch sum in each recrusive routing. finally, compare the largest elemnet in s with top-bottom branch sum.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[when pure loop doesn't work out]]></title>
    <url>%2F2018%2F10%2F01%2Fwhen-pure-loop-doesn-t-work-out%2F</url>
    <content type="text"><![CDATA[leetCode 115: given a string S and a string T, count the number of distinct subsequences of S which equals T. Input: S = &quot;babgbag&quot;, T = &quot;bag&quot; Output: 5 Explanation: As shown below, there are 5 ways you can generate &quot;bag&quot; from S. (The caret symbol ^ means the chosen letters) babgbag ^^ ^ babgbag ^^ ^ babgbag ^ ^^ babgbag ^ ^^ babgbag ^^^ first thoughtfor each alpha in T, traversing S, find a match, return; then move forward for next alpha in T and traversing S again, 1234567891011121314151617181920212223242526272829303132int sol(string&amp; s1, string&amp; s2)&#123; string::iterator sit1, sit2, nait; string notagain; int count=0; for(nait = s2.begin(); nait != s2.end(); nait++)&#123; notagain.push_back(*nait); sit1 = s1.begin(); sit1_last = s1.begin(); while( sit1 != s1.end()) &#123; for(sit2=s2.begin(); sit2 != s2.end(), sit1 != s1.end(); sit1++) &#123; if(*sit1 == *sit2) &#123; tmp.push_back(*sit2); sit2++; &#125; if(tmp.compare(s2) == 0) &#123; count++; break; &#125; &#125; sit1 = st1_last++; &#125; &#125;&#125; this is a failed trail. Since this kind of problem really can’t be solved by purely nested for-loop. think about, at the last level (traverse S to get g), there needs one for-loop, then the previous level or the level above (traverse S to get a) needs another loop. and each “a” needs one for-loop to traverse all possible “g” in S again. and the top level (travers S to get “b”) is another for-loop, and each “b” need another for-loop to traverse “a”. and this is only three levels (b-&gt;a-&gt;g) basically if implementing tree traversing with for-loop, since tree structure has many branches to the end, since even each sub-branch needs a for-loop, there will be exponent disaster of for-loop to cover all branches. second thoughtswhat’s the different mindset? recursive. when dealing with many-branches-travsersing (e.g. a tree strucutre), recursive is nature to think. since recursive only consider the neighbor two level branches. for this example, inside each recursive need a for-loop to catch all possible positions of the satisfied character, and stack is need to, when visiting a new character from T need poush, and when find out a T, then need to pop out the last character. during breadth traversing tree, either using a pure recursive or using stack with a while-loop. but here it needs a for-loop and stack inside each recursive. (a little complex) 1234567891011121314151617181920212223242526272829303132333435void rec(string&amp; S, string&amp; T, string::iterator tc, std::stack&lt;char&gt; ss, int&amp; nums )&#123; if(tc == T.end()) return ; for(int i= 0; i&lt;S.size(); i++) &#123; if(S[i] == *tc) &#123; ss.push(*tc); if(ss.size() != T.size()) &#123; string cur_s = S.substr(i+1); rec(cur_s, T, ++tc, ss, nums); --tc; ss.pop(); &#125;else &#123; cout &lt;&lt; "found one\n" ; nums++; ss.pop(); &#125; &#125; &#125;&#125;int sol(string&amp; S, string&amp; T)&#123; string::iterator tit = T.begin(); std::stack&lt;char&gt; ss ; int nums =0; rec(S, T, tit, ss, nums); return nums; &#125; TODO: there suppose be a general pattern for this kind of problem. third thoughtsif the problem is too complex to handle at first, more memory always make it looks simple, using containers to split the content. with 2 for-loops to create #num of buckets to store positions of each alphaet in T 123456789101112131415161718192021int sol(string&amp; s1, string&amp; s2)&#123; int length = s2.size(); std::map&lt;char, vector&lt;int&gt;&gt; smap; std::vector&lt;int&gt; pos; string::iterator sit; char alpha ; for(i=0; i&lt;s2.size(); i++) &#123; alpha = s2[i]; int i=0; pos.clear(); for(sit = s1.begin(); sit != s1.end(); sit++) &#123; if( alpha == *sit) &#123; pos.push_back(i++); &#125; &#125; smap.insert(std::pair&lt;char, vector&lt;int&gt;&gt;(alpha, pos); &#125; b 0, 2, 4 a 1, 5 g 3, 6 after get the map, then play the combinations games. that’s actually still a recursive problem.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Btree traversal]]></title>
    <url>%2F2018%2F10%2F01%2FBtree-traversal%2F</url>
    <content type="text"><![CDATA[Btree traversal is obvious to implement in recursion. here are non-recursion implementation, which needs std::stack or std::queue data structure to store the next level nodes in both deep-first-search idea and breadth-first-search idea, link. these are good examples of using stack, queue. usage in leetCode114, flatten a BTree to a linked list 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192void preorder_print(TreeNode* leaf)&#123; if(leaf == nullptr) return; std::stack&lt;int&gt; s; TreeNode* tmp ; s.clear(); // s.push(leaf); while(!s.empty()) &#123; tmp = s.pop(); cout &lt;&lt; tmp-&gt;value &lt;&lt; ', ' ; if(leaf-&gt;right != nullptr) s.push(leaf-&gt;right); if(leaf-&gt;left != nullptr) s.push(leaf-&gt;left); &#125; &#125;void inorder_print(TreeNode* leaf)&#123; std::stack&lt;int&gt; s ; s.clear(); TreeNode *tmp; while( !s.empty() || leaf!=nullptr) &#123; if(leaf != nullptr) &#123; s.push(leaf); leaf = leaf-&gt;left; &#125;else &#123; tmp = s.top(); s.pop(); cout &lt;&lt; tmp-&gt;value &lt;&lt; ', ' ; leaf = leaf-&gt;right; &#125; &#125;&#125;void postorder_print(TreeNode* leaf)&#123; std::stack&lt;int&gt; s ; s.clear(); TreeNode *lastNodeVisited = nullptr ; TreeNode *peekNode = nullptr; while( !s.empty() || leaf != nullptr) &#123; if(leaf != nullptr) &#123; s.push(leaf); leaf = leaf-&gt;left; &#125;else &#123; peekNode = s.top(); if(peekNode-&gt;right != nullptr &amp;&amp; lastNodeVisited != peekNode-&gt;right) leaf = peekNode-&gt;right; else &#123; cout &lt;&lt; peekNode-&gt;value &lt;&lt; ', '; lastNodeVisited = s.top(); s.pop(); &#125; &#125; &#125;&#125;void bfs_print(TreeNode* leaf)&#123; std::queue&lt;int&gt; q ; q.clear(); q.push(leaf); TreeNode *node; while( ! q.empty()) &#123; node = q.front(); q.pop(); cout &lt;&lt; node-&gt;vaue &lt;&lt; ', '; if(node-&gt;left != nullptr) q.push(node-&gt;left); if(node-&gt;right != nullptr) q.push(node-&gt;right) &#125;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[construct a self balanced BStree]]></title>
    <url>%2F2018%2F09%2F24%2Fconstruct-a-self-balanced-BStree%2F</url>
    <content type="text"><![CDATA[leetCode 109 construct a height-balanced Binary Search tree from input array(sorted or not). a self-balanced BStree, which means the left and right kid of each node have no more than 1 height difference, also named as AVL tree. There are three basic routines in implementation of AVL tree: right tree rotate, left tree rotate, and insert. and each TreeNode requires an additionly height value. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556TreeNode* rightRotate(TreeNode* leaf)&#123; if(leaf==nullptr) return leaf; TreeNode* root_left = leaf-&gt;left ; TreeNode* left_right = root_left-&gt;right ; root_left-&gt;right = leaf; leaf-&gt;left = left_right; return root_left; &#125;TreeNode* leftRotate(TreeNode* leaf)&#123; if(leaf==nullptr) return leaf; TreeNode* root_right = leaf-&gt;right; TreeNode* right_left = root_right-&gt;left; root_right-&gt;left = leaf; leaf-&gt;right = right_left; return root_right;&#125;TreeNode* insert(TreeNode* root, int key)&#123; if(root==nullptr) return (new TreeNode(key)); if(key &gt; root-&gt;val) root-&gt;right = insert(root-&gt;right, key); else if(key &lt; root-&gt;val) root-&gt;left = insert(root-&gt;left, key); else return root; root-&gt;height = std::max(height(root-&gt;left), height(root-&gt;right)) + 1 ; int balance = height_dif(root); if(balance &gt; 1 &amp;&amp; key &lt; root-&gt;val ) //new key inserted in left sub &#123; return rightRotate(root); &#125; /* keep in mind, -1 &lt;= last_balance &lt;= 1 only key &lt; root-&gt;val, will it possible that current_balance &gt; 1 */ if(balance &lt; -1 &amp;&amp; key &gt; root-&gt;val ) &#123; return leftRotate(root); &#125; return root; &#125; at the very first coding I natively pass node pointer by reference: TreeNode* insert(TreeNode* &amp;root, int key) root-&gt;right = insert(root-&gt;right, key); since assigned insert() back to the same node pointer again, if passing by reference, each insert will clear the memory-write the same memory all the time, and can’t generate. what actually happen in insert is creating a new object. the structure pointer inside structure definition is the trick here. when define root node, both leftand right nodes are nullptr, so argument root-&gt;right is nullptr, but the returning root-&gt;right is actually pointing to a node structure memory. also nullptr can’t be dereferring, basically since nullptr doesn’t point to any meaningful object, to dereference a null pointer will cause runtime or immediate crash.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[construct BTree from pre/in/post-order input]]></title>
    <url>%2F2018%2F09%2F19%2Fconstruct-BTree-from-pre-in-post-order-input%2F</url>
    <content type="text"><![CDATA[pre&amp;in-order inputleetCode105 : given preorder and inorder traversal of a tree, construct the binary tree. sol: each top node in Btree, has left-branch and right-branch, and each branch is a similar-structure subtree. so every time pop out the top node, and recursive the two subtrees, which return as the left kid and right kid of current top node. the recursive stopped when the list is empty(in real case, this means the node has only either left or right kid); or stopped when only one element in the list(in real case, the node has both kids, so left or right subtree has only one element). 12345678910111213141516171819202122232425262728293031323334353637TreeNode* sol(list&lt;int&gt;&amp; pre, list&lt;int&gt;&amp; in) &#123; if(pre.empty() || in.empty()) &#123; return nullptr; //empty left/right node &#125; if(pre.size() == 1 &amp;&amp; in.size() == 1) &#123; return new TreeNode(pre.front()); &#125; int root = pre.front(); pre.pop_front(); TreeNode* root_node = new TreeNode(root); list&lt;int&gt;::iterator in_it, pre_it; in_it = std::find(in.begin(), in.end(), root); if(in_it == in.end()) //only one node in inorder list now, wont happen &#123; return (new TreeNode(in.front())); &#125; int idx = std::distance(in.begin(), in_it); list&lt;int&gt; in_left_subtree(in.begin(), in_it); list&lt;int&gt; in_right_subtree(++in_it, in.end()); in.erase(in_it); pre_it = pre.begin(); std::advance(pre_it, idx); list&lt;int&gt; pre_left_subtree(pre.begin(), pre_it); list&lt;int&gt; pre_right_subtree(pre_it, pre.end()); root_node-&gt;left = sol(pre_left_subtree, in_left_subtree); root_node-&gt;right = sol(pre_right_subtree, in_right_subtree); return root_node; &#125; in each recursive step, I am using exteral containers, same stragey in scramble string. is there a one-swap way? post/in-order inputleetCode106 1234567891011121314151617181920212223242526272829TreeNode* sol(list&lt;int&gt;&amp; in, list&lt;int&gt;&amp; post)&#123; if(in.empty() || post.empty()) return nullptr; if(in.size() == 1 || post.size() == 1) return (new TreeNode(in.front())); // return the left || right kid //first find out the tree root, the last element in post-order int root_v = post.back(); TreeNode* root = new TreeNode(root_v); post.pop_back(); //find root_v in inorder list&lt;int&gt;::iterator in_lit = std::find(in.begin(), in.end(), root_v); //create subtrees recursive int left_length = std::distance(in.begin(), in_lit); list&lt;int&gt; in_left_sub(in.begin(), in_lit); list&lt;int&gt; in_right_sub(++in_lit, in.end()); in.erase(in_lit); list&lt;int&gt;::iterator post_lit = std::next(post.begin(), left_length); list&lt;int&gt; post_left_sub(post.begin(), post_lit); list&lt;int&gt; post_right_sub(post_lit, post.end()); root-&gt;left = sol(in_left_sub, post_left_sub); root-&gt;right = sol(in_right_sub, post_right_sub); return root ;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[construct BTree from breadth-order input]]></title>
    <url>%2F2018%2F09%2F19%2Fconstruct-BTree-from-breadth-order-input%2F</url>
    <content type="text"><![CDATA[first there should be a queue or stack to store the next layer elements, as the tree go deeper, there are many branches, which requires a contianer to track what’s the elements in next layer. stack always pop out the top element(FILO), which actually set the input elements in a reversed order as tree elements; queue can pop out the first element(FIFO), which can set the input elements in the same order in tree elements. so here pick std::queue. the input array can used std::vector, each time pop_front(), which basically read the array in order. and each pop_front element constructs a new TreeNode. if the layer container is empty(), then it’s the root layer; else it’s a branch layer. growing the tree in each branch layer, need update the next layer container. for each new inserting element, either insert to left or right of node A in parent layer or insert to the A’s sibling node B. then pop out the node which already has both kids. when traversling to the last node in parent layer, and if both the kids are filled-in, then there is a turning point, need to swap next_parent layer as parent layer. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152void insert_kids(std::queue&lt;TreeNode*&gt;&amp; parents, std::queue&lt;TreeNode*&gt;&amp; next_parents, TreeNode* p)&#123; if(parents.empty()) return ; TreeNode* father = parents.front(); if(!father-&gt;left) &#123; father-&gt;left = p; if(p) next_parents.push(p); &#125;else if(!father-&gt;right) &#123; father-&gt;right = p; if(p) next_parents.push(p); &#125;else &#123; parents.pop(); if(parents.empty()) // turning point, if returned then p will be lost &#123; parents.swap(next_parents); &#125; insert_kids(parents, next_parents, p); &#125; &#125;TreeNode* breadth_construct(list&lt;int&gt;&amp; arr)&#123; TreeNode *p, *root ; int x ; std::queue&lt;TreeNode*&gt; parents, next_parents; while(!arr.empty()) &#123; x = arr.front(); arr.pop_front(); p = (TreeNode*) new TreeNode(x); if(parents.empty()) &#123; parents.push(p); root = p ; continue; &#125;else if( !parents.empty()) //at this step, parents still has 1 element, but after insert_kids, parents is empty. then &#123; insert_kids(parents, next_parents, p); continue; &#125; &#125; return root; &#125; how to deal with NULL during struct constructure? if both (int x) and (TreeNode* p) constructor are defined, which will lead to ambisious when new TreeNode(NULL). 1234567891011121314151617181920212223242526struct TreeNode &#123; int value ; struct TreeNode *left ; struct TreeNode *right; //TODO: how to implement copy assignment in structure ? TreeNode(TreeNode* p) &#123; if(p == NULL) &#123; value = 0; left = NULL; right = NULL; &#125;else &#123; value = p-&gt;value; left = p-&gt;left; right = p-&gt;right; &#125; &#125; TreeNode(int x): value(x), left(NULL), right(NULL) &#123; &#125;&#125;;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[print combinatorics]]></title>
    <url>%2F2018%2F09%2F19%2Fprint-combinatorics%2F</url>
    <content type="text"><![CDATA[combinatorics related algorithms e.g. unique BST(leetCode95), Permutations(46), Unique Path(62). Give an integer m, how many different combinations can have? mathematically, it’s a permutation P_m^m or combination C_m^n problem, the total number is easy to calculate, but how to write a code to print out each combination elegantly ? one core step: how to generate a new combination(k+1) array by inserting one new element into the current combination(k). e.g. {1, 2} --&gt; {3, 1, 2}, {1, 3, 2}, {1, 2, 3} here is basically insert 3 at (k+1) positions, and each new position will generate a new combination with (k+1) size. depends on the problem, choose either vector(to support random access) or list (to support O(1) insert or delete) as the container. one tip here, how to erase one element from std::list while iterating ? 1234567891011121314151617181920212223242526272829303132333435363738394041vector&lt;list&lt;int&gt;&gt; next_layer(vector&lt;list&lt;int&gt;&gt;&amp; layer, int c)&#123; if(layer.empty()) &#123; list&lt;int&gt; tmp ; tmp.push_back(c); layer.push_back(tmp); return layer; &#125; vector&lt;list&lt;int&gt;&gt; next_layer_v, cur; for(int i=0; i&lt;layer.size(); i++) &#123; list&lt;int&gt;::iterator lit ; list&lt;int&gt; arr = layer[i] ; cur.clear(); for(lit = arr.begin(); lit != arr.end(); lit++) &#123; arr.insert(lit, c); //insert c in front of lit cur.push_back(arr); lit = arr.erase(--lit); // erase c, which is 1 step in front of lit, and must return lit here, else lit will become non-refereable &#125; next_layer_v.insert(next_layer_v.end(), cur.begin(), cur.end()); &#125; return next_layer_v; &#125;void sol(int num)&#123; vector&lt;list&lt;int&gt; &gt; layer, last_layer; list&lt;int&gt; cur_list ; for(int i=0; i&lt; num; i++) &#123; layer = next_layer(last_layer, i); last_layer = layer; &#125; print_vec_list(layer);&#125; this implementation is more clear than what I did in Permutation while the memory of many last layers vector]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[object creating in C/C++]]></title>
    <url>%2F2018%2F09%2F11%2Fobject-creating-in-C-C%2F</url>
    <content type="text"><![CDATA[construct an objectthe compiler will define a default constructor with no parameters, if there is no user defined default constructors. usually the parameters for user defined(UD) default constructors should have default values. directly call the UD constructor will create an object; call the UD through new keyword will create an object pointer. 12345678910111213141516struct TreeNode&#123; int val; TreeNode *right ; TreeNode *left; TreeNode(int x=0): val(x), left(NULL), right(NULL)&#123;&#125;; //user defined constructor TreeNode(const TreeNode *cp) //copy constructor &#123; val = cp-&gt;val; right = cp-&gt;right; left = cp-&gt;left; &#125;&#125;TreeNode node1; TreeNode node2(100);TreeNode *node_p = new TreeNode(10); create an object in pure Cnew operator do two things: allocate memory for a C++ class object, then call the object’s constructor to initialize this object. basically, new packages memory management of objects and objects initialization. while in pure C, since there is no object constructor, after malloc memory for the structure, either call an initial function or manually initialize this structure member variables. 123456789101112131415161718192021222324TreeNode &#123; int val; TreeNode *right ; TreeNode *left;&#125;int main()&#123; TreeNode *p = (TreeNode*) malloc( sizeof(struct TreeNode)); p-&gt;val = 0; p-&gt;right = NULL; p-&gt;left = NULL ; &#125;``` ## construct an object array beyond creating one object (pointer), how to create object array. ```c int nums = 5;TreeNode tree_array[nums];TreeNode *tree_p = (TreeNode*) new TreeNode[nums]; be aware, each element in tree_array has the whole memory of TreeNode structure; and tree_p++ will go to next TreeNode structure, tree_p[i] is also a whole memory of TreeNode structure. create an object array in pure C12int nums = 5;TreeNode *tree_p = (TreeNode*) malloc(nums * sizeof(TreeNode)); basically malloc will return a pointer to a block of memory, but it’s not responsible to initialize this block of memory. the rule of fiverule of three is about how to manage dynamically allocated resources in C++. why it is necessary? 1) when parameter B is copying by value from A, if no user defined copy constructor, the compiler will do a shallow copy from A to B by default, in which a new pointer point to the same content address. at the end of function call, the parameter B is out of scope, so destructor is called, and A is still there. but at the end of the main function, A is out of scope, need deallocating, then error is B already deallocate the content of A. with a user defined copy constructor, B will get a deep copy of A, so no sharing content, no problems when deallocating either B or A. 2) if no user specified assignment constructor, a shallow copy happens, then error-potential. and assignment constructor (operator=) can be implemented with copy constructor. 1234567int main()&#123; TreeNode node1; TreeNode node2 = node1; //actually a copy-construct, same as node2(node1) TreeNode node3 ; node3 = node1 ; //a compiler assignment-construct by default(shallow copy)&#125;]]></content>
      <tags>
        <tag>C++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scrabmle string]]></title>
    <url>%2F2018%2F09%2F11%2Fscrabmle-string%2F</url>
    <content type="text"><![CDATA[scramble string at leetCode 87. sol: get all possible scrambled strings of s1, then compare if s2 is in it. for 1-char: scramble(&quot;a&quot;) --&gt; &quot;a&quot; for 2-chars : scramble(&quot;ab&quot;) --&gt; &quot;ba&quot; for 3-chars: scramble(&quot;abc&quot;) --&gt; &quot;bac&quot;, &quot;cba&quot;, &quot;acb&quot;, &quot;cba&quot; for 4-chars: scramble(&quot;abcd&quot;) --&gt; (a | bcd) + (ab | cd) + (abc | d) for 5-chars: scramble(&quot;abcde&quot;) --&gt; (a | bcde) + (ab | cde) + (abc | de) + (abcd | e) from the enumaration, there is always a left-substring and a right-substring, and recursive in each substring. consider the push_back order, there are two: left-&gt;\right and right-&gt;\left at each two slibings. additional routines: how to do substring join and how to delete duplicate string from string-vector. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859 string join(string&amp; sub1, string&amp; sub2) &#123; string res; res.reserve(sub1.size() + sub2.size()); string::iterator it; for(it = sub1.begin(); it != sub1.end(); it++) res.push_back(*it); for(it = sub2.begin(); it != sub2.end(); it++) res.push_back(*it); return res; &#125; //TODO: keep in mind the transfer function, and how to design it vector&lt;string&gt; scramble(string&amp; s) &#123; string ls, rs; vector&lt;string&gt; vls, vrs, vcurs; if(s.size() == 1) &#123; vcurs.push_back(s); return vcurs; &#125; for(int i=1; i&lt;s.size(); i++) &#123; ls = s.substr(0, i); rs = s.substr(i, s.size()); vls = scramble(ls); vrs = scramble(rs); for(int m=0; m&lt; vls.size(); m++) for(int n=0; n &lt; vrs.size(); n++) &#123; vcurs.push_back(join(vls[m], vrs[n])); vcurs.push_back(join(vrs[n], vls[m])); &#125; &#125;/*how to delete duplicated string from vector&lt;string&gt; */ std::sort(vcurs.begin(), vcurs.end()); vcurs.erase( std::unique(vcurs.begin(), vcurs.end()), vcurs.end()); return vcurs; &#125; int main()&#123; string s1 = "abcd" ; vector&lt;string&gt; outs = scramble(s1); for(int i=0; i&lt;outs.size(); i++) cout &lt;&lt; outs[i] &lt;&lt; endl; return 0;&#125; How to write a completed code, meaning, always take care the boundaries correctly, no missing situations. It’s easy to start from scratch and achieve somewhere, but hard to be completed.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how dynamic programming works]]></title>
    <url>%2F2018%2F09%2F04%2Fhow-dynamic-programming-works%2F</url>
    <content type="text"><![CDATA[leetcode 64(Mini Path Sum): Given a m x n grid filled with non-negative numbers, find a path from top left to bottom right which minimizes the sum of all numbers along its path. the first thought is to build a tree： 1 / \ 1 3 / \ / \ 4 5 1 5 / /\ / /\ 2 1 2 1 1 2 while this is not a balanced tree, no regular tree way to maintain. Then what else solution? Dynamic Programming is a strategy to solve a simple problem at first, then find the rules(status transfer from previous state to current state) for the remaining problems. step1: the simpler problem, or as initial/boundary condition. e.g. only one row, or only one col, what’s the solution. step2: in general m rows, n cols, how to get the iterative rules after step1. 123456789101112131415161718192021222324252627282930313233343536373839int sol(vector&lt;vector&lt;int&gt; &gt;&amp; mat)&#123; vector&lt;vector&lt;int&gt; &gt; dp; int row = mat.size(); int col = mat[0].size(); for(int i=0; i&lt;row; i++) dp[i][0] += mat[i][0]; for(int j=0; j&lt;col; j++) dp[0][j] += mat[0][j]; for(int i=1; i&lt;row; i++) for(int j=1; j&lt;col; j++) dp[i][j] = min(dp[i-1][j], dp[i][j-1]) + mat[i][j]; return dp[row-1][col-1]; &#125;int main()&#123; vector&lt;int&gt; v1, v2, v3 ; v1 = &#123;1, 3, 1&#125;; v2 = &#123;1, 5, 1&#125;; v3 = &#123;4, 2, 1&#125; vector&lt;vector&lt;int&gt; &gt; mat; mat.push_back(v1); mat.push_back(v2); mat.push_back(v3); int out = sol(mat); cout &lt;&lt; "output =" &lt;&lt; out &lt;&lt; endl; return 0;&#125; See DP solution is much clear than design the tree.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how recursive works with passing reference variables]]></title>
    <url>%2F2018%2F08%2F29%2Fhow-recursive-works-with-passing-reference-variables%2F</url>
    <content type="text"><![CDATA[leetCode 62(unique paths): A robot is located at the top-left corner of a m x n grid (marked ‘Start’ in the diagram below). The robot can only move either down or right at any point in time. The robot is trying to reach the bottom-right corner of the grid (marked ‘Finish’ in the diagram below). How many possible unique paths are there? solution: it’s easy to model as a math combination problem, assume the right-step has m; the down-step has n. so each path from top left to bottom right, has (m+n) steps totally. the total unique paths is C_(m+n)^m passing by value: 12345int sol(int rm, int rn)&#123; return rm==0 ? 1 : (rm+rn)/rm * sol(rm-1, rn);&#125; what happened if rm-1 changed to rm–? warning: unsequenced modification and access to &apos;rm&apos; what about passing as reference ? 1234int sol(int&amp; m, int&amp; n)&#123; return m==0 ? 1 : (m+n)/(float)m * sol(--m, n);&#125; if using m– : error: expects an l-value for 1st argument of sol(int&amp;, int&amp;) m– is only r-value, can’t be used as reference varaible; but –m is r-value. for m as a reference variable, –m is the way to update the content of the address. while m– more like move to the next address?]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how backtracks work]]></title>
    <url>%2F2018%2F08%2F29%2Fhow-backtracks-work%2F</url>
    <content type="text"><![CDATA[leetCode 50 (N-Queens): The n-queens puzzle is the problem of placing n queens on an n×n chessboard such that no two queens attack each other. solution: each potentional position for a queen should satisfy no attach, then traverse the 2D grids to find out all good positions; it requires to find all possible combinations, so recursive call will be used also. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106 bool one_queen_visited(int** mat, int n, pair&lt;int, int&gt;&amp; queen_idx) &#123; int row = queen_idx.first ; int col = queen_idx.second; for(int i=0; i&lt;n; i++) &#123; for(int j=0; j&lt;n; j++) &#123; if(mat[row][j] == 0) mat[row][j] = 1; else if(mat[row][j] == 100) return false; &#125; if(mat[i][col] == 0) mat[i][col] = 1; else if(mat[i][col] == 100) return false; &#125; //for left leaning for(int i=row, j=col; i&gt;=0 &amp;&amp; j&gt;=0; i--, j--) &#123; if(mat[i][j] == 0) mat[i][j] = 1; else if(mat[i][j] == 100) return false; &#125; for(int i=row, j=col; i&lt;n &amp;&amp; j&lt;n; i++, j++) &#123; if(mat[i][j] == 0) mat[i][j] = 1; else if(mat[i][j] == 100) return false; &#125; //for right leaning //down for(int i=row, j=col; i&lt;n &amp;&amp; j&gt;=0; i++, j--) &#123; if(mat[i][j] == 0) mat[i][j] = 1; else if(mat[i][j] == 100) return false; &#125; //up for(int i=row, j=col; i&gt;=0 &amp;&amp; j&lt;n; i--, j++) &#123; if(mat[i][j] == 0) mat[i][j] = 1; else if(mat[i][j] == 100) return false; &#125; mat[row][col] = 100; //queen location marked as 100 return true; &#125;int backtrack = 0; void sol(int** mat, int n, int start_j=0) &#123; std::pair&lt;int, int&gt; idx; vector&lt;pair&lt;int, int&gt;&gt; queens; vector&lt; vector&lt;pair&lt;int, int&gt;&gt; &gt; queens_v; if(start_j &gt; n) return ; //end of recursive for(int i=0; i&lt;n; i++) &#123; for(int j= ((i==0)? max(start_j, 0) : 0); j&lt;n; j++) &#123; idx = std::make_pair(i, j); if(one_queen_visited(mat, n, idx)) // find a fit queen position, store into queens &#123; queens.push_back(idx); &#125; &#125; &#125; if(queens.size() == n) &#123; queens_v.push_back(queens); int** mat_copy = new int*[n] ; for(int i=0; i&lt;n; i++) &#123; mat_copy[i] = new int[n](); &#125; for(int i=0; i&lt;queens.size(); i++) &#123; idx = queens[i]; mat_copy[idx.first][idx.second] = 1 ; &#125; for(int i=0; i&lt;n; i++) &#123; for(int j=0; j&lt;n; j++) cout&lt;&lt; mat_copy[i][j] &lt;&lt; ' ' ; cout &lt;&lt; endl; &#125; &#125; clean_mat(mat, n); sol(mat, n, ++backtrack); &#125; I did actually new memory in C++ as following: 123int** mat = (int**) new(n * sizeof(int*)); for(int i=0; i&lt;n; i++) mat[i] = (int*) new( n * sizeof(int)); which failed, then realized only malloc works in this way.]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how broad first search works]]></title>
    <url>%2F2018%2F08%2F29%2Fhow-broad-first-search-works%2F</url>
    <content type="text"><![CDATA[leetCode 45 (jump game): Given an array of non-negative integers, you are initially positioned at the first index of the array.Each element in the array represents your maximum jump length at that position.Your goal is to reach the last index in the minimum number of jumps. e.g. [2, 3, 1, 1, 4] –&gt; 2 solution: at current position, bfs all the next positions it can jump to, when the back element is in next position list, then reached. 1234567891011121314151617181920212223242526272829303132333435363738394041int sol(vector&lt;int&gt;&amp; nums )&#123; vector&lt;int&gt;::iterator it, cur_it ; vector&lt;int&gt; *adj = new vector&lt;int&gt;[nums.size()]; int cur_node ; for(it=nums.begin(); it &lt; nums.end(); it++) &#123; cur_node = *it; adj[cur_node].push_back(cur_node); for(int i=1; i&lt;=cur_node; i++) &#123; cur_it = std::next(it, i); adj[cur_node].push_back(*cur_it); if( *cur_it == nums.back())&#123; it = nums.end(); //reach the last element, so return &#125; &#125; &#125; vector&lt;int&gt; tmp; int last_element = nums.back(); int mini_path = 1; for(int i=0; i &lt; nums.size(); i++) &#123; tmp = adj[i]; if(!tmp.empty()) &#123; for(int j=0; j&lt;tmp.size(); j++) &#123; cout&lt;&lt; tmp[j] &lt;&lt; ' ' ; &#125; cout &lt;&lt; endl; if(tmp.back() == last_element) &#123; return mini_path; &#125; mini_path++; &#125; &#125; return -1;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[how recursive works]]></title>
    <url>%2F2018%2F08%2F29%2Fhow-recursive-works%2F</url>
    <content type="text"><![CDATA[leetCode 46 Permutations: given a collection of distinct integers, return all possible permutations. Input: [1, 2, 3] Output: [ [1,2,3], [1,3,2], [2, 1, 3], [2, 3, 1], [3, 1,2], [3,2,1] ] At first glipmse, it’s middle difficult, jump to recursive implementation. But there always confused failures, e.g. passing vector as reference to the recursive calls, and even do a deep copy of that vector, the base vector is always modified by the copied vector. This problem blocks me a whole day, actually I don’t know how to make a recursive calls work. tip1) each recursive fun has its independent local variables ; tip2) recursive calls are serialized, namely only when inside recursive fun is done, then the outside recursive will continue. tip1 helps to explain when local variables changed unexpected; tip2 helps cause I trend to think all recursive calls are parallezed running, but the real running order is serialized, so no twist. simulate how human brain solve this problem: &lt;1(fix), 2(fix), 3&gt; ; &lt;1(fix), 3(fix), 2&gt; … the first position has n potentional values, then the second position has (n-1) potentional values, etc. so design the very first implementation as: traverse all potentional values in first position, and push it; then travers all potentional values in next position, and push it; till the last position, while only one element left, and push it. so a new combination is created. 123456789101112131415161718192021222324252627vector&lt;vector&lt;int&gt;&gt; sol1(vector&lt;int&gt;&amp; nums)&#123; vector&lt;vector&lt;int&gt;&gt; idx_vector ; for(int i=0; i&lt; nums.size(); i++) &#123; vector&lt;int&gt; tmp ; tmp.push_back(nums[i]); //the first element in new created vector vector&lt;int&gt; nums1 = nums ; nums1.erase(nums1.begin()+i); //the second element in new created vector for(int j=0; j&lt; nums1.size(); j++) &#123; tmp.push_back(nums1[j]); vector&lt;int&gt; nums2 = nums1; nums2.erase(nums2.begin() + j); if(nums2.size() == 1) &#123; tmp.push_back(nums2[0]); idx_vector.push_back(tmp); tmp.pop_back(); &#125; tmp.pop_back(); &#125; &#125; return idx_vector; &#125; the first implmenation only works for fixed input , so how to design a recursive fun to make this idea more general ? it’s easy to abstract the process above: for ith position in the new combination vector, the potentional values is one less from (i-1)th position, traverse all possible values in ith position and push it, don’t forget pop it out for traversing to the next possible value; and the end of recursive is when only one element left. 123456789101112131415161718192021void sol(vector&lt;int&gt;&amp; nums, vector&lt;int&gt;&amp; tmp, vector&lt;vector&lt;int&gt;&gt;&amp; idx_vector )&#123; if(nums.size() == 1) &#123; tmp.push_back(nums[0]); idx_vector.push_back(tmp); tmp.pop_back(); return ; &#125; for(int i=0; i&lt; nums.size(); i++) &#123; tmp.push_back(nums[i]); vector&lt;int&gt; nums2 = nums; nums2.erase(nums2.begin()+i); sol(nums2, tmp, idx_vector); tmp.pop_back(); &#125; return;&#125; test: 123456789101112131415161718int main()&#123; vector&lt;int&gt; nums = &#123;1, 2, 3, 4&#125;; int size = nums.size(); vector&lt;int&gt; tmp ; vector&lt;vector&lt;int&gt;&gt; outs; sol(nums, tmp, outs); vector&lt;int&gt;::iterator it ; for(int i=0; i&lt; size*(size-1); i++) &#123; for(it = outs[i].begin(); it != outs[i].end(); it++) cout&lt;&lt; *it &lt;&lt; ' ' ; cout &lt;&lt; "\n" &lt;&lt; endl ; &#125; return 0;&#125;]]></content>
      <tags>
        <tag>leetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MIT 6.S094 Deep Learning for Self Driving Cars]]></title>
    <url>%2F2018%2F08%2F10%2FMIT-s094%2F</url>
    <content type="text"><![CDATA[1 Deep Reinforcement Learning linkapps: motion planning 2 Convolutional Neural Networks linkapps: End-2-end driving task(pedestrian detect) 3 Recurrent Neural Networks linkapps: steering control through time CNN Project: DeepTeslaDRL Project: DeepTrafficFramework: ConvNetJS]]></content>
  </entry>
  <entry>
    <title><![CDATA[C++ template and STL containers]]></title>
    <url>%2F2018%2F08%2F10%2FC-template-and-STL-containers%2F</url>
    <content type="text"><![CDATA[I used C++ couple years already, but never take a close look at it. when looking back to few C++ demo works at school, I had a strong feeling at that time, to make the code running is my only goal, how it work or how to improve it, is always ignored, I am afraid in the language details, as the wisdom say: the evil is in details. after working for three years, I feel the necessary and urgent to back to the language itself(e.g. Linux, C/C++) as the first step to move forward in application development. Frameworks, engineering-based APIs are more close to final products, making them easy to be attracted, compared to how the details implemented. like the mechanical undergradute students, who first-time run ABAQUS with beatiful visulized results, feels so good. anyway I have to delay the short satification or self-feeling-good. C is clean and the applications have clear structure, C++ is more metaphysics, I even don’t know where to start. even I thought I knew C++ well, but actualy there are many details behind, e.g. allocator in STL. templatetemplate is used for generic programming, e.g. both vector and vector smell same at compiler time. Template reels off or abstract the common part “vector” as a container, and whatever type is ok to store in. function template123456789101112template &lt;class T&gt; void func(T arg)template &lt;typename T&gt; void func(T arg)template &lt;class T&gt; T add(T n1, int v)&#123;&#125;;template &lt;class T1, class T2, class T3&gt; T3 func(T1 a1, T2 a2, int arg3=3)&#123;&#125;; the actual meaning of TYPE is deduced by compiler depending on the arg passed to this function. “class” or “typename” is similar. template supports default parameters, once the i-th argument is set with default value, all arguments after it must using default values. class template123456789101112template&lt;class _Tp, class _Ref, class _Ptr&gt;class _list_iterator &#123; typedef _List_iterator&lt;_Tp, _Tp&amp;, _Tp*&gt; iterator ; typedef _List_iterator&lt;_Tp, const _Tp&amp;, const _Tp*&gt; const_iterator ; typedef _List_iterator&lt;_Tp, _Ref, _Ptr&gt; _Self ; typedef _Tp value_type ; typedef _Ptr pointer; typedef _Ref reference ; typedef _List_node&lt;_Tp&gt; _Node; &#125; feel the power of template in STL source code. STL containersreferences:&lt;&lt; the annotated STL source using SGI STL &gt;&gt; by jjHoua visitor guide to C++ allocatorthe annotated STL sourceI took several days to start, cause the first section on allocator already blocked me. why allocator ?The logic of a dynamic container doesn’t depend on the specifies of how memory is obtained; namely, the design of container classes should be decoupled from the memory allocation policy. how allocator works ?memory allocation and object construction is separated, allocator has four operations: allocate(), deallocate(), construct(), destroy(). there are std interface to allocators 1234567AllocTraits = std::allocator_traits&lt;alloc&gt; // define an allocator of type "alloc" AllocTraits::pointer p = AllocTraits::allocate(a, n) //get memory space for n objects of type T, but not construct yet AllocTraits::construct(a, trueaddress(ptr), x, y, z) ; //construct a T(x, y, z)AllocTraits::destroy(a, trueaddress(ptr)); // ~T()AllocTraits::deallocate(a, ptr, 1) ; // deallocate the space for one T object WHEN we say A is an allocator for T , where T is a type e.g. AllocatTraits::value_type. we mean, A knows how to obtain and release memory to store objects of type T. git:allocator iteratoriterator is used to build algorithms in containers. while I don’t really get the traits 1234567891011121314151617template &lt;class _Iterator&gt;struct iterator_traits &#123; typedef typename _Iterator::iterator_category iterator_category ; typedef typename _Iterator::value_type value_type ; typedef typename _Iterator::difference_type difference_type ; typedef typename _Iterator::pointer pointer; typedef typename _Iterator::reference reference ;&#125;;template&lt;class _Tp&gt;struct iterator_traits&lt;_Tp*&gt; &#123; typedef typename random_access_iterator_tag iterator_category ; typedef typename _Tp value_type ; typedef typename ptrdiff_t difference_type ; typedef typename _Tp* pointer; typedef typename _Tp&amp; eference ;&#125;; vectorstd::vector is dynamic, continous. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071template &lt;class _Tp, class _Alloc = __STL_DEFAULT_ALLOCATOR(_Tp)&gt;class vector:: protected _Vector_base&lt;_Tp, _Alloc&gt;&#123; public: typedef _Tp value_type ; typedef value_type* pointer ; typedef const value_type* const_pointer ; typedef value_type* iterator ; typedef const value_type* const_iterator ; iterator begin() &#123;return _M_start;&#125;; iterator end() &#123;return _M_finish ;&#125;; protected: _Tp* _M_start ; // the starting point of current used space _Tp* _M_finish; // the ending point of current sued space _Tp* _M_end_of_storage; // the end of total avialable space(capacity) public: explicit vector(const allocator_type&amp; __a = allocator_type()) : _Base(__a)&#123;&#125; //default constructor // construt of n elements of initial-value vector(size_type __n, const _Tp&amp; __value, const allocator_type&amp; __a = allocator_type()) : _Base(__n, __a) &#123; _M_finish = uninitialized_fill_n(_M_start, __n, __value); &#125; //copy construtor vector(const vector&lt;_Tp, _Alloc&gt;&amp; __x) :_Base(__x.size(), __x.get_allocator()) &#123; _M_finish = uninitialized_copy(__x.begin(), __x.end(), _M_start); &#125; size_type size() const &#123;return size_type(end() - begin());&#125; size_type capacity() const &#123;return size_type(_M_end_of_storage - begin()); bool empty() const&#123;return begin() == end();&#125; reference operator[](size_type __n)&#123;return *(begin() + __n);&#125; void reserve(size_type __n)&#123; if (capacity() &lt; __n) &#123; const size_type __old_size = size(); iterator __tmp = _M_allocate_and_copy(__n, _M_start, _M_finish); destroy(_M_start, _M_finish); _M_deallocate(_M_start, _M_end_of_storage-_M_start); _M_start = __tmp; _M_finish = __tmp + __old_size ; _M_end_of_storage = _M_start + __n ; &#125; &#125; void push_back(const _Tp&amp; __x) &#123; if(_M_finish != _M_end_of_storage) &#123; construct(_M_finish, __x); ++_M_finish; &#125;else _M_insert_aux(end(), __x); &#125; template&lt;class _Tp, class _Alloc&gt; inline bool operator==(const vector&lt;_Tp, _Alloc&gt;&amp; __x, const vector&lt;_Tp, _Alloc&gt;&amp; __y) &#123; return __x.size() == __y.size() &amp;&amp; equal(__x.begin(), __x.end(), __y.begin()); &#125;&#125;; liststd::list is cycling double-direction link list. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140struct _List_node_base &#123; _List_node_base * _M_next ; _List_node_base * _M_prev ;&#125;;template &lt;class _Tp&gt;struct _List_node : public _List_node_base &#123; _Tp _M_data;&#125;;struct _List_iterator_base &#123; typedef size_t size_type ; typedef ptrdiff_t difference_type ; typedef bidirectional_iterator_tag iterator_category; _List_node_base* _M_node ; //constructor _List_iterator_base(_List_node_base* __x) : _M_node(__x)&#123;&#125; _List_iterator_base()&#123;&#125;; void _M_incr() &#123; _M_node = _M_node-&gt;_M_next; &#125;; void _M_decr() &#123; _M_node = _M_node-&gt;_M_prev; &#125;; bool operator==(const _List_iterator_base&amp; __x) const &#123; return _M_node == __x.M_node ; &#125;&#125;;template&lt;class _Tp, class _Ref, class _Ptr&gt;struct _List_iterator : public _List_iterator_base &#123; typedef _List_iterator&lt;_Tp, _Tp&amp;, _Tp*&gt; iterator ; typedef _List_iterator&lt;_Tp, const _Tp&amp;, const _Tp*&gt; const_iterator ; typedef _List_iterator&lt;_Tp, _Ref, _Ptr&gt; _Self ; typedef _Tp value_type ; typedef _Ptr pointer; typedef _Ref reference ; typedef _List_node&lt;_Tp&gt; _Node; //constructor _List_iterator(_Node* __x): _List_iterator_base(__x)&#123;&#125; _List_iterator()&#123;&#125; reference operator*() const &#123;return ( (_Node*) _M_node)-&gt;_M_data; &#125; _Self&amp; operator++() &#123; this-&gt;_M_incr(); return *this; &#125;&#125;;template &lt;class _Tp, class _Alloc=_STL_DEFAULT_ALLOCATOR(_Tp)&gt;class list : protected _List_base&lt;_Tp, _Alloc&gt;&#123; public: typedef _List_node&lt;_Tp&gt; _Node; protected: _List_node&lt;_Tp&gt; * _M_node; public: list(size_type __n, const _Tp&amp; __value, const allocator_type&amp; __a = allocator_type()) : Base_(__a) &#123; insert(begin(), __n, __value); &#125; explicit list(size_type __n) :_Base(allocator_type()) &#123; insert(begin(), __n, _Tp()); &#125; protected: _Node* _M_create_node(const _Tp&amp; __x) &#123; _Node* __p = _M_get_node(); __STL_TRY &#123; _Construct(&amp;_p-&gt;_M_data, __x); &#125; return __p; &#125; public: iterator begin() &#123; return (_Node*)(_M_node-&gt;_M_next);&#125; iterator end() &#123; return _M_node; &#125; bool empty() const &#123;return _M_node-&gt;_M_next == _M_node ;&#125; size_type size() const &#123; size_type __result = 0; distance( begin(), end(), __result); return __result; &#125; size_type max_size() const &#123;return size_type(-1);&#125; reference front() &#123;return *begin();&#125; reference back() &#123;return *(--end());&#125; void swap(list&lt;_Tp, _Alloc&gt;&amp; __x) &#123; __STD::swap(_M_node, __x._M_node); &#125; interator insert(iterator __position, const _Tp&amp; __x) &#123; _Node* __tmp = _M_create_node(__x); __tmp-&gt;_M_next = __position._M_node ; __tmp-&gt;_M_prev = __position._M_node-&gt;_M_prev ; __position._M_node-&gt;_M_prev-&gt;_M_next = __tmp; __position._M_node-&gt;_M_prev = __tmp; return __tmp; &#125; void push_front(const _Tp&amp; __x)&#123;insert(begin(), __x);&#125; void push_back(const _Tp&amp; __x)&#123;insert(end(), __x);&#125; iterator erase(iterator __position) &#123; _List_node_base* __next_node = __position._M_node-&gt;_M_next ; _List_node_base* __prev_node = __position._M_node-&gt;_M_prev ; _Node* __n = (_Node*) __position._M_node ; __prev_node-&gt;next = __next_node ; __next_node-&gt;prev = __prev_node; _Destroy(&amp;__n-&gt;_M_data); _M_put_data(__n); return iterator((_Node*) __next_node); &#125;&#125; dequeuestd::dequeue can operate elements at both ends, and the memory is multi-sectional, in each memory section is linear continous, with advantage of vector and list. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155template &lt;class _Tp, class _Ref, class _Ptr&gt;struct _Deque_iterator &#123; typedef _Deque_iterator&lt;_Tp, _Tp&amp;, _Tp*&gt; iterator ; typedef _Deque_iterator&lt;_Tp, const _Tp&amp;, const _Tp*&gt; const_iterator ; static size_t _S_buffer_size() &#123;return __deque_buf_size(sizeof(_Tp));&#125; typedef random_access_iterator_tag iterator_category; typedef _Tp value_type ; typedef _Ptr pointer; typedef _Ref reference; typedef size_t size_type ; typedef ptrdiff_t difference_type ; typedef _Tp** _Map_pointer ; typedef _Deque_iterator _Self; _Tp* _M_cur ; //current point in cache _Tp* _M_first; //first point in cache _Tp* _M_last; _Map_pointer _M_node ; /* deque support multi-section memory space, in each memory section is linear continous * Map index is used to point to the memory sections */ _Deque_iterator(_Tp* __x, _Map_pointer __y) :_M_cur(__x), _M_first(*__y), _M_last(*__y + _S_buffer_size()), _M_node(__y) &#123;&#125; //default //copy difference_type operator-(const _Self&amp; __x) const &#123; return difference_type(_S_buffer_size()) * (_M_node - __x.M_node - 1) + (_M_cur - _M_first) + (__x._M_last - __x._M_cur); &#125; _Self&amp; operator++() &#123; ++_M_cur ; if(_M_cur == _M_last)&#123; _M_set_node(_M_node + 1); _M_cur = _M_first; &#125; return *this; &#125; _Self&amp; operator--() &#123; if(_M_cur == _M_first)&#123; _M_set_node(_M_node - 1); _M_cur = _M_last; &#125; --_M_cur ; return *this; &#125;&#125; /* deque has two iterator: start -&gt; the first element in first cache space; finish -&gt; the last element in last cache space */template &lt;class _Tp, class _Alloc&gt;class _Deque_base &#123; protected: _Tp** _M_map ; size_t _M_map_size; iterator _M_start; iterator _M_finish;&#125;;template &lt;class _Tp, class _Alloc = __STL_DEFAULT_ALLOCATOR(_Tp)&gt;class deque : protected _Deque_base&lt;_Tp, _Alloc&gt;&#123; public: typedef typename _Base::iterator iterator ; typedef typename _Base::const_iterator const_iterator ; protected: using _Base::_M_map ; using _Base::_M_map_size ; using _Base::_M_start ; using _Base::_M_finish ; public: explicit deque(const allocator_type&amp; __a = allocator_type()) :_Base(__a, 0) &#123;&#125; deque(const deque&amp; __x): _Base(__x.get_allocator(), __x.size()) &#123; uninitialized_copy(__x.begin(), __x.end(), _M_start); &#125; ~deque()&#123; destroy(_M_start, _M_finish);&#125; void push_back(const value_type&amp; __t) &#123; if(_M_finish._M_cur != _M_finish._M_last - 1) &#123; construct(_M_finish._M_cur, __t); ++_M_finish._M_cur ; &#125;else _M_push_back_aux(__t); &#125; void push_front(const value_type&amp; __t) &#123; if(_M_start._M_cur != _M_start._M_first) &#123; construct(_M_start._M_cur - 1, __t); --_M_start._M_cur; &#125;else _M_push_front_aux(__t); &#125; void pop_back() &#123; if(_M_finish._M_cur != _M_finish._M_first) &#123; --_M_finish._M_cur; destroy(_M_finish._M_cur); &#125;else _M_pop_back_aux(); &#125; void pop_front() &#123; if(_M_start._M_cur != _M_start._M_last -1) &#123; destroy(_M_start._M_cur); ++_M_start._M_cur; &#125;else _M_pop_back_aux(); &#125; iterator insert(iterator position, const value_type&amp; __x) &#123; if(position._M_cur == _M_start._M_cur) &#123; push_front(__x); return _M_start; &#125;else if(position._M_cur == _M_finish._M_cur) &#123; push_back(__x); iterator __tmp = _M_finish; --__tmp; return __tmp; &#125; &#125;&#125;; stackstd::stack only operate on the top element (first in last out), can’t iterate the container, the default container for stack is deque. 123456789101112131415161718192021222324252627temlate &lt;class _Tp, class _Sequence&gt;class stack&#123; public: typedef typname _Sequence::value_type value_type ; typedef typname _Sequence::size_type size_type ; typedef typname _Sequence container_type ; typedef typname _Sequence::reference reference ; typedef typname _Sequence::const_reference const_reference; protected: _Sequence c; // the fundmental container: deque by default public: stack() : c() &#123;&#125; explicit stack(const _Sequence&amp; __s) : c(__s) &#123;&#125; bool empty() const &#123; return c.empty();&#125; size_type size() const &#123;return c.size();&#125; reference top() &#123;return c.back(); &#125; void push(const value_type&amp; __x)&#123; c.push_back(__x);&#125; void pop() &#123; c.pop_back();&#125; template&lt;class _Tp, class _Seq&gt; bool operator==(const stack&lt;_Tp, _Seq&gt;&amp; __x, const stack&lt;_Tp, _Seq&gt;&amp; __y) &#123; return __x.c == __y.c ; &#125;&#125;; queuestd::queue supports only pop element from front, and push element into end, the default container is dequeue 123456789101112131415161718192021222324252627template &lt;class _Tp, class _Sequence&gt;class queue&#123; public: typedef typname _Sequence::value_type value_type ; typedef typname _Sequence::size_type size_type ; typedef typname _Sequence container_type ; typedef typname _Sequence::reference reference ; typedef typname _Sequence::const_reference const_reference; protected: _Sequence c; // the fundmental container: deque by default public: queue() : c() &#123;&#125; explicit queue(const _Sequence&amp; __s) : c(__s) &#123;&#125; bool empty() const &#123; return c.empty();&#125; size_type size() const &#123;return c.size();&#125; reference top() &#123;return c.back(); &#125; void push(const value_type&amp; __x)&#123; c.push_back(__x);&#125; void pop() &#123; c.pop_front();&#125; template&lt;class _Tp, class _Seq&gt; bool operator==(const queue&lt;_Tp, _Seq&gt;&amp; __x, const queue&lt;_Tp, _Seq&gt;&amp; __y) &#123; return __x.c == __y.c ; &#125;&#125;; priority queuestd::priority_queue is queue with priority.]]></content>
      <tags>
        <tag>c++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[design a threadpool in pure C]]></title>
    <url>%2F2018%2F08%2F02%2Fdesign-a-threadpool-in-pure-C%2F</url>
    <content type="text"><![CDATA[actually this post should be named as “pure C multithreads”, while it’s better to write some real code. a simple threadpool in pure C exposed APIsat most simple case, what a threadpool object should do? thpool_init(num_threads); thpool_destory(threapool_obj); thpool_add_work(callback, args); // so user define event callback() can be passed in; threadpool is used to assign jobs (from job list) to a thread. so joblist should be an internal class; and it’s better to package thread, job as separate class too; to add work, what kind of funcs need for joblist ? at least, to add new job(from outside) to the joblist. internal structures:123456789101112131415161718192021222324252627struct thread &#123; int id; pthread_t thread; //pthread_t is a unsigned long int; it's system assigned threadpool *thpool; //so thread know its domain&#125;struct job &#123; (void*) func(void*); // each job/task should have a callback func (void*) func_arg ; //and func args //since consider joblist as a list, it's helpful to add pointers to neighbors job* prev; job* next;&#125;struct jobqueue &#123; int num_jobs; job* front; job* rear; //some flags to support add new node(job) to the list&#125; struct threadpool_ &#123; thread* threads_array; jobqueue job_queue; // some flags &#125; consider syncronlizationwill multi threads call add_task() simutaneously? if so, jobqueue should have a mutex object; 123456 struct jobqueue &#123; int num_jobs; job* front; job* rear; pthread_mutex_t jq_mutex;&#125; during threadpool initialization, will all threads be created simultaneously and immediately? if not, there should be thread status flags (creating, exisiting-but-idle, working, died); and to update these flags need protect by mutex object; 123456struct threadpool_ &#123; thread* threads_array; jobqueue job_queue; int num_threads; //stands for the number of all existing threads pthread_mutex_t tp_mutex; &#125; this is an interesting, when design a lib, what’s in my mind. hopefully implement by the end of week.]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pure C socket]]></title>
    <url>%2F2018%2F07%2F31%2Fpure-C-socket%2F</url>
    <content type="text"><![CDATA[this is a review from GNU C lib. socket is a two-way communication channel, both read and write can be performed at either end. sys/socket.h123456789101112131415161718192021222324252627282930313233343536373839int socket(AF_INET, SOCK_STREAM, protocol); /* return fd for this new socket, or -1 as error */int close(int socket_fd); /* return 0 when close successfuly, else return -1 */int connect(int socket, struct sockaddr *addr, socketlen_t len);/* initiate a connection from (client) socket to (server) address; by default, the connection is blocking untill server respond */int listen(int socket, int n);/* n specifies the length of queue for pending connections; when the queue fills up, new clients attempting to connect will fail */int accept(int socket, struct sockaddr *addr, socketlen_t *len_ptr);/* if successfully, accept return a new socket fd, the original (server) socket remains open and unconnected; the address and len_ptr are used to return information about the name of client socket that initiated this connection */size_t send(int socket, const void *buffer, size_t size, int flags);/* param socket is the fd of current sending socket. no receiver socket explicitly defined, since connection-oriented(TCP)protocol will connect first prior to send/receive */size_t recv(int socket, const void *buffer, size_t size, int flags);/* param socket is the fd of current receiving socket */``` ## network socket I didn't realize GNU C socket I/O is so related to network socket. the missing part when reading muduo, libuv is here. The server listens the connection requests on the special server socket, then accept each incoming connection. select() blocks/sleeps the program until input is available/ready on the special server socket/fd. ```cvoid FD_ZERO(fd_set *set) /* initialized the file descriptor set to empty set */void FD_SET(int fd, fd_set *set) /* add fd to set */void FD_CLR(int fd, fd_set *set) /*remove fd from set */void FD_ISSET(int fd, const fd_set * set) /* return true(non-zero) if fd is in set; else return 0 */STDIN_FILENO ; /* file descriptor for std input “1” */ how to debug server/client code? chatRoom]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pure C I/O]]></title>
    <url>%2F2018%2F07%2F31%2Fpure-C-i-o%2F</url>
    <content type="text"><![CDATA[this is a review from GNU C programming streamtwo basic mechanism for representing the connection between your program and the file: streams &amp; file descriptors. FD is represented as objects of type int; streams are represented as FILE * objects a stream is an abstract concept reprensenting a communication channel to a file, a device, or consider it as a sequence of characters with functions to take characters out of one end, and put characters into the other end, like a pipe. file positionan integer representing the number of bytes from the beginning of the file; each time a character read or written, the file position is incremented, namely, access to a file is sequential. 12345678910111213141516171819202122long int ftell(FILE \* stream); //return file position int fseek(FILE \*stream, long int offset, int whence);/\* whence is SEEK\_SET | SEEK\_CUR | SEEK\_END \*/``` “write to a file” is always appended sequentially to the end of the file, regardless of the file position; but “read from a file” is used the current file position. which means multiple reading can happens simultaneously with an independent file pointer. In fact, each opening creates an independent file position pointer, even in the same program to open a file twice. ## std streams```c FILE *stdin ; FILE *stdout; FILE *stderr; FILE *fopen(const char *filename, const char *openMode); /* create a new stream connected to the file */ int fclose(FILE *stream) /* disconnected between the stream and the file, any buffered output is written and any buffered input will discarded */ ASCII IO123456789int fputs(const char *s, FILE *stream) ;/* write a char array into stream. this call doesn't add a newline or terminal null character */char *fgets(char *s, int n, FILE *stream);/* read n number of char array from stream, default add a newline character */ssize_t getline(char **lineptr, size_t *n, FILE *stream);/* read a whole line from stream */ block IOusually block stands for either block data or text in fixed-size, instead of characters or lines 12345size_t fread(void *data, size_t size, size_t n, FILE *stream);/* read #n block, each block has size from stream, and store in data */size_t fwrite(const void *data, size_t size, size_t n, FILE *stream);/* write #n block, each block has size from buffer data to stream */ formatted IO1234567int printf(const char *template, …); //write to std outputint fprintf(FILE *stream, const char *template, ...); write to streamint sprintf(char *s, const char *template, ...); //write to a stringint scanf(const char *template, …) //formatted read from stdinint fscanf(FILE *stream, const char *template, …) // read from stream int sscanf(const char *s, const char *template, …) // read from a string EOF1234int feof(FILE* stream) ; /* return nonzero iff end of file indicator is set for stream */int ferror(FILE* stream) ; /* return nonzero iff error indicator is set for stream */ stream bufferstream and file is not communicated character-by-character, there is a buffer for I/O. 12int fflush(FILE *stream) /* take any buffered output on stream to be delivered to the file */ file descriptor123456789101112int open(const char *filename, int flags);int open64(const char *filename, int flags) ;// allow large file mode size_t read(int fd, void *buffer, size_t size) // read from fd size bytes into buffer size_t pread(int fd, void *buffer, size_t size, off_t offset) // start reading from position “offset” size_t write(int fd, const void *buffer, size_t size) off_t lseek(int fd, off_t offset, int whence) // change the file position of fd FILE *fdopen(int fd, const char *opentype) // return a new stream for this fd synchronizing I/O1234void sync(void) ;// to ensure all operations finished before they return int fsync(int fd) ;// to ensure all data associated with the fd is written to the device not yetasync I/O, event I/O, interrupt driven I/O, GPIO …]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux at work]]></title>
    <url>%2F2018%2F07%2F26%2FLinux-at-work%2F</url>
    <content type="text"><![CDATA[bash environment/etc/profile -&gt; hold shell environment &amp; startup settings ~/.bashrc -&gt; system wide definitions for shell funcs &amp; alias ~/.bash_profile -&gt; user environment individually ususally during coapplication configuration on Mac or Linux, mostly use ~/.bashrc to add project related environment variables. regular expressions the$ :matches the line ending with “the” ^the :matches the line starting with “the” [^g]abc : search “abc” but not starting with “g” [^abc…z][0-9] : search numbers but not with alphabet in front ^[a-z] : search the line starting with low alphabet ^[^a-z]: search the line starting without low alphabet ^$ : match white space [xyz]: general match anyone from “xyz” [!xyz]: general match in opposite, neither from “xyz” shell expressions command &amp; : to run command in bg $! : current PID $# : number of arguments $1 : the first paramter $* : wildcard for all variables Linux commands ldd: check runtime lib unix2dos / dos2unix: change file format between Windows and Linux ps : print running processes in current terminal ipcs : check share memory portion in current system ipcrm -M ipc_key : remove the shared memory portion id by ipc_key top: print virtual,resident,shared memory percentage basename: e.g. basename /path/to/file -&gt; file wc -l .file: print total lines of the file df: check the usage of disk find . -type f -print0 | xargs -0 grep -l “xx” find D:\ | grep xml less .file : read the last few lines of file ln item link : soft link ln -s item link : hard link type command : check the type of command cat f1 f2 &gt; merged sort uniq comm f1 f2 : the common part of f1 and f2 diff f1 f2 : the difference of f1 and f2 2 &gt;&amp; 1: redirect std output(fd=2) to std error(fd=1) nm : check libs used in current executable(T defined, U undefined) gdbMPI gdb: (each MPI thread will have an independent terminal window) mpirun -np #cpus xterm -e gdb ./exe set breakpoint in different src: b sth.cxx:20 print an array: p (int[length]* a) add input file: set args -j input_file load src after triggering GDB: gdb file exe set args -j input_file books about Linuxbash guide for beginnerstao of regular expressionLinux programmer’s manualLinux system administrators guideC expert programmingwhat every programmer should know about CPU caches resources in multi-core optimizationunderstand CPU utilization &amp; optimizationIntel: optimization applications for NUMAIntel guide for developing multithreaded applicationsMPI parallel programming in Pythonconsiderations in software design for multi-core, multiprocessor architectureshow to optimize GEMMoptimize for Intel AVX using MKL with DGEMMGEMM: from pure C to SSE optimized micro kernela practical guide to SSE SIMDD with C++multi-core designUnix and pthread programming resources in applicationsintroduction to post processing finite element results with AVSCAE Linux: FEA inter-operabilityopen sourcing a Python project the right wayPPSSpyNastranhdfviewervalgrind postscriptstarting from 2016, I had went through each hot topic nowadays, even did some study in DL, AV, CV etc. every time the passion burst out and I promised to e.g. study a framework, or contribute an open project. in reality, the passion dies away soon. It’s like a new and very attracting concept bump out in the market, but no business model can handle it, then it dies out. downside of this learning pattern is that the fundmental is ignored. e.g. I can’t success in code interview, few experience in basic algorithms. kind of person always vision the big, but don’t realize how to reach there. it’s kind of wasting finally, just want to be focus at this moment.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pure C structure]]></title>
    <url>%2F2018%2F07%2F26%2FPure-C-structure%2F</url>
    <content type="text"><![CDATA[definition12345typedef struct gid_ &#123; double x; double y; char* name ; &#125; gid ; typedef defines “gid” as an alias name to “struct gid_ “. typedef also alias function handle/pointer, which is often used in asynchronous/event callback programming. other data encapsulation are: enum : map a list of const names to integral constants union: store many data type in one memory address initialization123gid g1=&#123;2.0, 3.0, "g1"&#125;;gid g2=&#123;.x=2.0, .y=3.0, .name="g2"&#125;;gid g3=(gid)&#123;2.0, 3.0, "g3"&#125;; in C++, structure initialization can also be done in constructor. memory alignmentfor better memory access in CPU architecture, memory alignment in structure is considered. namely: chars can start on any byte address 2-bytes shorts must start on an even address 4-bytes ints/floats must start on an address divisible by 4 8-bytes doubles/longs must start on an address divisible by 8 the size of the whole structure, is aligned to intergeral times of the max size of its member variable. e.g. sizeof(gid) = 24, not 8+8+4. to put the member variables in ascending/descending order is good practice. structure pointer arithmetic“gid++” will step forward the sizeof(gid); structure also supports self-reference: 123456typedef struct gid_ &#123; char *name ; double x; double y; gid_ *next_gid ; &#125; gid ; another common utils is structure array: 12gid gid_list[MAX_SIZE]; gid **gid_list_p ; structure as function parametersin general, structure can be passing to function by value or by pointer, but not by reference in pure C. also structure as return value from function can be value or a pointer structure in C++in C++, structure supports member functions, is same as a public class. and the initialization can be done either in constructor function or direct initialization during definition. see the difference of struct between C and C++ stdlib.h123456789101112131415161718 /* convert string s1 to an int*/ int atoi(const char* s1); /* memory op */ void* malloc(size_t size); void free(void *ptr); /* system level op */ char* getenv(const char *name); int system(const char *command); /* algorithms */ void* bsearch(const void* key, const void* base, size_t nitems, size_t size, int(*compar)(const void*, const void*)) void qsort(void *base, size_t nitems, size_t size, int(*compar)(const void*, const void*))]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pure C string]]></title>
    <url>%2F2018%2F07%2F24%2Fpure-C-string%2F</url>
    <content type="text"><![CDATA[string initializationin pure C, string is a char array terminating with NULL(‘\0’). To initialize an array of char(string) is with a string literal(a double-quotaed string). in general, the string literal is used as the initializer for an array of char; anywhere else, it is a static array of chars, which shouldn’t be modified by a pointer. 123456789101112131415161718192021222324252627282930313233/* initialize a string in C * the size of s1 is taken from the size of the initializer */ char s1[] = "hello world" ; // or char s1[12] = "hello world"; /* common errors */ char s2[]; s2 = "hello world"// error: storage size of 's2' isn't known char s2[12]; s2 = "hello world"// error: invalid array assignment /* there is no "=" operator defined for char array in C using strcpy()*/``` ## char pointer arithmetic ```c char s1[12]; *s1++ ; /* error: lvalue requied as increment operand * s3 is an array, can't modify the address of an array. the difference between pointer and array */ char* s2 = s1; *s2++;/* s2 is a pointer to s1, ++ is ok */ string.h1234567891011121314151617181920212223242526/* concatenate two strings */strcat(char* s1, const char* s2) ;strncat(char* s1, const char* s2, size_t n); /* locate the first/last occurance of char c in string s */strchr(const char* s1, int c);memchr(const void* s1, int c, size_t n);strrchr(const char* s1, int c); /* compare s1 and s2 alphabetically */strcmp(const char* s1, const char* s2); strncmp(const char* s1, const char* s2, size_t n);memcmp(const void* s1, const void* s2, size_t n);/* copy s2 to s1 */strcpy(char *s1, const char *s2); memcpy(void* s1, void* s2, size_t n);/* number of bytes, not including terminating NULL; sizeof() will inlcude the terminating NULL */strlen(const char* s1); /* find the first occurance of substring s2 in s1 */strstr(const char *s1, const char *s2);/* split string s1 into a sequence of tokens by s2 */strtok(char* s1, const char* s2); \ is replaced by in C++.and be aware of downs of C string.]]></content>
      <tags>
        <tag>pure C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[which function is called]]></title>
    <url>%2F2018%2F07%2F18%2Fwhich-function-is-called%2F</url>
    <content type="text"><![CDATA[which function is calledwhen a derived object calls the base class member function, inside which calls another virtual member function, which is implemented inside the derived class, so which virtual member function is actually called ? 123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;class Weld &#123; public: Weld()&#123;&#125;; virtual ~Weld()&#123;&#125;; virtual bool getDataIndex()&#123; std::cout &lt;&lt; "Weld::getDataIndex" &lt;&lt; std::endl; return true ; &#125; bool getInternalDataList()&#123; return getDataIndex(); &#125;&#125;;class SpotWeld: public Weld&#123; public: SpotWeld()&#123;&#125;; virtual ~SpotWeld()&#123;&#125;; virtual bool getDataIndex()&#123; std::cout &lt;&lt; "SpotWeld::getDataIndex" &lt;&lt; std::endl; return true; &#125;&#125;;class ACM2 : public SpotWeld&#123; public: ACM2()&#123;&#125;; ~ACM2()&#123;&#125;; virtual bool getDataIndex()&#123; std::cout &lt;&lt; "ACM2::getDataIndex" &lt;&lt; std::endl; return true; &#125; bool getPoints()&#123; return getInternalDataList(); &#125;&#125;;int main()&#123; ACM2 acm2 ; acm2.getPoints(); return 0;&#125; output is: ACM2::getDataIndex so the derived object always calls the member function that most closest to its own class domain first, even if this member function is called from a base class member function.]]></content>
      <tags>
        <tag>c++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[multi-core at work]]></title>
    <url>%2F2018%2F07%2F13%2Fmulti-core-at-work%2F</url>
    <content type="text"><![CDATA[NUMAuniform memory arch, all CPUs in the same sokcet shall the memory, and the memory IO is bottleneck; non uniform memory acess(NUMA), each CPU has itw own memory, inter-CPU memory access is remote. numctl cpu_node_bind MPI binding APIs memory allocation strategy in NUMA interleave: place the memory on alternating node, the first memory portion in node0, the next portion in node1 membind: forcely to allocate memory in special node CPU affinitythe benifit of CPU affinity is to reduce context switch since one special process is binded to one speical CPU, so the data required in this process (no other process data will be switched in), can always in the CPU cache. espcially for NUMA arch to access data locally. and this is specially true when the application generate a large cache footprint, e.g. in scientific computing. for general applications, CPU afinity may reduce performance, since in this way the CPU scheduler can’t work properly. CPU info/proc/cpuinfo physical id: socket indexsiblings: number of cores in each socketcore id: current core index e.g. Ford HPC CPU architecture: 2 or 4 CPU sockets group into one computing node each socket has 10 or 12 CPU cores each socket has a on-board shared memory atomic operationCPU physical mechanism: physically there is a bus #hlock pin. if #lock is added before the assembly instruction, the corresponding machine code will be pulled down during the execution of the #hlock pin till the end, basically the bus is locked only for current instruction cache coherence: the cache unit tranfered between CPU and main memory is cache line. in one socket, as slibings share L3 cache, there is an scenario, when CPU1 modified one variable, but not yet writen to main memory, and CPU2 read from main memory and did modified again, then the variable in CPU1 and CPU2 is not coherence. volatile in C, forcely to read the variable value from main memory every time, to avoid use dirty memory in cache another scenario, to achieve and cache coherence, and the same variable is read and write repeatly by multiple processes, the performance is worse, “false sharing” lock: signal, also called &quot;sleeping lock&quot;: used when the lock need to keep for a longer time spin lock: at most hold by one thread, to block other threads into critial area, used to keep for a short time. write/read lock: system performanceresident memory(res), the portion of virtual memory space that is actually in RAM; swapped memory, when the physical memory is full and the system needs more memory, inactive pages in memory moved to the shared space, and swapped usable memory in virtual memory = res memory + swapped memory mmap, to access the remote (data block) like access local RAM. voluntary context switches(vcs): when a thread makes a system call that blocks. vcs measures the frequency of calling blocked system I/O involuntary context switches(ivcs): when a thread has being runing too long without making a system call that blocks, and there are other processes waiting for CPU, then OS will switch for other CPUs. ivcs measures the CPU competition, an unfinished processed is switched off in general, as more threads, the context switch cost increase, due to the total amount of switch increase and as well each switch is more expensive, since CPU cache is limited, and each process will hold fewer data in cache. cpu_time (clock_t): the total amount of time that a process has actually used user CPU time: the amount of time spend in user space running system CPU time: the amount of time spent during kernel space running wall-clock time: the whole time from the process start to end Linux IPCinter-process communication(IPC) share memory is used in our application to cowork with MPI. while IPC helps to balance memory distributed in multi computing nodes, and MPI threads are the working horse to eat shared data. there are other IPC libs, e.g. Boost.interprocess. ftok() -&gt; to generate a IPC key, based on a special file path shmget() -&gt; generate a shared memory portion and return a shm_id shmat() -&gt; attach to the shm_id and return a pointer to that shared memory shmctl() shmdt() in design, all threads call shmget() to get a pointer to the share memory section, but actually only master thread do create the portion, others read it. since all thread can access the share memory section, it’s important to keep the first returned pointer from master thread clean/unpolluated. MPIthere are a few basic MPI APIs. in our project, to benefit both CPU and memory performance, we actually need: 1) subgroup the MPI comm, 2) bind MPI threads to sockets. MPI_COMM_GROUP() MPI_Group_incl() MPI_COMM_create() apis and numctl during run-time: mpirun -bycore -bind-to-socket -&gt; bind process to each core on the socket mpirun -bysocket -bind-to-socket mpirun numctl -membind=0 -np 32 ./run]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vehicle network]]></title>
    <url>%2F2018%2F07%2F12%2Fvehicle-network%2F</url>
    <content type="text"><![CDATA[vehicle networ is what connects the different parts together as a vehile. the lower-level basicA few basic concepts: TCP/UDP socket, CAN Bus, Ethernet, MCU register, Ip address, MAC address, Ethernet driver, network configure, how to code a ECU/MCU etc. there are EE students working on this close to physical level implementation, on how to talk with register, MCU pins and controls, and some implementing the data traffic protocol in network. While both are isolated from top applications, since no matter where the data come from, either AV application or connected vehicle or media data, doesn’t make a difference. architecture typical vehicle network architecture beyond the basic, network architecture brings a good vision to understand what makes a vehicle electronicly as a whole. and which is serving all apps with v2x, in-vehicle entertainment, AV. I was thought ECU handling events the same as web server. while they are very different. each ECU is doing only one special task. e.g. ABS ECU only dealing with ABS events, there are no many ABS events happening simultaneously to seize the ECU computing resource; however, a web server have to deal with multiplex request simultaneously, either using thread pool or asynchronous event callbacks. each ECU actually has an easy life, but the bus seems easily choked since around 100+ ECU nodes in the vehicle network. however again, typical vehicle network architecture is very matured products, without data-heavy applications arising, current CAN bus is great. smart phone in wheels?one day in future, every vehicle running on road is requesting some data from cloud seamlessly, the scenario is like billions of browsers send requests to Google server seamlessly, then the cloud may face same issues in today’s web server. Service oriented architecture(SOA) is also rising in vehicle network architeture design, but what kind of services is better locally in vehicle, and which services in cloud ? as hardwares evolution, even the computing-heavy tasks, e.g. vision based detection, path planning in AV, suppose not be a burden for local ECUs. so these services make sense locally served. except that, I only image future vehicle as a smart phone on wheels. so remote cloud server do connect to, e.g. talk to another vehicle, play online game during driving, check weather, find out a parking lot, resturant or similar, or the car company want to steal user data privately? SOA is a good move to decouple ECU modules and make the network bus light, and it’s fun to try some vehicle network architecture open project or play with ROS simulator if hardware required. but in a business view, I don’t know a good story to attract investors, namely vehicle network sounds not that blinking amazing.]]></content>
      <tags>
        <tag>vehicle network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gnu-make]]></title>
    <url>%2F2018%2F06%2F29%2Fgnu-make%2F</url>
    <content type="text"><![CDATA[websocket projects recently reviewed: uWebSocket, which is used in Udacity self-driving car term2 projects. the other is libwebsocket, which is used in automotive message broker(amb). gcc compiler optionsgcc and make: a tutorial on how to compile, link and build c/c++ projects -wall : print all warning messages -c : compile into object, by default the object has same name as the source file -o : specify the output executable filename headers(.h), static libs(.lib, .a) &amp; shared libs(.dll, .so)gcc by default, links to the shared libraries if available. the compiler search “include-paths” for headers, which is specified via -L\ option or CPATH; the linker search “library-paths” to link the program into an executable object, which is specified via -L\ or LIBRARY_PATH, in addition, need to specify the library name via -l the system default “include-paths” can be found by “cpp -v” gcc environment variablesPATH is used to search executable and run-time shared libs. (woo, this suppose to replace LD-LIBRARY-PATH)CPATH is used to search “include-paths”, it’s searched after paths specified in -I&lt;dir> options. C_INCLUDE_PATH &amp; CPLUS_INCLUDE_PATH can be used to specify C &amp; C++ headersLIBRARY_PATH is used to search linking-time “library-paths”, it’s searched after paths specified in -L\ options. the standard directories is /usr/lib Linux utils1) readelf: read ELF 2) ldconfig : by default, read /etc/ls.so.conf, sets up the appropirate symbolic links in the dynamic link dir, and then write a cache to /etc/ld.so.cache, which then is used by other programs 3) ldd: to see recursive shared library dependencies 4) file: determine file type 5) nm: list symbol table of an object file, commonly-used to check if a particular func or variable is defined in an object file. “T” indicates it is defined; “U” means undefined, which should be resolved by the linker. make &amp; cmake[gnu make] (https://www.gnu.org/software/make/manual/html_node/index.html#SEC_Contents) there are many best practical, e.g. effective cmake build libuvit’s built based on GNU autotools sh autogen.sh &quot;libtoolize: AC_CONFIG_MACRO_DIR([m4]) conflicts with ACLOCAL_AMFLAGS=-I m4&quot; fixing-solution, then make all &amp; make install, so here is libuv.so, add the directory to \$LIBRARY_PATH in ~/.bashrc build uWebSocketsit’s built based on gnu make. the tests command has dependents on libuv. since already added libuv directory to \$LIBRARY_PATH, run through. if else, errors output: cannot find -luv collect2: error: ld returned 1 exit status Makefile:xx recipe for targe &apos;tests&apos; failed make: *** [tests] Error 1 try to run ./testsBin, get another error: error while loading shared libraries: libuWS.so: cannot open shared object file: No such file or directory that’s run-time error, since libuWS.so is not included in \$PATH or speically for building/testing purpose, define $LD_LIBRARY_PATH. build libwebsocketsit’s built based on cmake. there is some dependent, but should go through well. beyond the notewhen 2-months ago, looking at amb project, which has websocket plugin module, then find uWebSocket lib, during reading this tiny lib, where libuv APIs are highly-used, and soon found out libuv is actually the event-loop in nodejs. Woo, somehow they are related. build tools are highly used in each project, but prior experience is more done by luck.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[career thoughts]]></title>
    <url>%2F2018%2F06%2F25%2Fcareer-thoughts%2F</url>
    <content type="text"><![CDATA[product data managmentan interesting meeting with material research group, these guys have some IT needs, but does’nt reach there. e.g. there are plenty of material fatigue data, including metadata, tables, S-N plots, so how to organize/manage them? one solution is from MSC Material Center[http://www.mscsoftware.com/news/msc-software-reinvents-materials-lifecycle-management-materialcenter] what triggered me is “data management” in general. In manufacturing industry, like automotive, many old style data used and storied in different departments, e.g. the material property data, load time history data for CAE department, the vehicle diagnostic logging data in vehcile control department, the vehicle dynamics records in vehicle test department. but neither are well-structured nor easy to track. two fields so far: data dashboard, requires data visulization and data mining; product lifecycle management, it’s a product driven, and may also have data dashboard needs. currently as I see, most data analysis is in bussiness driven view, not in product itself. how to accelerate product iteration through better using history products data suppose to be a big thing. on another side, industry data management is a little different than bussiness/market data. e.g. every year Ford releases a new F-150 truck, does it start out of new? no, the 2018 mois stly iterate by the 2017. so there is product data management, just managed through all component departments. maybe the questions should ask is: 1 do we get the most value from these whole product level data? 2 how to make special data manageble at subsystem level? it needs more experience in the whole process, but bring some thoughts in next career: PLM software and data management in special domain, e.g. material datacenter product. cloud CAEsince dashboard is so popluar to migrate the traditional software GUI to web/mobile app; and CAE solver can deployed in cloud, which is a better stronger reason to do user-side dashboard: with job submission, job status, and result plot/visulization sections. but why is it necessary to migrate CAE solvers in cloud? why the manufacturing product companines would like to share their prodcuts data with cloud providers? turn one step back, the most obvious reason is whenever internet is needed, e.g. communication among different end-users, cloud is good chonice; and for startup companies, who can’t afford to run jobs locally, have to migrate their calculation in cloud. I am kind of curious who is using AWS? Netflix, BMW, Autodesk! I was so suprised at first, how BMW and Autodesk would like to use AWS? anyway Netflix is data-flow based company, the core business is client-server communication, which make sense to use AWS. while BMW is using AWS for new business: connected service, all a sudden it makes sense. the car product business won’t be shared with AWS, but cloud is required as infrastructure for v2x connected service. that’s amazing. AutoDesk say a different story in cloud, since they sell CAD softwares, few people want to buy and own an expensive software but choose to pay for the service, by all meaning, this is not a new business, but AWS offer a mature channel. even though, cloud providers say they are cost-reducing, high-scalability, but I don’t think manufacturing companies will buy it due to security, instead they maintain their own clusters and share limited business in cloud. so standing in manufacturing industry, it’s better to figure out new services, which require communications through cloud, than migrate CAE solvers to cloud. that’s my second point.]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[muduo 3]]></title>
    <url>%2F2018%2F06%2F20%2Fmuduo3%2F</url>
    <content type="text"><![CDATA[one concern yesterday: does each worker thread call loop() and run the whole active channels callback ? suppose no. let’s track the process : 123456tcpServer.start() -&gt; threadPool.start() -&gt; new EventLoopThread(eventLoopThread::threadFunc, threadName) eventLoopThread-&gt;startLoop() -&gt; thread.start() -&gt; detail::startThread() -&gt; runInThread()::func_() the real func_ during creating new eventLoopThread, is threadFunc(), in which call loop.loop(). first, this loop object is created inside this new eventLoopThread object, no issue that the loop.threadId_ is current threadID. when multiple worker threads exist, what happens ? threads A B C conns T1 T2 T3 suppose T1 is assigend to worker thread A, etc. when calling eventLoopThread A.loop(), epoll_wait() is first called and return number of active events, epoll_wait() is thread-safe, no worry. then activeChannels:HandleEvents() is called. the real executor of this handleEvents is in the TcpConnection objects, namely: T1 or T2 or T3. each TcpConnection object has its own loop-, and only the worker thread with the same loop- can execute the events. so even though threadA get the list of all active events, but only events in T1 conenction will be executed by threadA. so we can see, in per (worker) thread per epoll, each (worker) epoll looks like only return the active channels/events in current worker thread’s eventLoop. There is no conflict among multiple worker threads, since each worker threas has its own eventLoop. how about eventLoop in server/clientthe eventLoopThread is kind of triggered inside Muduo, where is Tcp server/client eventLoop triggered ? from outsiders.]]></content>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[moduo 2]]></title>
    <url>%2F2018%2F06%2F19%2Fmuduo2%2F</url>
    <content type="text"><![CDATA[The several classes defined in Moduo: TcpServer, Acceptor, TcpConnection, EventLoop, epoller, channel, eventLoopThread, eventLoopThreadPool. 1) TcpServer constructioneach TcpServer suppose have multi- tcp connections, the acceptor works as the main I/O thread, which listen the server-side I/O socket, and handle all client input connections at first, (later will assign the connection task to each worker thread from pool). so the input argument “loop” during TcpServer construction is the main I/O eventLoop. 12345678910111213141516171819202122232425TcpServer::TcpServer(EventLoop* loop, const InetAddress&amp; listenAddr, const string&amp; nameArg, Option option) : loop_(CHECK_NOTNULL(loop)), ipPort_(listenAddr.toIpPort()), name_(nameArg), acceptor_(new Acceptor(loop, listenAddr, option == kReusePort)), threadPool_(new EventLoopThreadPool(loop, name_)), connectionCallback_(defaultConnectionCallback), messageCallback_(defaultMessageCallback), nextConnId_(1)&#123; acceptor_-&gt;setNewConnectionCallback( boost::bind(&amp;TcpServer::newConnection, this, _1, _2));&#125;``` one advantage of bind/callback is to import functors to different class domain. and server has always one I/O socket, but client-socket-fd suppose be a lot. ## 2) TcpServer newConnectionEach new tcp connection, will assign a worker thread to execute the speical callback functor for this new connection, How to schedule thread in threadpool is implemented by round-robin, which are implemented as:```cioLoop-&gt;runInLoop(boost::bind(&amp;TcpConnection::connectEstablished, conn)); EventLoopThreadPool::getNextLoop() does each worker thread run EventLoop.loop(), which will call epoll_wait(), and execute all active channels? suppose no.3) TcpConnection constructioneach new client connection will reponse to a new socket fd, and a new channel. (channel is actually the container of socket fd); and the functors on this connection is also imported to channel callbacks. basically from outside, we only see channel objects, TcpConnection object is the inner class. 123456789101112131415161718192021222324252627TcpConnection::TcpConnection(EventLoop* loop, const string&amp; nameArg, int sockfd, const InetAddress&amp; localAddr, const InetAddress&amp; peerAddr) : loop_(CHECK_NOTNULL(loop)), name_(nameArg), state_(kConnecting), reading_(true), socket_(new Socket(sockfd)), channel_(new Channel(loop, sockfd)), localAddr_(localAddr), peerAddr_(peerAddr), highWaterMark_(64*1024*1024)&#123; channel_-&gt;setReadCallback( boost::bind(&amp;TcpConnection::handleRead, this, _1)); channel_-&gt;setWriteCallback( boost::bind(&amp;TcpConnection::handleWrite, this)); channel_-&gt;setCloseCallback( boost::bind(&amp;TcpConnection::handleClose, this)); channel_-&gt;setErrorCallback( boost::bind(&amp;TcpConnection::handleError, this)); LOG_DEBUG &lt;&lt; "TcpConnection::ctor[" &lt;&lt; name_ &lt;&lt; "] at " &lt;&lt; this &lt;&lt; " fd=" &lt;&lt; sockfd; socket_-&gt;setKeepAlive(true);&#125; so where are channel (read/write/error/close) handleEvent callbacks triggered? it is during the eventloop.loop, after epoller return the active events, based on the status of each revent, special handleEvent is called. 4) eventLoop constructionduring constrution of eventLoop, a new poller is created based on this eventLoop itself, also a new wakeupfd and a new wakeupChannel. the purpose of wakeup fd/channel is to immediately wake up the work thread, rather than waiting till PollTime. and the wakeupfd bind handleRead, in which read one byte to make this wakeupfd I/O readable, which then is ready for I/O. 123456789101112131415161718192021222324252627EventLoop::EventLoop() : looping_(false), quit_(false), eventHandling_(false), callingPendingFunctors_(false), iteration_(0), threadId_(CurrentThread::tid()), poller_(Poller::newDefaultPoller(this)), timerQueue_(new TimerQueue(this)), wakeupFd_(createEventfd()), wakeupChannel_(new Channel(this, wakeupFd_)), currentActiveChannel_(NULL)&#123; LOG_DEBUG &lt;&lt; "EventLoop created " &lt;&lt; this &lt;&lt; " in thread " &lt;&lt; threadId_; if (t_loopInThisThread) &#123; LOG_FATAL &lt;&lt; "Another EventLoop " &lt;&lt; t_loopInThisThread &lt;&lt; " exists in this thread " &lt;&lt; threadId_; &#125; else &#123; t_loopInThisThread = this; &#125; wakeupChannel_-&gt;setReadCallback( boost::bind(&amp;EventLoop::handleRead, this)); // we are always reading the wakeupfd wakeupChannel_-&gt;enableReading();&#125; “activeChannels” suppose to be a class variable, which is shared by eventLoop objects, but it’s ok to keep a copy for each eventLoop object to avoid multi-thread competing. and suppose epoll_wait() is thread-safe, so later during construction of eventLoopThreadPool, multi eventLoopThreads won’t conflict with “active channels” 5) epoller constructionepoller object is created during eventloop construction. since the three interface of epoll instance are thread-safe, they look like global funcs. epoll_create(), return an epfd referring to the new epoll instance, this epfd is used by all subsequent calsl to the epoll interface. epoll_wait(), return all ready events on the epoll instance referred by epfd. epoll_ctl(), traverse the red-black tree strucutre to return the existing fd, or add new fd to the tree. 6) channel constructionchannel is the container of one fd, and is related to one eventLoop. channel is not responsible to create/delete fd, the real owner of each fd is TcpConnection or acceptor. Channel object works like a pipe to send fd from inner object TcpConnection to the eventLoop. the advantage here is eventLoop is independent from connections. 7) channel:update()1234channel::update() --&gt; loop-&gt;updateChannel() --&gt; poller-&gt;updateChannel() --&gt; //poller maintain a channel list, call epoll_ctl to add/return/delete the requiring channel 8) one epoll + threadpool vs per thread per epollthe first method, one global epoll listens all new connections, and send each connection callback to a new thread to execute. method 2, to listen the server I/O socket need to bind a unique epoll, in Moduo which is the acceptor epoll. then all client connection socket will be dealt with their own worker epoll.]]></content>
      <tags>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[moduo 1]]></title>
    <url>%2F2018%2F06%2F14%2Fmuduo1%2F</url>
    <content type="text"><![CDATA[Moduo: A C++ non-blocking network library for multi-threaded server in Linux. C++ 11 featuresa. functional, bindin C++11, function declartion can be: 123456789 return-type func(args)//or auto func(args) -&gt; return_type// the good part of &quot;-&gt;&quot; is to use &quot;decltype&quot; to decide the return type from future. std::function&lt;return_type(arg1_type, arg2_type..)&gt; ; [](type1, type2..)&#123;&#125; ; //lambda func, anonymous func std::forward std::bind() is used to assign existed variables to func parameters during compile-time, and unassigned parameters stand as placeholders, which then replace by real parameters during running-time, and return a new func. bind() can be used to bind static func, global func, class member func. 12345678910 std::bind(global_func, 1.0, _2) ; std::bind(&amp;class:memberfunc, classPointer[this], _1); ``` ### b. multi-threads synchronized primitives Q: what is condition variable ? A: used to block one or more threads, till been notified by another thread or overtime been wakeup. But if all threads are waiting, that&apos;s a problem, so at least for one thread, the condition variable should be true. threadA.wait(condition_variable); while(;;) { threadB.do(); } threadB.notify(); threadA.do(); 1234567891011121314151617181920212223242526 Q: what is mutex? A: it works like a lock, to block any other thread to access special part of memory, at any time, only one thread can own the mutex. in reality, to define mutexLock class will manage lock/unlock automatically due to the constructor/destructor of the object. ### c. rvalue reference, universal reference, std::forward Q: why need right-value reference ? A: to use rvalue like lvalue, save object/variable copying, the detail is about move constructor. universal reference, means either rvalue reference or lvalue reference, is to declare a variable /parameter with type T&amp;&amp; for some deduced type T### d. functional template, variadic arguments basically, it&apos;s to support any type, any number of parameters in function template. ``` template&lt;typename… Args&gt; class tuple&#123;&#125; //a template class template&lt;typename T, typename… Args&gt; void func()&#123;&#125; /* Args :: a template type parameter pack, a list of parameters T :: a normal template type parameter */ func(T, args...) /* (...) at right of func parameters is meta operator used to unpack &quot;args&quot; into separate arguments */ a simple thread / thread pool libtake a look at: thread-pool basically, a task queue to store all todo tasks; a thread pool, to store the worker threads, each of which takes one task from the task queue continuously till the queue empty. racing condition happens when two threads try to take the same task simultaneously, so mutex. and all operators requrieing thread-safe should use mutex, e.g. enqueue/dequeue taskthen callback functors, how each worker thread deal with the task at hand? to design function template with variadic arguments. a simple Tcp network libtake a look at: simpleNetwork in server: socket() -&gt; bind() -&gt; listen() -&gt; accept() –&gt; send()/write() in client: socket() -&gt; connect() -&gt; recv()/send() a basic idea is that each connection, the server will create a new thread to handle it. But it consume server quickly. I/O nonblocking/event-driven &amp; multiplex1234567891011#include &lt;poll.h&gt; struct pollfd &#123;int fd; //file descriptor, non-negativeshort events; //events to watch, set by usershort revents; //returned events, return from system kernel &#125;;POLLIN | POLLPRI ; //event readPOLLOUT | POLLWRBAND ; //event writePOLLER ; //event errorPOLLHUP ; //event hang up the basic idea of multplex(Linux APIs: poll(), epoll()) is to use one single thread to listen many connections/socket/fd, once any socket is ready for I/O, the thread will execute the write/read callback. epoll() on success, return the number of revents or 0; on error return -1 123456789struct epoll_event &#123; __u32 events ; union&#123; void* ptr, //if need to store a pointer int fd, // if need to store socket fd __u32 u32, // to store general 32 bit number __u64 u64 // to store general 64 bit number &#125; data;&#125;;]]></content>
      <tags>
        <tag>c++11</tag>
        <tag>muduo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[coding is the system engineering]]></title>
    <url>%2F2018%2F06%2F05%2Fcoding-is-the-system-engineering%2F</url>
    <content type="text"><![CDATA[during this week studying: automotive message broker. It’s a framework to support in-vehicle network communication, based on which many vehicle applications can build up. After jumped into the source code, soonly I found the dependent third-party libs, e.t. Qt, Glib, libwebsockets. None of these basis libs looks familiar, that’s really headache. So had to jump to learn a little about these libs first. Qt is heavy, give up on reading source code, basically to know what’s used for; Glib has a core on eventloop, after review the concept: nonblocking event I/O; and few lighter projects are found, e.g. event.js in RocketEngine. so I was happy to read js source code, but after reading nothing really keep in my head due to don’t know where to use them, neither don’t understand why these implement is necessary. maybe a bigger project with more details, so picked moduo, written by a Chinese. there is a book on this project, which started with multi-thread programming issues, no help. same problem, I am not familar with the application scenario, so can’t really catch the essential. back to the question: how to effciently read source code?1) I suppose, first to understand the application scenario2) compile and run in debug to track the data flow for projects, which you can’t see the flow by once3) if it’s a framework/foundmental libs, write demo The company IT system is not developer-friendly, git, cmake, npm, python lib are missing. that’s maybe the reason I am becoming lazy, if tools at-hand, may give a try; if not, nothing really do. The company has itself gmake system, but the bottom code never been touched. Then I compiled the demo libwebsocket, many failures bump out, during school time, I used a lot cmake, g++ with local headers, link to LD/_LIBRARY/_PATH, all out of practice for couple years. Anyway, at this moment, I realize that coding is a system enginnering. first to be really familar with OS, then the basic libs, then think about to write applications. For me, the first occupy with software is from (industry) application layer, lack of foundmental. now when to do sth, I feel hands are bounded, that push me to the root. Rome is not built in one day, OMG.]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[open source project checked]]></title>
    <url>%2F2018%2F05%2F31%2Fopen-source-project-checked%2F</url>
    <content type="text"><![CDATA[pen source projects I scatched To review how many open source projects I tried to study has been in my mind for a long time. I am always interested in new areas, new trends, and want to understand a little more, few contribution by now. One college friend, who worked at Intel China, first brought me to GTC 2008 at Beijing, where my eyes is opened first time, to know there is so many amazing works around the world. 1) HPC/FEA/CFDafter 2008, I was driven by computing mechanics more HPCG: a benchmark work to test FLOPs, which I used as a class project at Buffalo PETSC: a large sparse matrix solver, developed from Texas Austin, also met at Buffalo. the math is attracted me more and it is complex and a good learning material for C++ LibMesh: based on PETSC to do FEM. ran some demo and interested in math more GPU-SPH: GPU implementd of SPH(CFD algorithm), during 2011, GPU is popular in applied mechanics. PetIBM: immersed boundary method (CFD algorithm), used as a class project OpenFEM, OpenFOAM etc. during that period, I collected many small/big open source CFD/FEA projects, but few study. 2) Game Engineat 2011, Virtual Reality is attracting CHAI3D: my friend show me a demo, but I didn’t go through LiquidFun: google product Box2D: for fun, like LiquidFun, where cmake, configure skills played That time I also collected many other game engines from web, e.g. Unreal, skynet.. it’s so cool to be a game developer, but no time to deep in 3) Robotat 2014, robot is hot ROS: that’s my way to study the platform first, with a few study and no more SLAM: the cool concept when to uderstand the core algorithm OpenCV: used everywhere, read some docs, but not used independtely Arduino: platform, when I joined the Detroit Hacking Night(DHN) meetup RasiBerry: similar experience during DHN, later I tried to implement deep learning detection algorithm on a race car, not finished till now RTOS: go through like 2-month ago, when I feel I need more understand at embedded system. simple to understand, but not sure how can I master in practice 4) Deep Learningafter 2016, DL is so popular, many frameworks, online courses, papers bursting, no way to keep calm. TensorFlow: I thought it’s easy at first, but really didn’t go to the code, but implemented some examples Caffe: the DL framework jumped in, first knew about Google protocol buffer, very confused at that time ChatAI: I tried to add some fun in WeChat public platform 5) VehicleBuffalo Car simulator: at Buffalo lab, there was a physical car simulator, and code in OSG, cool project to learn C++ SimCar: later I had chance to know many open source/ commercial car simulators AGL: at 2017, started to view AGL updates, try to keep in mind the new trends in vehicle software fields GEVIVI: same time with AGL, interested in IVI as a sub-field openXC, SmartDeviceLink: OEM level apps 6) Web &amp; Mobileat 2017, luckly transfered to a web project, have the chance to know AngularJS, Node.js and event driven, REST, AJAX, async, many new and exciting ideas here. Hexo.io: a static blog engine web crawler: looks like a hack skill async event I/O lib: moduo, event.js top github Rankers have js projects, looks very intersting 7) OS relatedmany little tools when playing with Linux, system level, apps. One big stuff is Linux Process Communication(IPC). I used share memory in one product but never had a chance to know the big picture of IPC, later want to know about Linux network, and see socket, signal… feel connected. CMAKE: QT: Glib: MKL: intel math kernal lib, cool in first impression plugin-pattern in embedded software the good is know diversity, the short I don’t have done any contribution to combine these experince GBM]]></content>
  </entry>
  <entry>
    <title><![CDATA[W3C automotive open web platform]]></title>
    <url>%2F2018%2F05%2F22%2FW3C-automotive-open-web-platform%2F</url>
    <content type="text"><![CDATA[W3C automotive open web platformMain page: Link A clear web framework: 1) define the network communication APIs(based WebSocket protocol); 2) standarlize vehicle data; 3) define APIs to access vehicle data. Vehicle Information Service Specification(VISS)Object: to define WebSocket based APIs for a vehicle information service to enable client apps to get, set, subscribe, unsubscribe to vehicle signals, data attributesLink Vehicle Datadoc Link Object: to define a standard Vehicle Data with might be available in a vehicle 1) VehicleInterface2) VehicleCommonDataType3) VehicleConfigurationInterface (identification, sizeConfiguration, fuelConfiguration, transmissionConfiguration, wheelConfiguration, steeringWheelConfiguration)4) Running Status Interface(vehicleSpeed, wheelSpeed, engineSpeed, vehiclePowerMode, powertrain, acceleratorPedalPosition, throttlePosition, tripMeters, transmission, cruiseControlStatus, lightStatus, interiorLightStatus, horn, chime, fuel, engineOil, acceleration, engineeCoolant, steeringWheel, wheelTick, ignitionTime, gyro, brakeOperation, buttonEvent, drivingStatus, nightMode, startStopMode)5) Maintenance Interfaces(odometer, transmissionOil, transmissionClutch, brakeMaintenance, washerFluid, malfuncitonIndicator, battery Status, Tire, trouble Code, diagnostic)6) Personalization Interfaces ( languageConfiguration, unitsOfMeasures, mirror, driveMode, seatAdjustment, dashboardIllumination, vehicleSound )7) DrivingSafety Interfaces ( antilockBrakingSystem, tractionControlSystem, electroniceStabilitySystem, topSpeedLimit, airbagStatus, door, childSafetyLock, seat)8) Climate Interfaces (temperature, rainSensor, wiperStatus, defrost, sunroof, convertibleRoof, sideWindow, climateControl, atmosphericPressure)9) Vision &amp; Parking Interfaces( laneDepartureDetection, alarm, parkingBrake, parkingSensors) Vehicle Information API SpecificationObject: define a high level API for accessing vehicle signals, data attributes and communicate with in-vehicle data servers doc Link VISClient Interface used to define any on-board, off-board clients VISClientOptions Interface used to define a connection to a vehicle signal server(speicifiable by protocal, host, port) VISSubscription Interface used as return value from subscribed() methods VSS Interface used as return value from getVSS(), which should be sufficent to fully traverse the VSS tree Vehicle Information Access APIdoc Link Object: enable connectivity through in-vehicle infotainment systems and vehicle data access protocols 1) Navigator Interface: exposes the interface to vehicle information services2) Vehicle Interface: the initial entry point to get access to the vehicle information3) Zone interface: physical and logical zones4) VehicleIneterfaceCallback5) AvailableCallback6) VehicleInterfaceError (permission denied, invalid operation, timeout, invalid zone, unknown, error, message)7) VehicleInterface : the base interface to get all vehicle properties8) VehicleCOnfigurationInterface : access to static vehicle information9) VehicleSignalInterface: access to variables vehicle info10) Data Availability : available, not supported, not supported security policy, supported …]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where are you in next 5 years(2)]]></title>
    <url>%2F2018%2F05%2F18%2Fwhere-are-you-in-next-5-years-2%2F</url>
    <content type="text"><![CDATA[the billions level productThink about these guys in the world, who defined products/services used by billions people, they are more than model innovation, but really make a diffrence in most people’s life. e.g. iPhone, facebook, Google, they are not created from nowhere, but went through product iterations by iterations, and they only imerge when the tech, the market, the time all are in perfect. How many people in history achieved here? in any sense, it’s the history choose that person, not that person made history. so take it easy even you are not the 0.01%. in the promising marketmost people in their life time neither can be the next Jobs, nor Bill Gates. that’s the reality, no sad but clean expectation in the end before really in the last day of life. the second goal is easier, find a promising market and lead a small product, maybe lucky invovled in a domain market finally. You are not significant, but one of other 5000 competitors. Even this career path, however, you can’t expect the normal lifestyle: start at 25 and retire at 55 with enough 401K to death. If so, mostly you will be fired out someday in 30s or 40s. Chinese say, “if you dont plan far, you will be in trouble soon” so what may be the promising market subset in automotive software in next 5 years? generally say: 1) service, consulting; 2) self-business; 3)tech expert. in specificly saying: 1) electricity, energy infrastructure; 2) connected, cloud infrastructure; 3) autonomous vehicle.4) mobile apps, which is the carrier for the first 3. I mean the trend is so clear these days. No one can say he dont’ know where should stand in future. but where are you now? I like the model Elon Musk mentioned when do future plan: what’s your reality, what’s your goal, how to meet the gap, than focus on acting. will automotive software like mobile smartphones ?It’s interesting even now there are few third-party or independent “automotive software” companines, on opposite, in mobile market, there are lots of small or big third-party developing companines around Andriod, iOS, the mobile ecosystem is plenty and diversity. the reality in automotive field is lack of abstraction and separation between bottom hardware and top applications. in a mature mobile ecosystem, developer -&gt; end-usersin automotive software ecosystem, devleoper –&gt; OEM –&gt; end-users some auto allience is working on(AutoSAR). as developers, either gain some knowledge in hardware/control to solve the gap, or waiting for the day. what I expect on the way, may be like mobile time:1) automotive OS platform2) vehicle apps3) infrastures extending once the platform is unified, suppose many new auto branchs will emergy. like HTC, Xiaomi, Vivo, Huawei, Lenvo branches after Andriod OS. then new market stratgey is highly required, also traditional OEMs will be heavily impacted. OEM don’t like mobile ecosystemthis may happen soon or never, since OEM don’t like this trend. most possiblely, automotive software developers will highly rely on OEMs. so where will I stand in next 5-years ? OEM is good at strategy study and product integration. at a tech supplier, the benefit is more product driven experience. OEM suppose to have the advantage at automotive platform built-up, but reality is big Internet/software companies with product-level solutions, and OEM doesn’t. it is clear for me in next 5-years to jump into electric, connected, autonomous related industries, either at OEM level or supplier level. Also it is the time to do some study at automotive platform vendors.]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[where are you in next 5-years]]></title>
    <url>%2F2018%2F05%2F14%2Fwhere-are-you-in-next-5-years%2F</url>
    <content type="text"><![CDATA[what industry will you be in? in every industry, the product should be the core to define all other supporting teams, the market team, the product design team, IT team, manufacture team etc. so my answer suppose to be vehicle, or maybe I even should not limit here. as an mechanical/mechanics based engieer for three years, I realized there are three aspects: 1 solid knowledge in this special field, e.g. Mechanical has concept of stress, material property; market has concept of supply chain, product strategy, customer expectation; 2 fluent with the industry tools, which give the feeling you can fix the world by it, e.g. CAD/CAE tools to mechanical, programming tools to developers; 3 passion in the product, which is the driven force to explore and creativity. Do I have passion in vehicle? Or Do I feel the pain/hurt due to any unsolved issues in vehicle? maybe no, that’s why I stay in surface even after 3-years, don’t feel the pain neither the fire. knowledge is almost the easist part, which answer “what”, the true barrier is about tools(how) and passion(why). From knowledge level, reading couple professional books will be enough to absolve the concepts in a new acknowledge. career passionBut why you want to involve in this job? most people even don’t go to why, since reality is here: after getting married, pay the house fee, kids taken after. Job is a job, to support family, period. I love family, by the way. but don’t take family as an excuse for muddy career. Is there a field that knowledge is the tool? maybe AI, so far AI products is limited, e.g. voice, image. so tools are highly overlapped with knowledge. It sounds like an easy-in field. for a while as AI maturing and becoming an common service, then AI related products will burst out in every field, then product/market/capital-driven occupy. It’s a bad strategy to chase after market hot topics to develop personal career path. Current market trend is helpful, but there is no clear next-10-year market goal; on personal level, however, you definitely need a clear next 5/10-year goal, then every small adjust should point to that goal. so basically there are two categories: knowledge-driven, which is new coming e.g. AI; market-driven, which is always matured, e.g. automotive, smart phones. I suppose the matured market, if lacking creative input(vey much based on customer needs, market trends), is going to sunset sooner or later; the knowldege-driven market is bursting on the way, and absorving/requiring more and more labors. so where I am now, and where will I be in next 5-year? How do you survive in a matured market, or are you born to be the new-comers? and is the new-comers achievable? e.g. will AI related knowledge/tools be easy to catch? if in a matured market (automotive CAE)if I dont figure out a clear 5-year goal, most possiblely I will stay very unhappy in CAE the next 5 years; also very possible I can’t tolerant the work environemnt any more, and jump to any field at that time accept me; few chance to refresh my opinions and define a CAE sub-market. there are a few concerns. First, it’s not good to change direction immidetialy anytime the market is down, that’s too risk if you don’t setup the long-term goal. Second, in a sunset field, it’s not only about salary not high, the hidden aspects includes scattered office environoment, lay-off dangerous, not been valued, which will change the person into sunset. I mean, even a sunset period still need labers to maintain, but depends on personality, not for me somehow. what may be the CAE sub-market to rise? I can feel the tools is still highly used in automotive fields, but the maturity in CAE software products requires few new development, some new try into autonomous vehicle safety will not be a burst. Another try is in cloud based environment, is more like a sub-applications for the cloud vendors, it’s kind of a pattern innovation, not a product innovation. Due to the fewer chances in mature products, the level of candicates is actually high, most openings requries PhD. the mature market is a employer market, not employees friendly. And the education system may take decades to make a shift, during the period the employee somehow have to be devalued, because of the market decide their values. if in a new market (AI)by all menas, a new market does have more chances and promising futures and all the benifits where the mature market doesn’t have. The point is how to transfer from a mature market employee to a new market employee. I mentioned before, three aspects, knowledge, tools, and passion. Love it first, and the knowledge and familar with tools will achieved. need more discussion in next time.]]></content>
      <tags>
        <tag>CAE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[what happens in automotive softwares]]></title>
    <url>%2F2018%2F05%2F07%2Fwhat-happens-in-automotive-softwares%2F</url>
    <content type="text"><![CDATA[Backgroud:Due to 6-year school experince in mechanics, I was native to jump into CAE position. But I have few willing with CAD, which is very fundemental to be a qualified Product-Design side engineer. so I am not. So I am in a CAE tools support team, where I don’t directly design, mainly in enhancement, deployment etc, where understandthe old code, and write new function code, track bugs, system configure is enough. even in the big CAE vendors companies(Altair, Dassult System), the new methodlogy invest is very possibly less than product integration and customer consultings. what’s changing:the trend of CAE tools in OEMs demenstrates less investment, not because CAE tools are less used, but the CAE methodlodgy/process is really mature; new trends are arising, e.g. connected vehicles(CV), smart city, autonomous vehicles(AV), all of which require different knowledge and mindset(from mechanical to EE/CS). In 2017 Sep, I enrolled Udacity self-driving car, which gave some knowledge(openCV, deep learning, data fusion, object detect, plan algorithm), and the problems in AV. This field is so hot that openings around everywhere, basically California companies are high-demand, looking for a strong guy, AI expert, or senior automotiveengineer; while Michigan companies are old fasion, more on system integration level, and the required skills are random. if it’s a turning pointwhile Udacity didn’t work for me and AV is too young to all-in invest.For a while I am actually back to CAE, tried to enjoy it. But bad news keep coming, less projects funded, and frustrated office environment, so I move on. this time, IoT(connected vehicles) come to mind. it is really an old topic, since 2008 at college, IBM throw the big vision: smart earth to connect everything. Decades passed, finally the infrastructure, the application levels(transport, home, offices) are prepared-well. Good for me, I track AGL, GENIVI open source projects for around a year already and had 8-months experience in mobile developement(RESTful, server-client model), all bring me some fresh idea in connected vehicles. To study the automotive embedded software system, I tracked freeRTOS first, cause it’s easy since knowldege in Linux; about applications based on RTOS, however, I have no idea, e.g. vehicle dynamics, body/engine/powertrain control components, sensors, algorithms. While they are new but not difficult, hopefully can be familar in short period. softwares in connected vehiclesThere are two sections: the vehicle development, including traditional control components, which requires professional knowledge in vehicle dynamics, ECU; Vehicle Infotainment(IVI)components, which is like mobile developement. this section already has standard architecture, e.g. AutoSar secondly the vehicle to surroundings, either cloud device, peronsal mobile devices, or other vehicles. which requires: cloud infrastructures, communication protocol, security vendors, Android/IOS mobile apps, and IoT hardware vendors. it’s a clear big market, also it presents more valuable to do business than to be an engineer in each small field. the reasons come to mind, 1)architecture is done, no big mind/theory updated ; 2) so all should be about products, the integration components to market products is virtual. on-goingCAE softwares is heavy-math/numerical algorithms demanding; on the other side, embedded softwares is like enterprise Java, more on logic flow. As the population of mobile frameworks, and standarlization in automotive embedded system, the threshold suppose become lower. On the other hand, the dependence on suppliers’ libs and the test/release on hardwares may draw the life cycle of embedded software development longer. To explore embedded softwares may not the right career path, but no doubt it’s good to know what’s happening there. Finally, Either embrace the changing or wait it come to you, I mean, both are good stragies, maybe!]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[open source car control]]></title>
    <url>%2F2017%2F09%2F05%2Fopen-source-car-control%2F</url>
    <content type="text"><![CDATA[OSCC Introgithub it’s a modular using software to interface with a vehicle’s communication network and control systems. functions: to send control commands to the vehicle, read control messages from the vehicle’s OBD-II CAN network,f and forward reports for current vehicle control state (e.g. steering angle, wheel speed) sensors: steerng wheel torque sensor, throttle position sensor, brake position sensor issues: not safe for spoofing CAN message, or hacking firmware &amp; hardwareapplication layer (API)]]></content>
      <tags>
        <tag>automotive software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cs231 -- CNN in computer vision]]></title>
    <url>%2F2017%2F07%2F24%2FCNN-demo%2F</url>
    <content type="text"><![CDATA[what happend in high dimensional space?Pixel-based distance on high-dimensional data can be very unintuitive. Linear Classification1) define a score function from image pixels to class scores. benefits, no need to store all data 2) SVM and Softmax 3) a loss function, measure the quality of a paricular set of parameters based on how well the induced scores agreed with the ground truth labels optimization (SGD)the loss function as a hihg-dimeonsional optimization landscape, in which trying to reach the bottom BPRectified linear unit (ReLU)Neural Networkstrain a small network, the final loss are relatively few local minima, and easy to converge, but they are high loss; if train large network, there may many different solutions, but the variance in final loss is much smaller. –&gt; all solutions are equally as good, rely less on the random initialization in practice, use regularization tech to control overfit on large train network Data Preprocessing1) mean subtraction 2) normalization 3) PCA &amp; whitening 4) weight initialization 5) regularization 5.1) L-norm regularization 5.2) Dropout Hyperparamter optimization1) initial learning rate 2) learning rate decay schedule 3) regularization strength (L2 penalty) tips: decay learning rate over the period of training; search for good hyperparameters with random search CNNlayers used to build ConvNet architectures: 1) Convolutional layer 2) ReLU layer 3) Pooling layer 4) Fully-connected layer case study: LeNet AlexNet ZF Net GoogleNet VGGNet ResNet Visulization CNNTransfer learning]]></content>
  </entry>
</search>