<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="what I don&apos;t know">
<meta property="og:type" content="website">
<meta property="og:title" content="Serious Autonomous Vehicles">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Serious Autonomous Vehicles">
<meta property="og:description" content="what I don&apos;t know">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Serious Autonomous Vehicles">
<meta name="twitter:description" content="what I don&apos;t know">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>Serious Autonomous Vehicles</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Serious Autonomous Vehicles</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/22/mobility-data-center-in-ADAS-ADS/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/22/mobility-data-center-in-ADAS-ADS/" itemprop="url">mobility data center in ADAS/ADS</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-22T04:10:33-05:00">
                2020-11-22
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/11/22/mobility-data-center-in-ADAS-ADS/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/11/22/mobility-data-center-in-ADAS-ADS/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>keywords</strong>: autosar, data factory, AI training, simulation, v&amp;v, DevOps, IoT, adas applications</p>
<p>2~3 years ago, the top teams focus on perception, planning kinds of AI algorithms, which is benefited from the bursting of DNN, and lots invest goes there, and the optimism think once the best training model is founded, self-driving is ready to go. </p>
<p>then there was a famous talk about “long tail problems in AV” from Waymo team in 2018, the people realize to solve this problem, they need as many data as possible and as cheap as possible, which gives a new bussiness about data factory, data pipeline. </p>
<p>the investors realize the most cuting-edge AI model is just a small piece of done, there should be a data factory, which comes from MaaS serivces providers or traditional OEMs. </p>
<p>as data collector doesn’t exist common in traditional vehicles, so OEMs have to first make a new vehicle networking arch to make ADAS/ADS data collecting possible. which by the end, the game is back to OEMs. </p>
<p>at this point, IoT providers see their cake in AD market, OEMs may have a little understanding about in-vehicle gateway, t-box, but edge computing, cloud data pipeline are mostly owned by IoT providers, e.g. HuaWei and public data service providers, e.g. China Mobility. and the emerging of 5G infrastructure nationally also acc their share. </p>
<p>pipeline is one thing, the other is in-vehicle SoC, which has a few matured choices, such as Renasas, NXP, Mobileye, Nvidia Drive PX2/Xavier/Orin, and a bunch of new teams, such as horizon robotics, HuaWei MDC e.t.c </p>
<p>the traditionally definition of in-vehicle SoC has a minor underline about data pipeline and the dev tools around. but nowadays, taking a look at HuwWei MDC, the eco is so closed, from hardware to software, from in-vehicle to cloud. of course, the pioneer Nvidia has expand the arch from vehicle to cloud, from dev to validation already.  </p>
<p>SoC is the source of ADS/ADAS data, which give the role of SoC as mobility data center(MDC), we see the totally mindset transfer from software define vehicle to data defined vehicle. </p>
<p>the mechanical part of the vehicle is kind of de-valued when thought vehicle just as another source of data on-line. </p>
<p>to maximize the value of data, the data serivces(software) is better decoupled from vehicle hardwares(ecu, controller), which is another trend in OEMs, e.g. autosar. </p>
<p>till now, we see the AI models, simulation, data services are just the tip of the iceberg. and this is the time we see self dirving as the integrated  application for AI, 5G, cloud computing infra and future manufacturing. and the market is so large, no one can eat it all. </p>
<h2 id="refer"><a href="#refer" class="headerlink" title="refer"></a>refer</h2><p><a href="https://bbs.huaweicloud.com/blogs/142759" target="_blank" rel="external">AutoSAR Classic from Huawei</a></p>
<p>Mobileye赖以成名的EyeQ系列芯片同样内嵌了感知算法，但其在出售产品时候，往往都是软硬件打包出售，并不会根据客户情况进行针对性修改，或是让客户的算法运行在自己的感知芯片上。但地平线则采用完全开放的理念，即可提供硬件、也可提供包括算法的整体方案，还给客户提供了名为天工开物的完整工具链，让客户自己对芯片上的算法进行调整优化。</p>
<ul>
<li><p>Matrix2 (地平线）</p>
</li>
<li><p>mdc (huawei)</p>
</li>
<li><p>Drive PX 2 (nvidia)</p>
</li>
<li><p>DRIVE AGX Xavier （nvidia) </p>
</li>
<li><p>Orin (Nvidia)</p>
</li>
</ul>
<p><a href="https://www.sohu.com/a/321995543_391994" target="_blank" rel="external">车载智能计算基础平台 参考架构 1.0</a></p>
<p><a href="https://blogs.nvidia.cn/category/auto/" target="_blank" rel="external">nvidia self driving form</a></p>
<p><a href="https://blogs.nvidia.cn/2019/07/01/higher-standard-lead-industry-safety-group/" target="_blank" rel="external">nvidia lead the most safe standard</a></p>
<p>凭借我们自身在安全和工程方面的经验，NVIDIA已致力于领导欧洲汽车供应商协会（CLEPA）互联自动驾驶车辆工作组。NVIDIA在仿真技术和功能安全方面，拥有丰富的发展历史。我们的自动驾驶汽车团队在汽车安全和工程方面拥有宝贵的经验。</p>
<p>通过NVIDIA DRIVE Con​​stellation这样的平台，制造商可以通过该平台对他们的技术进行长距离的驾驶测试，还可以设定在现实世界中很少遇到的罕见或危险测试场景</p>
<p>NVIDIA还与自动化与测量系统标准化协会（ASAM）合作。我们正在领导其中一个工作组，以定义创建仿真场景的开放标准，描述道路拓扑表示、传感器模型、世界模型，以及行业标准和关键性能指标，从而推进自动驾驶车辆部署的验证方法。</p>
<p>业界正在开发一套新标准——ISO 21448，被称为预期功能安全（SOTIF）。它旨在避免即使所有车辆部件都处于正常运行的状态，但依然有可能会引发风险的情况。例如，如果运行在车辆中的深度神经网络错误地识别了道路中的交通标志或物体，则即使软件没有发生故障也可能产生不安全的情况。</p>
<p><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/self-driving-cars/safety-report/NVIDIA-Self-Driving-Safety-Report-2018.pdf" target="_blank" rel="external">nvidia drive</a></p>
<ul>
<li><p>Drive OS </p>
</li>
<li><p>Drive AV(a variety of DNNs)</p>
</li>
<li><p>Drive Hyperion(AGX Pegasus, and sensors)</p>
</li>
<li><p>Drive IX</p>
</li>
<li><p>Drive Mapping </p>
</li>
</ul>
<ul>
<li>Drive Constellation,  a data center solution to test and validate the actual hardware/software in an AV car</li>
</ul>
<p>data factory -&gt; AI training -&gt; </p>
<p> We also expand the use of our DNNs to support features like automatic emergency steering and autonomous emergency braking, providing redundancy to these functionalities</p>
<p> We also define key performance metrics to measure the collected data quality and add synthetic data into our training datasets</p>
<p> we incorporate actual sensor data from automatic emergency braking scenarios using re-simulation to help eliminate false positives.</p>
<p> NVIDIA created the DRIVE Road Test Operating Handbook to ensure a safe, standardized on-road testing process.</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/11/21/leetCode-swap-pairs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/11/21/leetCode-swap-pairs/" itemprop="url">leetCode_swap_pairs</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-21T08:22:01-05:00">
                2020-11-21
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/11/21/leetCode-swap-pairs/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/11/21/leetCode-swap-pairs/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="background"><a href="#background" class="headerlink" title="background"></a>background</h2><p><a href="https://leetcode-cn.com/problems/swap-nodes-in-pairs/" target="_blank" rel="external">LeetCode24: swap pairs</a></p>
<h2 id="intuitive-sol"><a href="#intuitive-sol" class="headerlink" title="intuitive sol"></a>intuitive sol</h2><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div></pre></td><td class="code"><pre><div class="line">  struct ListNode &#123;</div><div class="line">      int val;</div><div class="line">      ListNode *next;</div><div class="line">      ListNode() : val(0), next(nullptr) &#123;&#125;</div><div class="line">      ListNode(int x) : val(x), next(nullptr) &#123;&#125;</div><div class="line">      ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125;</div><div class="line">  &#125;;</div><div class="line"></div><div class="line">#include &lt;iostream&gt;</div><div class="line"></div><div class="line">class Solution &#123;</div><div class="line">public:</div><div class="line">    ListNode* swapPairs(ListNode* head) &#123;</div><div class="line">        ListNode *dummy = new ListNode(-1);</div><div class="line">        ListNode *prev = dummy ;</div><div class="line">        prev-&gt;next = head ;</div><div class="line">        ListNode *p1=head, *p2=p1-&gt;next, *p3=p2-&gt;next, *p4=p3-&gt;next, *pn, *tmp ;</div><div class="line"></div><div class="line">        if(p1 == nullptr)</div><div class="line">        &#123;</div><div class="line">            return nullptr ;</div><div class="line">        &#125;else if(p2 == nullptr)&#123;</div><div class="line">            return p1 ;</div><div class="line">        &#125;else if(p3 == nullptr)</div><div class="line">        &#123;</div><div class="line">            p2-&gt;next = p1 ;</div><div class="line">            p1-&gt;next = nullptr ;</div><div class="line">            head = p2 ;</div><div class="line">            return head ;</div><div class="line">        &#125;else if(p4 == nullptr)</div><div class="line">        &#123;</div><div class="line">            head-&gt;next = p2 ;</div><div class="line">            p2-&gt;next = p1 ;</div><div class="line">            p1 -&gt;next = p3;</div><div class="line">            return head ;</div><div class="line">        &#125;</div><div class="line"></div><div class="line">        for(p1=head, p2=p1-&gt;next, p3=p2-&gt;next, p4=p3-&gt;next ; p4 &amp;&amp; p3 &amp;&amp; p2 &amp;&amp; p1;  prev=p3, p1=prev-&gt;next, p2=p1-&gt;next, p3=p2-&gt;next, p4=p3-&gt;next )</div><div class="line">&#123;</div><div class="line"></div><div class="line">   pn = p4-&gt;next ;</div><div class="line">   p2-&gt;next = p1 ;</div><div class="line">   p4-&gt;next = p3 ;</div><div class="line">   p1-&gt;next = p4;</div><div class="line">   p3-&gt;next = pn ;</div><div class="line">   prev-&gt;next = p2 ;</div><div class="line"></div><div class="line">   if (pn == nullptr)</div><div class="line">   &#123;</div><div class="line">     break;</div><div class="line">   &#125;else if(pn-&gt;next == nullptr)</div><div class="line">   &#123;</div><div class="line">     break;</div><div class="line">   &#125;else if (pn-&gt;next-&gt;next == nullptr)</div><div class="line">   &#123;</div><div class="line">     break;</div><div class="line">   &#125;else if(pn-&gt;next-&gt;next-&gt;next == nullptr)</div><div class="line">   &#123;</div><div class="line">     break;</div><div class="line">   &#125;</div><div class="line"></div><div class="line">&#125;</div><div class="line"></div><div class="line">  if(pn == nullptr || pn-&gt;next == nullptr)&#123;</div><div class="line">    return prev-&gt;next;</div><div class="line">  &#125;</div><div class="line">   if(pn-&gt;next-&gt;next == nullptr )</div><div class="line">   &#123;</div><div class="line">     tmp = pn-&gt;next ;</div><div class="line">     prev-&gt;next = pn-&gt;next ;</div><div class="line">     tmp-&gt;next = pn ;</div><div class="line">     pn-&gt;next = nullptr;</div><div class="line">   &#125;else if(pn-&gt;next-&gt;next-&gt;next == nullptr)&#123;</div><div class="line">     tmp = pn-&gt;next ;</div><div class="line">     ListNode *last = tmp-&gt;next ;</div><div class="line">     prev-&gt;next = tmp ;</div><div class="line">     pn-&gt;next = last ;</div><div class="line"></div><div class="line">   &#125;</div><div class="line">     return prev-&gt;next;</div><div class="line">    &#125;</div><div class="line">&#125;;</div><div class="line"></div><div class="line">int main()</div><div class="line">&#123;</div><div class="line">   ListNode *head = new ListNode(1);</div><div class="line">   ListNode *sec = new ListNode(2);</div><div class="line">   ListNode *thd = new ListNode(3);</div><div class="line">   ListNode *fth = new ListNode(4);</div><div class="line">   head-&gt;next = sec ;</div><div class="line">   sec-&gt;next = thd ;</div><div class="line">   thd-&gt;next = fth ;</div><div class="line"></div><div class="line">   Solution *sol = new Solution();</div><div class="line"></div><div class="line">   ListNode *res = sol-&gt;swapPairs(head) ;</div><div class="line">   std::cout &lt;&lt; res-&gt;val &lt;&lt; ', ' &lt;&lt; res-&gt;next-&gt;val &lt;&lt; ', ' &lt;&lt; res-&gt;next-&gt;next-&gt;val &lt;&lt; std::endl;</div><div class="line">   return 0;</div><div class="line">&#125;</div></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/12/why-Hil-MiL-SiL-and-ViL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/12/why-Hil-MiL-SiL-and-ViL/" itemprop="url">why Hil MiL SiL and ViL</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-10-12T19:10:50-04:00">
                2020-10-12
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/10/12/why-Hil-MiL-SiL-and-ViL/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/10/12/why-Hil-MiL-SiL-and-ViL/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="background"><a href="#background" class="headerlink" title="background"></a>background</h2><p>there are two very different teams in AD. one kind is people from top Tier1 and popular OEMs, the benefit of these guys is they are very matured at the product process management, e.g. V&amp;V and the corresponding R&amp;D process, the other pons of these guys, they have lots of engineering know-how/experience to make things work. mostly we know how the system/tool work, but compared to build the sytem/tool to work, the first knowledge is about 10%. </p>
<p>the mature R&amp;D process is, as I see, is very valuable in a long time, which we’d say <strong>engineers getting richer as they getting older</strong>. till now, German and Janpanese top companies still have strong atmosphere to respect engineers, which keeps their engineers and their industry process management growing more and more mature. that’s a very good starting point for fresh young men, if they can join these top companies in early time. </p>
<p>the other team is from Internet companies, they are the kind of people with philosophy: as you can image out, I can build it up. while the philosophy always become true in IT and Internet service companies, and looks promising in industry fields, as the IT infra, like nowadays, service to cloud, office work in cloud, which derives lots of cloud infra, but the core like robot operation, making vehicle driving automatically, or computer aided engineering e.t.c. requires lots of know-how, far beyond the infra. </p>
<p>Internet teams are popular in China and US, but US still have strong engieer atmosphere like Germany, which is not in China. basically I want to say, there is no apprentice process to train fresh men to matured engineers in either companies or training organizations in China, which makes engineers here show low credit. </p>
<p>even Internet knowledge and skills in China, often we’d say <strong>programming work are youth meals, as programmer getting older they getting poor</strong></p>
<p>that’s the tough situation for many young people, if the men got neither good engineering training, nor got smart and young enough to coding, he get doomed in his career. but that’s not a problem for the country neither for the companies, still Chinese workers are cheap, there are always lots of young people need bread beyond a promising career. </p>
<h2 id="physical-or-virtual"><a href="#physical-or-virtual" class="headerlink" title="physical or virtual"></a>physical or virtual</h2><p>the first-principal of writing a program:</p>
<ul>
<li>make it run ok </li>
<li>make it run correct</li>
<li>make it run performance-well</li>
<li>make it extensible </li>
</ul>
<p>the following is to understand why we need HiL, mil, sil, to ViL during verification and validation of an ADS product, from the physical or virtual viewpoint. </p>
<h3 id="physical-or-virtual-world"><a href="#physical-or-virtual-world" class="headerlink" title="physical or virtual world"></a>physical or virtual world</h3><h5 id="case-1-from-physical-world-to-physical-sensor"><a href="#case-1-from-physical-world-to-physical-sensor" class="headerlink" title="case 1) from physical world to physical sensor"></a>case 1) from physical world to physical sensor</h5><p>namely, physical road test, either in closed-field, or open roads. </p>
<p>this is the case when we need ground truth(G.T.) system to validate the device under test(DUT) sensor, to evaluate or test the DUT’s performance boundary, failure mode e.t.c. </p>
<p>the people can come from sensor evaluation teams, or system integration teams. </p>
<h5 id="case-2-from-virtual-world-to-physical-sensor"><a href="#case-2-from-virtual-world-to-physical-sensor" class="headerlink" title="case 2) from virtual world to physical sensor"></a>case 2) from virtual world to physical sensor</h5><p>the virtual world come either from digital twins, or replay from a data collector. this is hardware in loop(HiL) process, which used a lot in validate either sensor, or MCUs. when using HiL to validate MCUs, the virtual world is mimic signals e.t.c</p>
<h3 id="virtual-sensor"><a href="#virtual-sensor" class="headerlink" title="virtual sensor"></a>virtual sensor</h3><h5 id="case-3-from-virtual-world-to-virtual-sensor"><a href="#case-3-from-virtual-world-to-virtual-sensor" class="headerlink" title="case 3) from virtual world to virtual sensor"></a>case 3) from virtual world to virtual sensor</h5><p>virtual sensor has three kinds basically:</p>
<ul>
<li><p>ideal (with noise) sensor model</p>
</li>
<li><p>statisticsly satisfied sensor model</p>
</li>
<li><p>physical sensor model </p>
</li>
</ul>
<p>of course, the costing is increasing from ideal to physical sensor model. </p>
<p>ideally, the downside fusion module should be no senstive to sensors, either phyiscal sensors or virtual sensors(sensor models). the benefits of capturing virtual world by virtual sensor is so cheap, which makes it very good to training perception algorithms, when physical sensor data is expensive, which is often the reality for most companies now.</p>
<p>there is <strong>local maximum</strong> issues with virtual sensor data to train AIs, so in reality, most team used to mix 10% real-world sensor data to improve or jump out from these local maximums.</p>
<p>of course, virtual sensor is one fundamental element to close loop from virtual world to vehicle moving, in a sim env. </p>
<h3 id="physical-or-virutal-perception-to-fusion"><a href="#physical-or-virutal-perception-to-fusion" class="headerlink" title="physical or virutal perception to fusion"></a>physical or virutal perception to fusion</h3><p>here is how to test fusion, does it work correctly, performance well, how to handle abnormal(failure) case.</p>
<h5 id="case-4-from-physical-sensor-perception-data-to-fusion"><a href="#case-4-from-physical-sensor-perception-data-to-fusion" class="headerlink" title="case 4) from physical sensor perception data to fusion"></a>case 4) from physical sensor perception data to fusion</h5><p>physical perception data comes in two ways:</p>
<ul>
<li>the sensor system in vehicle</li>
<li>ground truth system(G.T.)</li>
</ul>
<p>during RD stage, the sensor system in vehicle is treated as device under test(DUT), whose result can compare with the labeling outputs from G.T. system, which help to validate DUT performance, as well as to evaluate fusion performance.</p>
<p>in phyiscal world, ground truth sytem is usually equipped with a few higher precision Lidars, of course the cost is more expensive.</p>
<p>another pro of physical perception data is extract edge cases, which used to enrich the scenario libs, especially for sensor perception, and fusion. </p>
<p>during massive production stage, when the data pipeline from data collector in each running vehicle to cloud data platform is closed-loop, which means the back-end system can extract and aggregate highly volume edge case easily, then these large mount of physical perception data can drive fusion logsim.</p>
<p>question here, edge case scenarios are these abnormal perception/fusion cases, but how to detect edge cases from highly volume data in cloud(back-end), or to design the trigger mechanism in vehicle(front end) to only find out the edge cases, is not an matured work for most teams.</p>
<p>another question here, to evaluate fusion, requires objective ground truth, which is not avaiable in massive production stage. an alternative option is using a better performance and stable sensor as <strong>semi ground truth</strong>, such as Mobileye sensor.</p>
<h5 id="case-5-from-virtual-sensor-perception-data-to-fusion"><a href="#case-5-from-virtual-sensor-perception-data-to-fusion" class="headerlink" title="case 5) from virtual sensor perception data to fusion"></a>case 5) from virtual sensor perception data to fusion</h5><p>when in sim world, it’s easily to create a <strong>ground truth sensor</strong>, then it’s easily to check fusion output with the g.t. sensor, which is great, the only assuming here, is the sim world is highly vivid of the physical world. if not, the <strong>ground truth sensor</strong> is not useful, while obviously to build a digital twin as phyiscal as possible is not easy than create the ADS system. </p>
<p>on the other hand, if the sim world is not used to evaluate fusion, for example, used to generate synthetic images, point cloud to train perception AI modules, which is one benefit. </p>
<p><strong>in summary</strong>, when evaluate and validate fusion, it requires ground truth labelling, either from physical g.t. system, or virtual g.t. sensor.  1) the g.t. system is only used for during R&amp;D stage, with a small volumn of g.t. data; for massive release stage, there is no good g.t. source yet; 2) g.t. sensor in virtual world is easy to create, but requires the virtual worls is almost physical level. </p>
<p>second opnion, fusion evaluation is deterministic and objective. so if the fusion can validated well during RD stage, considering its performance robost, stable, there is no need to validate fusion module in massive lease. when perception/fusion edge case happens, we can study them case by case.</p>
<p>third opinon, for anormal case, e.g. sensor failure, sensor occupied cases, also need validate during RD. </p>
<h3 id="planning"><a href="#planning" class="headerlink" title="planning"></a>planning</h3><p>the evaluation of planning good or not is very subjective, while in fusion, ground truth is the criteria. so there are two sols:</p>
<ul>
<li>to make subjective goals as much quanlity as possible </li>
<li>define RSS criterias to bound the planning results</li>
</ul>
<p>ideally, planning should be not sensitive to fusion output from physical world, or virtual world. and when come to planning verification, we asumme the fusion component is stable and verified-well, namely should not delay find fusion bugs till planning stage. </p>
<h5 id="case6-from-sim-fusion-output-to-planning"><a href="#case6-from-sim-fusion-output-to-planning" class="headerlink" title="case6) from sim fusion output to planning"></a>case6) from sim fusion output to planning</h5><p>SiL is a good way to verify planning model. previously, planning engineers create test scenarios in vtd, prescan, and check does the planning algorithms work.</p>
<p>for a matured team, there are maybe hundreds and thousands of planning related scenarios, the should-be verification process requires to regress on all these scenarios, so to automatically and accelerate this verification loop, gives the second solution: cloud SiL with DevOps, like TAD Sim from Tencent, Octopus from Huawei e.t.c.</p>
<p>another benefits of SiL in cloud is for complex driving behavior, real vehicle/pedestrains to vehicle interactions, and especially when the scenario lib is aggregating as the ADS lifecycle continues.</p>
<p>if the planning algorithm is AI based, then to mimic the real-human drivers driving behaivor and assign these driving behaviors to the agents in the virtual world, will be very helpful to train the ego’s planning AI model.</p>
<p>here are two models: imitation learning and reinforcement learning. firstly we train the agent/ego driving behaivor using physical world driving data by imitation learning in a training gym; and transfer these trained model to agents and ego in the sim world, they continue driving and interaction with each other, and keep training itself to do better planning. </p>
<p>for corner/edge cases, as planning is very subjective, and lots of long-tail scenarios are there, so physical world situations collection is very valuable. </p>
<h5 id="case-7-from-physical-fusion-output-to-planning"><a href="#case-7-from-physical-fusion-output-to-planning" class="headerlink" title="case 7) from physical fusion output to planning"></a>case 7) from physical fusion output to planning</h5><p>Tesla looks be the only one, who deployed the shadow mode trigging mechanism to get planning corner cases from physical driving, and the data close loop.</p>
<p>the large volumn of physical driving data is very useful for verification and iteration of planning: </p>
<ul>
<li><p>aggregate more real planning scenarios, by detecting edge cases</p>
</li>
<li><p>train better driving behavior, as close as possible to humans</p>
</li>
</ul>
<h3 id="control"><a href="#control" class="headerlink" title="control"></a>control</h3><p>control is the process from planning output, e.g. acc, decel, turning-angle to physical actuator response, brake force, engine torque e.t.c</p>
<p>there are a few common issues :</p>
<ul>
<li><p>nonlinear characteristic, mostly we don’t get a perfect control output as expect. e.g. from decel to brake force. </p>
</li>
<li><p>the actuator has response delay, which need professional engineers train to get a good balance, but still doesn’t work as expect at all the scenarios </p>
</li>
<li><p>the actuators as a whole is very complex, tuning requires.</p>
</li>
</ul>
<h5 id="case-8-from-planning-to-virtual-vehicle-model"><a href="#case-8-from-planning-to-virtual-vehicle-model" class="headerlink" title="case 8) from planning to virtual vehicle model"></a>case 8) from planning to virtual vehicle model</h5><p>this is where sim requires a high-precise vehicle dynamic model, which affects the performance. but a simple vehicle dynamic does work for planing, if not requires to cosist with the physical performance. </p>
<h4 id="case-9-from-planning-to-physical-vehicle"><a href="#case-9-from-planning-to-physical-vehicle" class="headerlink" title="case 9) from planning to physical vehicle"></a>case 9) from planning to physical vehicle</h4><p>ViL, which is another big topic </p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/10/07/find-out-ADS-simulation-trend-from-top-teams/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/10/07/find-out-ADS-simulation-trend-from-top-teams/" itemprop="url">find out ADS simulation trend from top teams</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-10-07T01:13:43-04:00">
                2020-10-07
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/10/07/find-out-ADS-simulation-trend-from-top-teams/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/10/07/find-out-ADS-simulation-trend-from-top-teams/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="background"><a href="#background" class="headerlink" title="background"></a>background</h2><p>what’s the basic logic behind simulation in autonomous driving system(ADS) ? or why we need simulation in ADS, during AD development and even after massively produced ? how to integrate simulation in the AD closed-loop platform, namely from fleet/test data collection to valuable new features?</p>
<p>before I can answer these questions, a few steps has went through:</p>
<ul>
<li>L2 commerical sims</li>
</ul>
<p>e.g. Matlab ADS box, vtd, prescan e.t.c. </p>
<ul>
<li>L3+ WorldSim</li>
</ul>
<p>few years ago, most ADS teams get the knowledge: AD require at least 10 billion miles verification, which can’t be done in traditional test field. so comes digitial twins, game engine based simulator, e.g. LGsim, Carla, and Tencent, Huawei etc have already made these simulator as service in their public cloud. we also try LGsim, and deploy it in k8s env, that was a good time to learn, but not really helpful in practice. </p>
<ul>
<li>L2 LogSim</li>
</ul>
<p>to assist L2 ADAS functions/algorithms/features iteration, as mentioned in <a href="https://zjli2013.github.io/2020/09/20/system-validation-in-l2-adas/" target="_blank" rel="external">system validation in l2 adas</a>, most l2 adas features doesn’t necessarily depends on Logsim, standard benchmark test suit are enough most time.</p>
<p>of course, with more mount of LogSim, definitely can expose more bottleneck of the existing l2 adas features, but there is a balance between costing and profit. currently, large mount of physical data based L2 adas feature optimization is not an efficient invest for most OEMs. </p>
<p>the special case of l2 feature is false positive of AEB system, which actually requires statiscally measurement.</p>
<p>in a common development cycle, AEB system have about 5 major versions, and a few minor versions in each major version, so each version deployment need to check its false positive statically, which make logsim is a have-to. </p>
<p>another common usage of logsim is sensor algorithm development, e.g. Bosch Radar. before each new version of radar algorithm release, they have to check its performance statiscally through logsim. </p>
<p>LogSim is a very good starting point to integrate simulator into the ADS closed-loop platform, while we deal with data collection, clean, uploading, storage in db, and query through data engine, and DevOps to automatically trig to run, analysis and report. </p>
<ul>
<li>system verification and validation</li>
</ul>
<p>simulation is a test pathway, that’s the original purpose of simulation. traditionally, new vehicle release has went through closed field test, which has changed during ADS age, as ADS system is open-loop, there is no test suit can do once and forever, so <strong>miles coverage</strong> and <strong>scenario coverage</strong> are the novel pathways in ADS validation, which leads to simulation.</p>
<ul>
<li>ADS regulation evalution </li>
</ul>
<p>that’s the new trend as ADS getting popular, the goverment make rules/laws to set bars for new ADS players. one obligatory way is simulation.</p>
<p>thanks for China Automotive Research Institute(CARI) teams. </p>
<p>the following I’d share some understanding of simulation from top AD simulation teams: </p>
<h2 id="QCraft"><a href="#QCraft" class="headerlink" title="QCraft"></a><a href="https://www.qcraft.ai/" target="_blank" rel="external">QCraft</a></h2><p>Our mission at QCraft is to bring autonomous driving into real life by using <a href="https://www.qcraft.ai/1852273-1862545.html?newsid=1816799&amp;_t=1582550990" target="_blank" rel="external">a large-scale intelligent simulation system and a self-learning framework for decision-making and planning</a>.</p>
<p>QCraft was ex-waymo simulation team, has a solid understanding about simulation in AD R&amp;D. the logic behind QCraft: </p>
<ul>
<li><p>感知是一个比较确定性的问题，如何测试和评价是非常明确的，整体的方法论也是比较清楚的</p>
</li>
<li><p>规划决策视为目前最具挑战性的问题。第一，不确定性难以衡量。现有判断规划决策做得好坏的指标是舒适度和安全性；第二，从方法论的角度来说，行业里占主流位置的规划决策方法论，整体上看与20年前相比并没有大的突破。模仿学习或强化学习的方法，在大规模实际应用时也仍然存在众多问题</p>
</li>
</ul>
<p>许多创业公司从无到有的技术构建过程——先做好建图和定位，再做好感知，最后再开始做规划决策和仿真。</p>
<p>this is a very good point, as most early start-ups focus on AI based perception or planning, but gradually people realize as  no destructive break-through in AI tech, the AI model evaluation is too slowly, but collecting useful data is the real bottleneck. AI model is the most cheap thing when compare to data. </p>
<p>the other point, Predict &amp; Planning(P&amp;P) is the real challenging in L3+ ADS, when dealing with L2 adas features, P&amp;P is knowlege based, which is a 20-years-old mindset. as P&amp;P in L3+ requires an efficient way to test, then comes to simulation. </p>
<p>边界化难题（Cornercase），在你遇上野鸭子之前，你甚至不知道会有野鸭子的问题，所以边界化难题是需要有方法去(自动)发现新的corner case，并解决。</p>
<p>除了收集大量的数据，更重要的是建立自动化生产的工厂，将源源不断收集来的有效数据，通过自动化的工具，加工成可用的模型。以更快的速度、更高效的方式应对边界化难题（Corner case）。</p>
<p>测试工具是为了帮助工程师高效地开发，快速复现车辆上的问题，并提前暴露可能的潜在问题，同时也是提供一个评估系统，评价一个版本和另外一个版本比是变好了还是变坏了。</p>
<p>我们的测试系统可做到和车载系统的高度一致，在路上出现的问题，回来就能在仿真里复现，并进行修复。保证再次上路时不出现同样问题。我们产生的场景库也与现实环境高度一致，因为本来就是从现实中学习来的</p>
<p>轻舟智航不希望“只见树木不见森林”——通过见招拆招的方式进入到某个具体的小应用场景，变成一家靠堆人来解决问题、无法规模化的工程公司，</p>
<p>in a word, to build a closed-loop data platform to drive ADS evolution automatically or self-evolution, that’s the real face of autonomous vehicle. </p>
<h4 id="QCraft-实现无人驾驶需要什么样的仿真系统"><a href="#QCraft-实现无人驾驶需要什么样的仿真系统" class="headerlink" title="QCraft: 实现无人驾驶需要什么样的仿真系统"></a><a href="https://www.qcraft.ai/1852273-1862545.html?newsid=1816797" target="_blank" rel="external">QCraft: 实现无人驾驶需要什么样的仿真系统</a></h4><ul>
<li>基于游戏引擎开发的仿真软件大都“华而不实”</li>
</ul>
<p>仿真软件在自动驾驶领域的重要应用，就是复现(replay)某一次的路测效果。但由于这种第三方软件的开发与自动驾驶软件的开发是相互独立的，很难保证其中各个模块的确定性，导致整个仿真软件存在不确定性，最终影响可用性。</p>
<p>轻舟智航仿真系统的系统架构可以分为5层：最底层的是轻舟智航自研的Car OS，借助底层的通讯系统来保证模块之间的高效通讯； Car OS与仿真器是高度整合的系统，核心仿真器及评估器，是基于底层的Car OS接口开发的，能保证仿真系统的确定性；再往上一层是仿真周边工具链和基础架构，可保证整个数据闭环的有效性，将全部数据高效利用起来；第四层是大规模场景库构建；最顶层则是分布式系统仿真平台，支持快速、大规模的仿真应用，在短时间内得出正确评估。</p>
<p>仿真场景库的自动生成的相关工作。视频中红色和绿色的两个点，分别代表两辆车的运动轨迹，这些轨迹的生成和变化，是在真实的交通数据集上，利用深度学习的方法进行训练，再使用训练好的深度神经网络 (生成模型) 合成大规模的互动车辆的轨迹</p>
<p>我们认为仿真是达到规模化无人驾驶技术的唯一路径。首先，借助仿真及相关工具链，能形成高效的数据测试闭环，支持算法的测试和高效迭代，取代堆人或堆车的方式；其次，只有经过大规模智能仿真验证过的软件，才能够保证安全性和可用性。</p>
<p><img src="https://cdn.yun.sooce.cn/4/51701/png/15853709246623a220004b7106964.png?version=1585370929" alt="image"></p>
<p>in a word, this is a very ambitious plan, from carOS to cloud end, the whole data pipeline, from fleet data collection to model training, to new features release. the missing part is who would pay for it and the most evil part is who will pay for the large mount of engineering work, which is not something feeling high for PhDs. </p>
<h2 id="Latent-Logic"><a href="#Latent-Logic" class="headerlink" title="Latent Logic"></a><a href="https://www.latentlogic.com/" target="_blank" rel="external">Latent Logic</a></h2><p>another waymo simulation startup, offers a platform that uses <strong>imitation learning</strong> to generate virtual drivers, motorists and pedestrians based on footage collected from real-life roads. Teams working on autonomous driving projects can insert these virtual humans into the simulations they use to train the artificial intelligence powering their vehicles. The result, according to Latent Logic, is a closer-to-life simulated training environment that enables AI models to learn more efficiently.</p>
<h4 id="training-autonomous-vehicles-using-real-life-human-behaviour"><a href="#training-autonomous-vehicles-using-real-life-human-behaviour" class="headerlink" title="training autonomous vehicles using real-life human behaviour"></a><a href="https://www.research.ox.ac.uk/Article/2019-06-19-training-autonomous-vehicles-using-real-life-human-behaviour" target="_blank" rel="external">training autonomous vehicles using real-life human behaviour</a></h4><p>‘Autonomous vehicles must be tested in simulation before they can be deployed on real roads. To make these simulations realistic, it’s not enough to simulate the road environment; we need to simulate the other road users too: the human drivers, cyclists and pedestrians with which an autonomous vehicle may interact.’</p>
<p>‘We use computer vision to collect these examples from video data provided by traffic cameras and drone footage. We can detect road users, track their motion, and infer their three-dimensional position in the real world. Then, we learn to generate realistic trajectories that imitate this real-life behaviour.’</p>
<p>in a word, Latent Logic is dealing with P&amp;P training in L3+ ADS, which is the real challenging. </p>
<h2 id="Roman-Roads"><a href="#Roman-Roads" class="headerlink" title="Roman Roads"></a><a href="https://www.romanroads.io/" target="_blank" rel="external">Roman Roads</a></h2><p>using <strong>imitation learning</strong> to train robots to behave like human, state of the art behavioral tech.</p>
<p>We offer <strong>R&amp;D solutions</strong> from 3D environment creation, traffic flow collection to testing &amp; validation and deployment.</p>
<ul>
<li>driving behavior data collection </li>
</ul>
<p>ego view collection, fleet road test </p>
<ul>
<li>real-time re-construction</li>
</ul>
<p>real time generation of 3d virtual env and human behavior(imitation learning)</p>
<ul>
<li>data-driven decision making </li>
</ul>
<ul>
<li>pre-mapping </li>
</ul>
<p>The behavior offset are different between two cities. We collect data, like how people change lane and cut in, and learn the naturalistic behaviors at different cities.</p>
<p>in a word, still a very solid AI team, but who would pay for it and how to get valuable data, or integrate into OEM’s data platform, is the problem. </p>
<h2 id="Cognata"><a href="#Cognata" class="headerlink" title="Cognata"></a><a href="https://www.cognata.com/" target="_blank" rel="external">Cognata</a></h2><p>the customer includes Hyundai Mobis. Cognata delivers large-scale full product lifecycle simulation for ADAS and Autonomous Vehicle developers.  </p>
<h4 id="training"><a href="#training" class="headerlink" title="training"></a>training</h4><p>Automatically-generated 3D environments, digital twins or entirely synthetic worlds by DNN, synthetic datasets, and realistic AI-driven traffic agents for AV simulation.</p>
<h4 id="validation"><a href="#validation" class="headerlink" title="validation"></a>validation</h4><ul>
<li><p>pre-built scenarios, </p>
</li>
<li><p>standard ADAS/AV assessment programs </p>
</li>
<li><p>fuzzing for scenario variaties for regulations and certifications </p>
</li>
<li><p>UI friendly </p>
</li>
</ul>
<h4 id="analysis"><a href="#analysis" class="headerlink" title="analysis"></a>analysis</h4><ul>
<li><p>Ready-to-use pass/fail criteria for validation and certification of AV and ADAS</p>
</li>
<li><p>Trend mining for large scale simulation</p>
</li>
</ul>
<h4 id="visulization"><a href="#visulization" class="headerlink" title="visulization"></a>visulization</h4><h3 id="how-it-works"><a href="#how-it-works" class="headerlink" title="how it works"></a>how it works</h3><p>static layer: digital twin </p>
<p>dynamic layer: AI powered vehicles and pedestrains </p>
<p>sensor layer: most popular sensor models based on DNN </p>
<p>cloud layer: scalability and on-promise. </p>
<p>Cognata as an independent simulation platform is so good, but when considering integration with exisitng close loop data platform in OEMs, it’s like a USA company, too general, doesn’t wet the shoe deeply, compare to QCraft, whose architecture is from down to top, from car OS to cloud deployment, which is more reliable solution for massively ADAS/AD products in future.</p>
<h2 id="applied-intuition"><a href="#applied-intuition" class="headerlink" title="applied intuition"></a><a href="https://www.appliedintuition.com/" target="_blank" rel="external">applied intuition</a></h2><p>another Waymo derived simulation company. Test modules individually or all together with our simulation engine that’s custom built for speed and accuracy.</p>
<p>improve perception algorithms, Compare the performance of different stack versions to ground truth data. Test new behaviors and uncover edge cases before pushing updates to your vehicles.</p>
<ul>
<li><p>Extract valuable data from real world drives and simulations</p>
</li>
<li><p>Review interesting events recorded from vehicles and simulations to determine root cause issues. Share the data with other team members for further analysis and fixes.</p>
</li>
<li><p>Extract and aggregate performance metrics from drive logs into automatic charts, dashboards, and shareable reports for a holistic view of your development progress.</p>
</li>
<li><p>Run your system through thousands of virtual scenarios and variations to catch regressions and measure progress before rolling it out for on-road testing.</p>
</li>
</ul>
<p>in a word, looks pretty.</p>
<h2 id="metamoto"><a href="#metamoto" class="headerlink" title="metamoto"></a><a href="https://www.metamoto.com/" target="_blank" rel="external">metamoto</a></h2><p>simulation as a service, Enterprise products and services for massively scalable, safe, scenario-based training and testing of autonomous system software</p>
<p>it’s an interet based simulator compare to preScan, but in core is just another preScan, with scalability. can’t see data loop in the arch. so it’s helpful during R&amp;D, but not realy usefuly after release.</p>
<h2 id="Parallel-Domain"><a href="#Parallel-Domain" class="headerlink" title="Parallel Domain"></a><a href="https://paralleldomain.com/" target="_blank" rel="external">Parallel Domain</a></h2><p>power AD with synthetic data, the ex-Apple AD simulation team.</p>
<p>Parallel Domain claims its computing program will be able to generate city blocks less than a minute, Using real-world map data.  Parallel Domain will give customers plenty of options for fine tuning virtual testing environments. The simulator offers the option to incorporate real-world map data, and companies can alter everything from the number of lanes on a simulated road to the condition of its computer-generated pavement. Traffic levels, number of pedestrians, and time of day can be tweaked as well.</p>
<p><a href="https://www.thedrive.com/tech/20559/parallel-domain-wants-to-create-a-virtual-world-for-self-driving-car-tests" target="_blank" rel="external">Nio is the launch customer of Parallel Domain</a></p>
<p><a href="https://www.futurecar.com/2229/Parallel-Domain-Looks-to-Train-Autonomous-Vehicles-in-Virtual-Reality" target="_blank" rel="external">PD looks to train AD in virtual reality</a></p>
<p><strong>from real map to virtual world</strong>, and road parameters are programable. but what about micro traffic flow, vehicle-pedestrain-cars interaction ?</p>
<p>I think it’s great to generate virtual world with Parallel Domain, but not enough as the simulator in the whole close loop.</p>
<p>the collected data, of course include real map info, which can used to create virtual world, but why need this virtual world? is to train AD P&amp;C system, which is more than just the static virtual world and with some mimic pedestrain/vehicle behaviors.</p>
<p>in AI powered AD, valid and meaningful data is the oil. the basic understanding here is to with more data, get more robost and general AI model, which means with more data, the AI AD system can do behavior better with existing scenarios, and more importantly, do increase the ability to handle novel scenarios automatically.</p>
<p>so is the close loop data in AD.</p>
<h2 id="righthook"><a href="#righthook" class="headerlink" title="righthook"></a><a href="https://righthook.io/how-it-works/" target="_blank" rel="external">righthook</a></h2><ul>
<li><p>digital twin of real world </p>
</li>
<li><p>scenario creation tool powered by AI</p>
<p>to derive high-value permuation and test cases automatically(maybe both static and dynamic scenarios)</p>
</li>
<li><p>vehicle configuration </p>
</li>
</ul>
<ul>
<li>test management </li>
</ul>
<p>integration with DevOps and cloud on-premise </p>
<p>in a world, this is something similar like Cognata, to generate vivid world from physical map data or synthetic data, then add imitation learning based agents, then a DevOps tool and web UI configurable.</p>
<p>the most important and also the difficult part of this pipeline, is how to obtain large mount of valid and useful real data as cheap as possible, to train the scenario generator, as well as agents behavior generator. </p>
<p>only MaaS taxi companies and OEMs have the data. </p>
<h2 id="rfpro"><a href="#rfpro" class="headerlink" title="rfpro"></a><a href="http://www.rfpro.com/" target="_blank" rel="external">rfpro</a></h2><p>a driving simulation and digital twin for ad/adas, vd(chassis, powertrain e.t.c) development, test and validation. </p>
<p> rFpro includes interfaces to all the mainstream vehicle modelling tools including CarMaker, CarSim, Dymola, SIMPACK, dSPACE ASM, AVL VSM, Siemens Virtual lab Motion, DYNAware, Simulink, C++ etc.  rFpro also allows you to use industry standard tools such as MATLAB Simulink and Python to modify and customise experiments.</p>
<p>rFpro’s open Traffic interface allows the use of Swarm traffic and Programmed Traffic from tools such as the open-source SUMO, IPG Traffic, dSPACE ASM traffic, PTV VisSim, and VTD. Vehicular and pedestrian traffic can share the road network correctly with perfectly synchronised traffic and pedestrian signals, while allowing ad-hoc behaviour, such as pedestrians stepping into the road.</p>
<p><a href="http://www.rfpro.com/driving-simulation/datafarming/" target="_blank" rel="external">data farming: generating mimic training data</a></p>
<ul>
<li><p>the largest lib of digital twins of public roads in the world </p>
</li>
<li><p>supervised learning env for perception </p>
</li>
</ul>
<p>in a word, looks like a traditionally tier2. </p>
<h2 id="edge-case-research"><a href="#edge-case-research" class="headerlink" title="edge case research"></a><a href="https://edge-case-research.com/" target="_blank" rel="external">edge case research</a></h2><h4 id="Hologram"><a href="#Hologram" class="headerlink" title="Hologram"></a>Hologram</h4><p>complements traditional simulation and road testing of perception systems</p>
<p>Hologram unlocks the value in the perception data that’s collected by your systems.  It helps you find the edge cases where your perception software exhibits odd, potentially unsafe behavior.</p>
<p>from recorded data, to automated edge case detection(powered by AI), The result: <strong>more robust perception</strong></p>
<p><img src="https://edge-case-research.com/wp-content/uploads/2019/07/image.png" alt="image"></p>
<p><img src="https://ecrweb.wpengine.com/wp-content/uploads/2018/08/Web-1920-%E2%80%93-1@2x.png" alt="image"></p>
<p>most of the cost of developing safety-critical systems is spent on verification and validation. </p>
<p>in a word, safety is a traditional viewpoint, and most AI based  teams doesn’t have solid understanding. but how ECR ca</p>
<h2 id="foretellix"><a href="#foretellix" class="headerlink" title="foretellix"></a><a href="https://www.foretellix.com/adas-and-highway-solution/" target="_blank" rel="external">foretellix</a></h2><p>out of box verification automation solution for ADAS and highway functions, developed based on input from OEMs, regulators and compliance bodies. </p>
<p><strong>Coverage Driven Verification</strong>, Foretellix’s mission is to enable <strong>measurable safety</strong> of ADAS &amp; autonomous vehicles, enabled by a transition from measuring ‘quantity of miles’ to ‘quality of coverage’ </p>
<p><a href="https://www.foretellix.com/technology/" target="_blank" rel="external">how it works</a></p>
<ul>
<li>what to test ?</li>
</ul>
<p>Industry proven verification plan and 36 scenario categories covering massive number of challenges and edge cases</p>
<ul>
<li>When are you done?</li>
</ul>
<p>Functional coverage metrics to guide completeness of testing</p>
<p><img src="https://www.foretellix.com/wp-content/uploads/2020/08/Untitled-design-47.png" alt="image"></p>
<p>this is ADAS L2 V&amp;V solution, mostly in functional metric test. </p>
<h4 id="Open-Language-M-SDL"><a href="#Open-Language-M-SDL" class="headerlink" title="Open Language: M-SDL"></a><a href="https://www.foretellix.com/open-language/" target="_blank" rel="external">Open Language: M-SDL</a></h4><p>M-SDL is an open, human readable, high level language that allows to simplify the capture, reuse and sharing of scenarios, and easily specify any mix of scenarios and operating conditions to identify previously unknown hazardous core &amp; edge cases. It also allows to monitor and measure the coverage of the autonomous functionality critical to prove  ADAS &amp; AV safety, independent of tests and testing platforms. </p>
<p><img src="https://www.foretellix.com/wp-content/uploads/2019/09/new%E2%80%94screen_REPLACEMENT.jpg" alt="image"></p>
<h2 id="atlatec"><a href="#atlatec" class="headerlink" title="atlatec"></a><a href="https://www.atlatec.de/simulation.html" target="_blank" rel="external">atlatec</a></h2><p>HD map for simualtion, digitial twin of real road, integrated well with simulation suppliers, e.g. IPG, Vires, Prescan.</p>
<h2 id="ivex"><a href="#ivex" class="headerlink" title="ivex"></a><a href="https://ivex.ai/" target="_blank" rel="external">ivex</a></h2><p>provides <strong>qualitatively safety assessment of planning and decision making</strong> for all levels of ADs during development. </p>
<h4 id="safety-assessment-tool"><a href="#safety-assessment-tool" class="headerlink" title="safety assessment tool"></a><a href="https://ivex.ai/assessment_tool/" target="_blank" rel="external">safety assessment tool</a></h4><p>what is safety requirements during AD development ?</p>
<p>what’s the KPIs to represent these safety requirements ? </p>
<p>is safety requirements iterative in each functional iteration, or done once for ever ?</p>
<p>safety requirements can be validate before release, after then, when new corner cases detected, need to do safety validate automatically. so in this way, safety and function should keep in the same step.</p>
<p>the ability of safety assessment tool :</p>
<ul>
<li><p>unsafe cases and decision detection from a large amount of scenarios </p>
</li>
<li><p>a qualitative metric of safety (RSS model)</p>
</li>
<li><p>statistical analysis of risk and safety metrics </p>
</li>
</ul>
<h4 id="safety-co-pilot"><a href="#safety-co-pilot" class="headerlink" title="safety co-pilot"></a><a href="https://ivex.ai/safety_copilot/" target="_blank" rel="external">safety co-pilot</a></h4><p>guarantee safety of a planned trajectory. </p>
<p>The safety co-pilot uses the safety model to assess whether (1) a situation is safe, and (2) a planned trajectory for the next few seconds can be considered as safe, accounting for predicted movements of other objects and road users.</p>
<p>in a word, safety is big topic, but I can’t see the tech behind how Ivex solve it.</p>
<h2 id="nvidia"><a href="#nvidia" class="headerlink" title="nvidia"></a><a href="https://www.nvidia.com/en-us/self-driving-cars/" target="_blank" rel="external">nvidia</a></h2><h2 id="intel"><a href="#intel" class="headerlink" title="intel"></a><a href="https://www.intel.com/content/www/us/en/automotive/autonomous-vehicles.html" target="_blank" rel="external">intel</a></h2><h2 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h2><p>from the top ADS simulation teams, we see a few trends:</p>
<ul>
<li><p>simulation driven P&amp;P iteration</p>
</li>
<li><p>simulation driven V&amp;V </p>
</li>
</ul>
<p>can simulation be an independent tool, or it is customized and in-house services ? </p>
<p>maybe like CAE ages, in the early time, Ford/GM have their own CAE packages, later CAE tools are maintained by external suppliers. when ADS simulation is matured, there maybe few independent ADS simulation companies, like Ansys, Abaqus in CAE fields.</p>
<p>or a totally differenet story I can’t image here. </p>
<h2 id="refer"><a href="#refer" class="headerlink" title="refer"></a>refer</h2><p><a href="https://selfdriving.fyi/" target="_blank" rel="external">SelfDriving.fyi</a></p>
<p><a href="https://www.naincubator.com/" target="_blank" rel="external">north america incubator</a></p>
<p><a href="https://www.zhihu.com/question/367321729" target="_blank" rel="external">zhihu</a></p>
<p><a href="https://www.pegasusprojekt.de/en/" target="_blank" rel="external">pegasus symposium 2019</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/20/system-validation-in-l2-adas/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/09/20/system-validation-in-l2-adas/" itemprop="url">system validation in l2 adas</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-09-20T01:38:09-04:00">
                2020-09-20
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/20/system-validation-in-l2-adas/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/09/20/system-validation-in-l2-adas/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="background"><a href="#background" class="headerlink" title="background"></a>background</h2><p>from system requirements, the functional models can be created. the bottom line of ADAS is safety, which defines the safety requirements. during ADAS system validation, both function modules and safety modules should be covered. </p>
<p>my experience lay in SiL a lot. a question recently is how much percentage between SiL and HiL is a good choice?   </p>
<p>a few years early, SiL, especially world-sim, e.g. LGSVL, Carla are highly focused. the big companies said, to achive a L3+ autonmous driving system, there needs at least 10 billion miles driving test, which is almost impossible in traditional vehicle desing lifecycle, which gives a life for virtual sim driving validation.</p>
<p>which even not consider the iteration of ADAS algorithms. as if there is no mechanism to gurantee the previous road data is valid to validate the new version of algorithms, they have to collect another 10 billion miles for each algorithm version iteration. </p>
<p>but now most OEM choose the gradually evaluation way from ADAS to AD. during ADAS dev and test, Bosch has mature solutions, they don’t need 10 billion miles to validate AEB, ACC, LK kind of L2 ADAS functions, usually 1500 hrs driving data is enough, and they have ways to re-use these driving hrs as much as possible during their ADAS algorithms iteration. </p>
<p>I am thinking the difference is about function-based test and scenario-based test. </p>
<p>ADAS functions always have a few limited <code>if-else</code> internally and state machines in system-level. for function-based test, to cover all these <code>if-else</code> logic and state machines jumping, with additional safety/failure test, the ADAS system can almost gurantee to be a safe and useful product.</p>
<p>there is no need to cover all scenarios in the world for L2 ADAS system. of course, once someone did find out all physical scenarios in the world, they can define new ADAS features. and add these new features to their products.</p>
<p>in a word, L2 ADAS is a closed-requirement system, the designers are not responsible for any cases beyond the designed features.</p>
<p>For L3 AD system, the designers is responsible for any possible scenarios, which is a open-requirements system, there is no gurantee the design features is enough to cover all scenarios in real world, so which need scenario-based test and keep evaluating through OTA.</p>
<p>For L2 ADAS, OTA is not a have-to option in some way, but L3 ADAS has to OTA frequently. </p>
<p>OTA for l2 adas is to improve the performance of known features, through analysis of big driving data, but it doesn’t discovery novel features. </p>
<p>OTA for l3 adas need to improve the performance of known features, as well as to discover new features as much as possible and as quick as possible. </p>
<p>which of course bring requirement of OEM’s data platform. Tesla is currently the only OEM, who can close the data loop, from customer’s driving data, to OEM’s cloud, and OTA new/better features back to customers.</p>
<p>there is no doubt, Tesla evaluation is scenario-based. collecting scenarios is not only for validate existing systems, or test purpose, but more for discover new features, e.g. from lane/edestrain/vehicle detection to traffic light detection e.t.c.</p>
<p>the traditional OEMs still don’t know how to use scenario data valuablely, only image the collected data can do validate or calibrate a better performance known features. </p>
<h2 id="ADAS-HiL"><a href="#ADAS-HiL" class="headerlink" title="ADAS HiL"></a>ADAS HiL</h2><p>HiL helps to validate embedded software on ECUs using simulation and modeling teches. at the bottom of V model, there are software dev and test, the upper right is software/hardware integration test, namely HiL. </p>
<p>as I understand, the purpose of HiL is software and hardware integration test, and there are two main sub validation: safety requirements, and function requiements.</p>
<p>to validate safety in HiL, fault injection is used. safety module is very bottom-line, and any upper functional module is rooted from safety module. in a narraw view, fault injection only focus on known or system-defined faults, which is finite cases; in a wide view, any upper functional cases can reach to a fault injection test case, which is almost unlimited. </p>
<p>in the narraw view, coverage of functions(both function internnal state machine and across-function jump trig mechanism) is iterable, even though its total size may be hundreds of thousands. </p>
<h2 id="ADAS-massively-production-solution"><a href="#ADAS-massively-production-solution" class="headerlink" title="ADAS massively production solution"></a>ADAS massively production solution</h2><h4 id="1R1V-3R1V"><a href="#1R1V-3R1V" class="headerlink" title="1R1V(3R1V)"></a>1R1V(3R1V)</h4><p><img src="https://pic4.zhimg.com/v2-62e036891dcc3ab550d08075d733a5a0_r.jpg" alt="image"></p>
<p>Level 2 ADAS system, some OEMs called it as highway Assist(HWA), mostly provided by Tier1, e.g. Bosch. </p>
<h4 id="5R1V-5R5V"><a href="#5R1V-5R5V" class="headerlink" title="5R1V(5R5V)"></a>5R1V(5R5V)</h4><p><img src="https://pic4.zhimg.com/80/v2-488c5b081b066d209efd40d39f935398_1440w.jpg" alt="image"></p>
<p>Level 2+ ADAS system, some OEMs called it as HighWay Pilot(HWP), hidden meaning it’s L3, but in fact, not a fully L3. </p>
<h4 id="8R1V-5R12V"><a href="#8R1V-5R12V" class="headerlink" title="8R1V(5R12V)"></a>8R1V(5R12V)</h4><p><img src="https://pic3.zhimg.com/80/v2-036ba41699984687fd44fd1cb1614935_1440w.jpg" alt="image"></p>
<p>camera-priority solution, used in Tesla and Mobileye. </p>
<h2 id="L2-ADAS-system-validation"><a href="#L2-ADAS-system-validation" class="headerlink" title="L2 ADAS system validation"></a>L2 ADAS system validation</h2><p>from traditional vehicle system test and validation, there are finite cases, e.g. ESP interfaces. for ADAS system validation, which is scenario based, and mostly there are infinite cases.</p>
<p>there are different ways to cover ADAS system validation:</p>
<ul>
<li>fault injection test, the vehicle powertrain, ADAS sensors, ADAS SoC/MCU, all these HW has random probability to fail. </li>
</ul>
<h4 id="Fault-Injection"><a href="#Fault-Injection" class="headerlink" title="Fault Injection"></a>Fault Injection</h4><p>fault injection tests is used to increase the test coverage of Safety Requirements. Within the fault injection tests arbitrary errors are introduced into the system to proof the safety mechanisms that have been encoded in the software to examine. fault injection tests is only a subset of Requirements based testing. </p>
<p>ISO 26262-4 [System] describes the Fault Injection Test as follows:<br>The test uses special means to introduce faults into the item. This can be done within the item via a special test interface or specially prepared elements or communication devices. The method is often used to improve the test coverage of the safety requirements, because during normal operation safety mechanisms are not invoked.</p>
<p>The ISO 26262-4 [System] defines the fault injection test as follows: Fault Injection Test includes injection of <code>arbitrary faults</code> in order to test safety mechanisms (e.g. corrupting software or hardware components, corrupting values of variables, by introducing code mutations, or by corrupting values of CPU registers). <code>arbitrary faults</code> is actually from a known list of errors.</p>
<p>fault injection is <a href="https://users.ece.cmu.edu/~koopman/des_s99/fault_injection/index.html" target="_blank" rel="external">good at testing known sorts of bugs or defect</a>, but poor at testing novel faults or defects, which are precisely the sorts of defects we would want to discover. therefore, fault injection in ADAS is to verify the designed safety mechanism/responses. </p>
<p>to verfication of the system. if an ADAS system is designed to tolerate a certain class of faultss, then these faults can be directly injected into the system to examine their responses. for errors which is too infrequent to effectively test in the field, fault injection is powerful to acclerate the occurence of faults.</p>
<p>in summary, fault injection is more verification tool, rather than a tool to improve performance or find novel design faults. </p>
<h4 id="software-verification-and-validation"><a href="#software-verification-and-validation" class="headerlink" title="software verification and validation"></a>software verification and validation</h4><p>verification is about whether there is the functions as required. validation is about how good the functions are as required. verfication tech includes: dynamic testing and static testing. e.g. funcitonal test, random test;  validation tech includes: (h/sw) fault injection, dependency analysis, hazard analysis, risk analysis e.t.c. </p>
<p>the software verification is usually a combination of review, analyses, and test. review and analyses are performed on the following components:</p>
<ul>
<li>requirement analysis </li>
<li>software arch </li>
<li>source code </li>
<li>outputs of integration process</li>
<li>test cases and their procedures and results </li>
</ul>
<p>for test is to demonstrate it satisfies all requirements and to demonstrate that errors leading to unacceptable failure conditions has safe strategies. usually including:</p>
<ul>
<li>h/sw integration test: to verify the software is operating correctly in the hardware </li>
<li>software integration test </li>
<li>low-level test</li>
</ul>
<h2 id="CANape"><a href="#CANape" class="headerlink" title="CANape"></a>CANape</h2><h4 id="measurement"><a href="#measurement" class="headerlink" title="measurement"></a>measurement</h4><ul>
<li><p>device plugin into CANape box under a special channel group</p>
</li>
<li><p>the signals need recorded </p>
</li>
<li><p>triger strategy to start recording </p>
</li>
</ul>
<h4 id="calibration"><a href="#calibration" class="headerlink" title="calibration"></a>calibration</h4><h4 id="visulization"><a href="#visulization" class="headerlink" title="visulization"></a>visulization</h4><h2 id="CANoe"><a href="#CANoe" class="headerlink" title="CANoe"></a>CANoe</h2><h2 id="refer"><a href="#refer" class="headerlink" title="refer"></a>refer</h2><p><a href="https://zhuanlan.zhihu.com/p/139222892" target="_blank" rel="external">ADAS/AD dev: L2+ ADAS/AD sensor arch</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/83822903" target="_blank" rel="external">ADAS/AD dev: SoC chips solution</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/163732559" target="_blank" rel="external">ADAS/AD dev: massive production solutions</a></p>
<p><a href="https://www.ni.com/en-us/innovations/white-papers/09/using-fault-insertion-units--fius--for-electronic-testing.html" target="_blank" rel="external">using Fault Insertion Units for electronic testing</a></p>
<p><a href="http://blog.heicon-ulm.de/iso26262-fault-injection-test-do-you-really-need-it/" target="_blank" rel="external">Fault injection test in ISO 26262 – Do you really need it</a></p>
<p><a href="https://www.researchgate.net/publication/290851811_Fault_Injection_in_the_Automotive_Standard_ISO_26262_An_Initial_Approach" target="_blank" rel="external">paper: Fault Injection in automotive standard ISO 26262: an initial approach</a></p>
<p><a href="https://users.ece.cmu.edu/~koopman/des_s99/fault_injection/index.html" target="_blank" rel="external">fault injection from CMU EE</a></p>
<p><a href="https://users.ece.cmu.edu/~koopman/des_s99/verification/" target="_blank" rel="external">verfication/validation/certification from CMU EE</a></p>
<p><a href="https://www.testandmeasurementtips.com/challenges-hil-testing-adas/" target="_blank" rel="external">the challenege of ADAS HiL</a></p>
<p><a href="https://ipg-automotive.com/fileadmin/user_upload/content/Download/PDF/Events/Apply_Innovate_2018/Presentations/Apply_and_Innovate_2018_HyundaiAutron_Konrad_Song_Lee.pdf" target="_blank" rel="external">integrated ADAS HiL system with the combination of CarMaker and various ADAS test benches</a></p>
<p><a href="https://assets.vector.com/cms/content/events/2020/Webinars20/Vector_Webinar_Online_Offline_ADAS_ECU.pdf" target="_blank" rel="external">Vector: online and offline validation of ADAS ECUs</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/18/adas-data-logging-solution-know-how/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/18/adas-data-logging-solution-know-how/" itemprop="url">adas data logging solution know how</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-18T09:48:19-04:00">
                2020-08-18
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/18/adas-data-logging-solution-know-how/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/08/18/adas-data-logging-solution-know-how/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Data replay offers an excellent way to analyze driving scenarios and verify simulations based on real-world data. This can be done with HIL systems as well as with data logging systems that offer a playback mechanism and software to control the synchronized playback. Captured data can be replayed in real time or at a slower rate to manipulate and/or monitor the streamed data.</p>
<p>An open, end-to-end simulation ecosystem can run scenarios through simulations via a closed-loop process.</p>
<p><a href="https://www.vector.com/int/en/news/news/logging-challenges-adas-sensordata/" target="_blank" rel="external">overcoming logging challenges in ADAS dev</a></p>
<p><a href="https://assets.vector.com/cms/content/events/2019/VA/VECO19/Day_2/ADAS_Data_Logging_Solution_-_Yuchen_Yang.pdf" target="_blank" rel="external">pdf: ada logging solution from Vector</a></p>
<p><a href="https://www.ni.com/zh-cn/innovations/automotive/advanced-driver-assistance-systems/adas-datalogger.html" target="_blank" rel="external">confidently record raw ADAS sensor data for drive tests from NI</a></p>
<p><a href="https://assets.vector.com/cms/content/events/2020/Webinars20/Vector_Webinar_Online_Offline_ADAS_ECU.pdf" target="_blank" rel="external">online and offline validation of ADAS ECUs</a></p>
<p><a href="https://assets.vector.com/cms/content/know-how/_technical-articles/ADAS_Recording_Elektronikautomotive_201703_PressArticle_EN.pdf" target="_blank" rel="external">pdf: data recording for adas development from Vector</a></p>
<p><a href="https://assets.vector.com/cms/content/know-how/_technical-articles/Ethernet_Timesync_Automobil-Elektronik_201608_PressArticle_EN.pdf" target="_blank" rel="external">pdf: time sync in automotive Ethernet</a></p>
<p><a href="https://www.mobileye.com/us/fleets/technology/" target="_blank" rel="external">mobileye fleets solutions</a></p>
<p><a href="https://blackberry.qnx.com/content/dam/qnx/products/adas/adas-product-brief.pdf" target="_blank" rel="external">pdf: QNX platform for ADAS 2.0</a></p>
<p><a href="https://hackernoon.com/time-synchronization-in-modular-collaborative-robots-d4c218fcb66d" target="_blank" rel="external">time sync in modular collaborative robots</a></p>
<p><a href="https://www.dellemc.com/resources/en-us/asset/white-papers/products/storage/dell-emc-adas-solution-powered-by-isilon-wp.pdf" target="_blank" rel="external">pdf: solving storage conundrum in ADAS development and validation</a></p>
<p><a href="https://www.dspace.com/en/pub/home/applicationfields/our_solutions_for/driver_assistance_systems/data_driven_development/data_replay/adas-ad_platforms.cfm" target="_blank" rel="external">validation of ADAS platforms(ECUs) with data replay test from dSPACE</a></p>
<p><a href="https://www.dspace.com/en/pub/home/products/sw/impsw/rtmaps.cfm" target="_blank" rel="external">RTMaps from dSpace</a></p>
<p><a href="https://www.vector.com/int/en/products/products-a-z/software/vadasdeveloper/" target="_blank" rel="external">vADASdeveloper from vector</a></p>
<p><a href="https://www.microcontrollertips.com/the-data-driven-roadto-automated-driving-faq/" target="_blank" rel="external">date driven road to automated driving</a></p>
<p><a href="https://releases.asam.net/OpenSCENARIO/2.0-concepts/ASAM_OpenSCENARIO_2-0_Concept_Paper.html" target="_blank" rel="external">ASAM OpenSCENARIO doc</a></p>
<p><a href="https://www.dspace.com/en/pub/home/applicationfields/our_solutions_for/driver_assistance_systems/hil_simulation/open_loop_hil_testing_of_image.cfm#144_35505" target="_blank" rel="external">open loop HiL for testing image processing ECUs</a></p>
<p><a href="https://github.com/OpenSimulationInterface" target="_blank" rel="external">github: open simulation interface</a></p>
<p><a href="https://www.pegasusprojekt.de/files/tmpl/Pegasus-Abschlussveranstaltung/20_Sensor_Models.pdf" target="_blank" rel="external">sensor models from Pegasus</a></p>
<p><a href="https://www.pegasusprojekt.de/en/subproject-1" target="_blank" rel="external">scenario analysis and quality measures from Pegasus</a> </p>
<p><a href="https://www.pegasusprojekt.de/files/tmpl/Pegasus-Abschlussveranstaltung/PEGASUS-Gesamtmethode.pdf" target="_blank" rel="external">pdf: Pegasus method an overview</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/18/autosar-know-how/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/18/autosar-know-how/" itemprop="url">autosar know-how</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-18T09:42:19-04:00">
                2020-08-18
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/18/autosar-know-how/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/08/18/autosar-know-how/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>the following are knowledges from Internet, if copyright against, please contact me. </p>
<h2 id="autosar-微控制器抽象层-MCAL"><a href="#autosar-微控制器抽象层-MCAL" class="headerlink" title="autosar: 微控制器抽象层 MCAL"></a><a href="https://blog.csdn.net/ChenGuiGan/article/details/80310713" target="_blank" rel="external">autosar: 微控制器抽象层 MCAL</a></h2><h4 id="微控制器驱动"><a href="#微控制器驱动" class="headerlink" title="微控制器驱动"></a>微控制器驱动</h4><ul>
<li><p>GPT Driver</p>
</li>
<li><p>WDG Driver</p>
</li>
<li><p>MCU Driver </p>
</li>
<li><p>Core test </p>
</li>
</ul>
<h4 id="存储器驱动"><a href="#存储器驱动" class="headerlink" title="存储器驱动"></a>存储器驱动</h4><h4 id="通信驱动"><a href="#通信驱动" class="headerlink" title="通信驱动"></a>通信驱动</h4><ul>
<li><p>Ethernet驱动</p>
</li>
<li><p>FlexRay 驱动</p>
</li>
<li><p>CAN 驱动</p>
</li>
<li><p>LIN 驱动</p>
</li>
<li><p>SPI 驱动</p>
</li>
</ul>
<h4 id="I-O驱动"><a href="#I-O驱动" class="headerlink" title="I/O驱动"></a>I/O驱动</h4><h2 id="AUTOSAR：基础软件层"><a href="#AUTOSAR：基础软件层" class="headerlink" title="AUTOSAR：基础软件层"></a><a href="https://blog.csdn.net/ChenGuiGan/article/details/80305190" target="_blank" rel="external">AUTOSAR：基础软件层</a></h2><p>AUTOSAR软件体系结构包含了完全独立于硬件的应用层（Application Layer）和与硬件相关的基础软件层（BasicSoftware,BSW），并在两者中间设立了一个运行时环境（Run Time Environment），从而使两者分离，形成了一个分层体系架构。</p>
<h4 id="基础软件层组件"><a href="#基础软件层组件" class="headerlink" title="基础软件层组件"></a>基础软件层组件</h4><ul>
<li><p>系统，提供标准化(os, timer, error)规定和库函数</p>
</li>
<li><p>内存，对内、外内存访问入口进行标准化</p>
</li>
<li><p>通信，对汽车网络系统、ECU间、ECU内的通信访问入口进行标准化</p>
</li>
<li><p>I/O， 对传感器、执行器、ECU的IO进行标准化</p>
</li>
</ul>
<h2 id="服务层与复杂驱动"><a href="#服务层与复杂驱动" class="headerlink" title="服务层与复杂驱动"></a><a href="https://blog.csdn.net/ChenGuiGan/article/details/80380054" target="_blank" rel="external">服务层与复杂驱动</a></h2><h4 id="系统服务"><a href="#系统服务" class="headerlink" title="系统服务"></a>系统服务</h4><p>比如， os定时服务、错误管理。为应用程序和基础软件模块提供基础服务。</p>
<h4 id="存储器服务"><a href="#存储器服务" class="headerlink" title="存储器服务"></a>存储器服务</h4><h4 id="通信服务"><a href="#通信服务" class="headerlink" title="通信服务"></a>通信服务</h4><p>通信服务通过通信硬件抽象与通信驱动程序进行交互</p>
<h4 id="复杂驱动"><a href="#复杂驱动" class="headerlink" title="复杂驱动"></a>复杂驱动</h4><p>复杂驱动（CCD）层跨越于微控制器硬件层和RTE之间，其主要任务是整合具有特殊目的且不能用MCAL进行配置的非标准功能模块。复杂驱动程序跟单片机和ECU硬件紧密相关。</p>
<h2 id="Autosar-time-sync"><a href="#Autosar-time-sync" class="headerlink" title="Autosar time  sync"></a>Autosar time  sync</h2><h4 id="11-Time-sync"><a href="#11-Time-sync" class="headerlink" title="11 Time sync"></a><a href="https://blog.csdn.net/sky8336/article/details/91355471" target="_blank" rel="external">11 Time sync</a></h4><p>对于自适应平台，考虑了以下三种不同的技术来满足所有必要的时间同步需求：</p>
<ul>
<li><p>经典平台的StbM</p>
</li>
<li><p>库chrono -要么std::chrono (c++ 11)，要么boost::chrono</p>
</li>
<li><p>时间POSIX接口</p>
</li>
</ul>
<p>TBRs充当时间基代理，提供对同步时间基的访问。通过这样做，TS模块从“真实的(real)”时基提供者中抽象出来。</p>
<h4 id="autoSar-time-sync-protocol-specification"><a href="#autoSar-time-sync-protocol-specification" class="headerlink" title="autoSar: time sync protocol specification"></a><a href="https://www.autosar.org/fileadmin/user_upload/standards/foundation/19-11/AUTOSAR_PRS_TimeSyncProtocol.pdf#:~:text=%20%20%20Title%20%20%20Time%20Synchronization,Created%20Date%20%20%2011%2F21%2F2019%2010%3A06%3A48%20AM%20" target="_blank" rel="external">autoSar: time sync protocol specification</a></h4><p>Precision Time Protocol (PTP)</p>
<p>generalized Precision Time Protocol (gPTP)</p>
<p>Time Synchronization over Ethernet, IEEE802.1AS</p>
<p>time master: is an entity which is the master for a certain Time Base and which propagates this Time Base to a set of Time Slaves within a certain segment of a communication network. If a Time Master is also the owner of the Time Base then he is the Global Time master. </p>
<p>time slave: is the recipient for a certain Time Base within a certain<br>segment of a communication network, being a consumer for this Time Base</p>
<p>time measurement with Switches:</p>
<p>in a time aware Ethernet network, HW types of control unit exists:</p>
<ul>
<li><p>Endpoints directly working on a local Ethernet-Controller</p>
</li>
<li><p>Time Gateways, time aware bridges, where the local Ethernet-Controller connects to an external switch device.  A Switch device leads to additional delays, which have to be considered for the calculation of the corresponding Time Base</p>
</li>
</ul>
<h4 id="specification-of-time-sync-over-Ethernet"><a href="#specification-of-time-sync-over-Ethernet" class="headerlink" title="specification of time sync over Ethernet"></a><a href="https://www.autosar.org/fileadmin/user_upload/standards/classic/4-3/AUTOSAR_SWS_TimeSyncOverEthernet.pdf" target="_blank" rel="external">specification of time sync over Ethernet</a></h4><p>Global Time Sync over Ethernet(EthTSyn) interface with:</p>
<ul>
<li><p>Sync time-base manager(StbM), get and set the current time value</p>
</li>
<li><p>Ethernet Interface(EthIf), receiving and transmitting messages</p>
</li>
<li><p>Basic Software Mode Manager(BswM), coord of network access</p>
</li>
<li><p>Default Error Tracer(DET), report of errors </p>
<p>A time gateway typically consists of one Time Slave and one or more Time<br>Masters.  When mapping time entities to real ECUs, an ECU could be Time Master (or even Global Time Master) for one Time Base and Time Slave for another Time Base.</p>
</li>
</ul>
<h4 id="time-sync-in-automotive-Ethernet"><a href="#time-sync-in-automotive-Ethernet" class="headerlink" title="time sync in automotive Ethernet"></a><a href="https://assets.vector.com/cms/content/know-how/_technical-articles/Ethernet_Timesync_Automobil-Elektronik_201608_PressArticle_EN.pdf" target="_blank" rel="external">time sync in automotive Ethernet</a></h4><p>The principal methods for time synchronization in the automotive industry are currently based on AUTOSAR 4.2.2, IEEE 802.1AS, and the revised IEEE 802.1AS-ref, which was developed by the Audio/Video Bridging Task Group, which is now known as the TSN (Time Sensitive Networking) Task Group.</p>
<p>The type of network determines the details of the synchronization process. For example, with CAN and Ethernet, the Time Slave corrects the received global time base by comparing the time stamp from the transmitter side with its own receive time stamp. With FlexRay, the synchronization is simpler because FlexRay is a deterministic system with fixed cycle times that acts in a strictly predefined time pattern. The time is thus implicitly provided by the FlexRay clock. While the time stamp is always calculated by software in CAN, Ethernet allows it to be calculated by either software or hardware</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/18/mcu-know-how/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/18/mcu-know-how/" itemprop="url">mcu know-how</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-18T09:35:58-04:00">
                2020-08-18
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/18/mcu-know-how/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/08/18/mcu-know-how/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="basic-knowledge"><a href="#basic-knowledge" class="headerlink" title="basic knowledge"></a>basic knowledge</h2><h4 id="SPI-protocol"><a href="#SPI-protocol" class="headerlink" title="SPI protocol"></a>SPI protocol</h4><p>SPI, Serial Peripheral Interface。使MCU与各种外围设备以串行方式进行通信以交换信息。<br>SPI总线可直接与各个厂家生产的多种标准外围器件相连，包括FLASHRAM、网络控制器、LCD显示驱动器、A/D转换器和MCU等。</p>
<p>SPI接口主要应用在EEPROM、FLASH、实时时钟、AD转换器， ADC、 LCD 等设备与 MCU 间，还有数字信号处理器和数字信号解码器之间，要求通讯速率较高的场合。</p>
<h4 id="TAPI-protocol"><a href="#TAPI-protocol" class="headerlink" title="TAPI protocol"></a>TAPI protocol</h4><p>TAPI（电话应用程序接口）是一个标准程序接口，它可以使用户在电脑上通过电话或视频电话与电话另一端的人进行交谈。TAPI还具备一个服务提供者接口（SPI），它面向编写驱动程序的硬件供应商。TAPI动态链接库把API映射到SPI上，控制输入和输出流量。 </p>
<h2 id="MCU-timing"><a href="#MCU-timing" class="headerlink" title="MCU timing"></a>MCU timing</h2><p>Software design is easy when the processor can provide far more computing time than the application needs. in MCU, the reality is often the opposite case. the following are some basic know-how, before we can jump into ADAS MCU/SOC issues.</p>
<h4 id="scheduling-sporadic-and-aperiodic-events-in-a-hard-real-time-system"><a href="#scheduling-sporadic-and-aperiodic-events-in-a-hard-real-time-system" class="headerlink" title="scheduling sporadic and aperiodic events in a hard real-time system"></a><a href="https://pdfs.semanticscholar.org/926b/1a5e44a87bdaa979e98608650821fa35f79c.pdf" target="_blank" rel="external">scheduling sporadic and aperiodic events in a hard real-time system</a></h4><p>A common use of periodic tasks is to process sensor data and update the current state of the real-time system on a regular basis. </p>
<p> Aperiodic tasks are used to handle the processing requirements of random events such as operator requests. An aperiodic task typically has a soft deadline. Aperiodic tasks that have hard deadlines are called sporadic tasks.</p>
<p> Background servicing of aperiodic requests occurs whenever the processor is idle (i.e., not executing any periodic tasks and no periodic tasks are pending).  If the load of the periodic task set is high, then utilization left for background service is low, and background service opportunities are relatively infrequent. However, if no aperiodic requests are pending, the polling task suspends itself until its next period, and the time originally allocated for aperiodic service is not preserved for aperiodic execution but is instead used by periodic tasks</p>
<h4 id="foreground-background-scheduling"><a href="#foreground-background-scheduling" class="headerlink" title="foreground-background scheduling"></a><a href="https://www.geeksforgeeks.org/foreground-background-scheduling/" target="_blank" rel="external">foreground-background scheduling</a></h4><ul>
<li><p>periodic tasks are considered as foreground tasks</p>
</li>
<li><p>sporadic and aperiodic tasks are considered as background tasks</p>
<p>foreground tasks have the highest priority and the bc tasks have lowest priority. among all highest priority, the tasks with highest priority is scheduled first and at every scheduling point, highest priority task is scheduled for execution. only when all foreground tasks are scheduled, bc task are scheduled. </p>
</li>
<li><p>completion time for foreground task</p>
</li>
</ul>
<p>for fg task, their completion time is same as the absolute deadline.</p>
<ul>
<li>completion time for background task </li>
</ul>
<p>when any fg task is being excuted, bc task await.</p>
<p>let Task <strong>Ti</strong> is fg task, <strong>Ei</strong> is the amount of processing time required over every <strong>Pi</strong> period. Hence，</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Avg. CPU utilization for Ti is Ei/Pi</div></pre></td></tr></table></figure>
<p>if there are <strong>n</strong> periodic tasks(fg tasks), e.g. T1, T2, … Tn </p>
<p>then total avg CPU utilization for fg taskes:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">fg_cpu_util = E1/P1 + E2/P2 + ... + En/Pn</div></pre></td></tr></table></figure>
<p>then the avg time available for execution of bg task in every unit of time is:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">1 - fg_cpu_util</div></pre></td></tr></table></figure>
<p>let <strong>Tb</strong> is bg task, <strong>Eb</strong> is the required processing time, then the completion time of bg task:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">=  Eb / (1 - fg_cpu_util)</div></pre></td></tr></table></figure>
<p>in ADAS system, usually there exist bost periodic tasks(fg) and aperiodic tasks(bc), and they are corelated, fg tasks always have higher priority than bc tasks. so there is chance when a certain fg task rely on output of another bc task, which is not or partially updated due to executing priority, then there maybe some isues.</p>
<h2 id="refer"><a href="#refer" class="headerlink" title="refer"></a>refer</h2><p><a href="https://assets.vector.com/cms/content/events/2019/VH/VIC2019/Track_4_3_Functional_Safety_and_ECU_Implementation.pdf" target="_blank" rel="external">Vector: Functional safety and ECU implementation</a></p>
<p><a href="https://www.eetimes.com/autosar-os-measures-task-execution-times/" target="_blank" rel="external">autosar OS measures task execution times</a></p>
<p><a href="https://www.sohu.com/a/298859329_257861" target="_blank" rel="external">3min看懂mcu</a></p>
<p><a href="https://developer.51cto.com/art/202008/623049.htm" target="_blank" rel="external">设计定时任务系统</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/08/18/verfication-and-validation-in-ADAS-dev/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/08/18/verfication-and-validation-in-ADAS-dev/" itemprop="url">verfication and validation in ADAS dev</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-08-18T09:32:44-04:00">
                2020-08-18
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/08/18/verfication-and-validation-in-ADAS-dev/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/08/18/verfication-and-validation-in-ADAS-dev/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Verification-and-Validation-in-V-model"><a href="#Verification-and-Validation-in-V-model" class="headerlink" title="Verification and Validation in V-model"></a>Verification and Validation in V-model</h2><h4 id="verification"><a href="#verification" class="headerlink" title="verification"></a>verification</h4><ul>
<li>whether the software conforms the specification </li>
<li>finds bugs in dev </li>
<li>output is software arch e.t.c </li>
<li>QA team does verification and make sure the software matches requirements in SRS.</li>
<li>it comes before validation </li>
</ul>
<h4 id="validation"><a href="#validation" class="headerlink" title="validation"></a>validation</h4><ul>
<li>it’s about test, e.g.  black box test, white box test, non-functional test</li>
<li>it can find bugs which is not catched by verification </li>
<li>output is an actual product </li>
</ul>
<p><a href="https://www.professionalqa.com/v-model" target="_blank" rel="external">V-model is an extension of waterfull model</a>. The phases of testing are categorised as “Validation Phase” and that of development as “Verification Phase”</p>
<h4 id="how-simulation-helps"><a href="#how-simulation-helps" class="headerlink" title="how simulation helps ?"></a>how simulation helps ?</h4><ul>
<li>for validation to cover known and rara critical scenarios. </li>
<li>for verification to test whether the component function as expected</li>
</ul>
<h2 id="model-based-to-data-driven"><a href="#model-based-to-data-driven" class="headerlink" title="model based to data driven"></a>model based to data driven</h2><table>
<thead>
<tr>
<th>methodlogy</th>
<th>completeness</th>
<th>known</th>
<th>0-error-gurantee</th>
<th>iterable</th>
<th>example</th>
</tr>
</thead>
<tbody>
<tr>
<td>model based</td>
<td>1</td>
<td>1</td>
<td>1</td>
<td>0</td>
<td>NASA</td>
</tr>
<tr>
<td>data driven</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>Tesla Motor</td>
</tr>
</tbody>
</table>
<p>with traditionally vehicle/airspace development, the system team first <strong>clearly</strong> define <strong>all requirements</strong> from different stakeholders and different departments, which may <strong>take a long time</strong>; then split to <strong>use cases</strong>, which is garanteed to be complete and all-known set, and <strong>garantee zero-error</strong>, the engineers just make sure each new development can meet each special verification. the general product design cycle is <strong>3 ~ 5 years</strong>, and once it release to market, there is little chance to upgrade, except back to dealer shops.</p>
<p>model based mindset need to control everything at the very beginning, to build a clear but validatable super complex system at very first, even it takes long long time. and the development stage can be a minor engineering process with a matured project driven management team. </p>
<p>the goods of model based mindset is it strongly gurantee known requirements(including safety) is satisfied, while the drawback is it lose flexibility, slow response to new requirements, which means lose market at end.</p>
<p>to validate model based design ADS system, usually it highlights the full-cover or completeness of test cases, which usually can be pre-defined in semantic format(.xml) during system requirement stage. then using a validation system(e.g. a simulator) to parse the semantic test cases, and produce, run and analysis the test scenarios automatically.</p>
<p>in data driven ADS system, the system verification and validation strongly depends on <strong>valid data</strong>. </p>
<p>1) data quantity and quality. as the data set can cover as many as plenty kinds of different scenarios, it’s high qualitied； while if the data set have millions frames of single lane high way driving, it doesn’t teach the (sub)system a lot really.</p>
<p>2) failure case data, which is most valueable during dev. usually the road test team record the whole data from sensor input to control output, as well as many intermediate outputs. what means a <strong>failure case</strong>, is the (sub)system (real) output doesn’t correspond to expected (ideal) output, which is a clue saying something wrong or miss-handled of the current-version ADS system. of course, there are large mount of <strong>normal case</strong> data.</p>
<p>3) ground truth(G.T.) data, to tell the case as either normal or failure, needs an evaluation standard, namely <strong>GT  data</strong>. there are different ways to get GT data in RD stage and massive-producing stage. in RD stage, we can build a GT data collecting vehicle, which is expensive but highly-valued, of course it’s better to automatically generate G.T. data, but manually check is almost a mandatory. a low-efficient but common way to get GT data by testing driver’s eye. after data collection, usually there is off-line data processing with the event log by the driver. so the offline processing can label scenarios as <strong>normal case</strong> or <strong>failure case</strong>, usually we care more about <strong>failure case</strong>. in massive-producing stage, there is no GT data collecting hardware, but there is massive data source to get a very high-confidence classifer of failure or normal. </p>
<p>4) sub-system verification, is another common usage of data, e.g. fusion module, AEB module, e.t.c. due to the limitation of existing sensor model and realistic level of SiL env, physical sensor raw data is more valued to verify the subsystem, which including more pratical sensor parameters, physical performance, physical vehicle limitation e.t.c, compared to synthetic sensor data from simulator, which is either ideal or statistically equal, or too costing to reach physical-level effect. </p>
<p>5) AI model training, which consume huge data. in RD stage, is difficult to get that much of road data. so synthetic data is used a lot, but has to mixed a few portion of physical road data to gurantee no over-fit with semi-data. on the other hand, tha’s a totally different story if someone can obtain data from massive-producing fleet, as <a href="https://patentscope2.wipo.int/search/en/detail.jsf?docId=WO2020056331&amp;tab=PCTBIBLIO" target="_blank" rel="external">Telsa patented:SYSTEM and METHOD for obtaining training data</a>: An example method includes receiving sensor and applying a neural network to the sensor data. A trigger classifier is applied to an intermediate result of the neural network to determine a classifier score for the sensor data. Based at least in part on the classifier score, a determination is made whether to transmit via a computer network at least a portion of the sensor data. Upon a positive determination, the sensor data is transmitted and used to generate training data. </p>
<p>which is really an AI topic to learn from massive sensor data to understand a failure case. </p>
<p>6) AI model validation, validation should depends on labeled valid dataset, e.g. G.T. data, or data verified from existing system, e.g. some team trust mobileyes output as G.T. data. </p>
<p>7) (sub)system validation</p>
<h2 id="SiL-sematic-driven"><a href="#SiL-sematic-driven" class="headerlink" title="SiL sematic driven"></a>SiL sematic driven</h2><p>this mostly correspond to model based dev, there are a few issues about sematic driven SiL: </p>
<p>1) build realistic-close sensor model, but how realistic it is compared to the real physical sensor ?  80% ?</p>
<p>2) virtual env from the SiL simulator, based on the virtual modeling ability. </p>
<p>3)  1) + 2) –&gt;  synthetic sensor raw data, which may have about 60%~80% realistic, compared to road test recording data</p>
<p>4) is there system bias of virtual/synthetic world ?  </p>
<p>during RD road test, we can record the failure scenario as semantic metadata(such as kind of OpenX/Python script), as well record the whole sensor &amp; CAN data.</p>
<p>with semantic metadata, we import it to the SiL simulator, inside which create a virtual world of the senario. if the sensor configuration (include both intrinsic and extrinsic) in simulator is the same as the configurations in real test vehicles, and our sensor model in simulator can behave statistically equal to the real sensors, check <a href="">sensor statistical pars</a>, so it’s almost a satistically realistic sensor model. </p>
<p>sematic scenario description framework(SSDF) is a common way to generate/manage/use verification(functional and logic) scenarios libs and validation (concrete) scenarios libs. the benefits about SSDF is a natural extension of V-model, after define system requirements, and generate test cases based on each user case, namely sematic scenarios. </p>
<p>but as we mentioned above, how precision the SiL performance and especially when comes to statiscally equal sensor model, namely, how to validate the accuracy loss or even reliability loss gap between synthetic and real envs, which is usually not considered well in sematic scenario based SiL. </p>
<p>no doubt, synthetic data, or pure semantic scenario has its own benefits, namely fully labeled data, which can be used to as <strong>ground truth</strong> in virutal world or as input for AI training. again, we need to confirm how much realiabitliy these labeled data are, before we can 100% trust them.</p>
<p>Ideal ground truth/probabilistic sensor models are typically validated via software-in-the-loop (SIL) simulations. </p>
<p>Phenomenological/physical sensor models are physics-based. They are based on the measurement principles of the sensor (i.e. camera uptakes, radar wave propagation) and play a role simulating phenomena such as haze, glare effects or precipitation. They can generate raw data streams, 3-D point clouds, or target lists.</p>
<h2 id="sensor-statistically-evaluation"><a href="#sensor-statistically-evaluation" class="headerlink" title="sensor statistically evaluation"></a>sensor statistically evaluation</h2><ul>
<li><p>sensor accuracy model, kind of obeying <strong>exponential distribution</strong>, along side with the distance in x-y plane. further the sensor accuracy is speed、scenario etc depends. </p>
</li>
<li><p>sensor detection realiability(including false detection, missing detection), kind of obeying <strong>normal distribution</strong> , further can speicify obstacle detection realiability and lane detection realiability. </p>
</li>
<li><p>sensor type classification realiability, kind of <strong>normal distribution</strong></p>
</li>
<li><p>sensor object tracking realiability, kind of <strong>normal distribution</strong> </p>
</li>
<li><p>vendor nominal intrinsic, there is always a gap from vendor nominal intrinsic to the sensor real performance. e.g. max/min detection distance, FOV, angle/distance resolution ratio e.t.c. so we can use the test-verified sensor parameters as input for sensor model, rather than the vendor nominal parameters. </p>
</li>
</ul>
<p>as mentioned, there are lots of other factors to get a statistically equal sensor model, which can be considered iteration by iteration.</p>
<p>the idea above is a combination of statistical models, if there is a way to collect sensor data massively, a data-driven machine learning model should be better than the combination of statistical models. </p>
<h2 id="data-is-the-new-oil"><a href="#data-is-the-new-oil" class="headerlink" title="data is the new oil"></a>data is the new oil</h2><p>at the first stage, we see lots of public online data set, especially for perception AI training, from different companies e.g. Cognata, Argo AI, Cruise, Uber, Baidu Apollo, Waymo, Velodyne e.t.c. </p>
<p>for a while, the roadmap to AI model/algorithms is reached by many teams, the real gap between a great company and a demo team, is gradually in build a massive data collection pipeline, rather than simply verify the algorithm works. the difference is between Tesla and the small AI team. </p>
<p>this will be a big jump from traidional model based mindset to data-driven mindset, including data driven algorithm as well as data pipeline.</p>
<p>in China, the data center/cloud computing/5G is called <strong>new infrastructure</strong>, which definitely accelerate the pocessing of building up the data pipline from massively fleet. </p>
<h2 id="refere"><a href="#refere" class="headerlink" title="refere"></a>refere</h2><p><a href="https://www.guru99.com/verification-v-s-validation-in-a-software-testing.html" target="_blank" rel="external">difference of V vs V</a></p>
<p><a href="https://radenso.com/blogs/radar-university/what-are-false-alerts-on-a-radar-detector" target="_blank" rel="external">what are false alerts on a radar detector</a></p>
<p><a href="https://deepai.org/publication/surfelgan-synthesizing-realistic-sensor-data-for-autonomous-driving" target="_blank" rel="external">surfelGAN: synthesizing realistic sensor data for AD from DeepAI</a></p>
<p><a href="https://www.microcontrollertips.com/data-injection-testing-autonomous-sensors-through-realistic-simulation/" target="_blank" rel="external">data injection test of AD through realistic simulation</a></p>
<p><a href="https://www.avsimulation.com/" target="_blank" rel="external">avsimulation</a></p>
<p><a href="https://www.bmw.com/en/innovation/the-development-of-self-driving-cars.html" target="_blank" rel="external">BMW: development of self driving cars</a></p>
<p><a href="https://understand.ai/" target="_blank" rel="external">understand.AI. a dSPACE company</a></p>
<p> <a href="https://www.cybertrucktalk.com/threads/tesla-files-patent-for-sourcing-self-driving-training-data-from-its-vehicles.139/" target="_blank" rel="external">cybertruck talk</a> </p>
<p> <a href="https://teslamotorsclub.com/tmc/threads/tesla-files-patent-for-sourcing-self-driving-training-data-from-its-fleet.189145/" target="_blank" rel="external">tesla club</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/07/mf4-know-how/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="David Z.J. Lee">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Serious Autonomous Vehicles">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/07/07/mf4-know-how/" itemprop="url">mf4 know how</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-07T08:51:49-04:00">
                2020-07-07
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/07/07/mf4-know-how/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2020/07/07/mf4-know-how/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="preparation"><a href="#preparation" class="headerlink" title="preparation"></a>preparation</h2><h4 id="pip-reinstall"><a href="#pip-reinstall" class="headerlink" title="pip reinstall"></a>pip reinstall</h4><ul>
<li><p>uninstall current pip </p>
</li>
<li><p>apt-get install python-pip  #which install the default 8.1 version</p>
</li>
<li><p>sudo -H pip2 install –upgrade pip  #which upgrade to 20.1 version</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install --install-option=<span class="string">"--prefix=<span class="variable">$PREFIX_PATH</span>"</span> package_name</div></pre></td></tr></table></figure>
<p><a href="https://github.com/pypa/pip/issues/4754" target="_blank" rel="external">why does pip3 say I am using v8.1.1, however version 20.1.1 is avail</a></p>
<h4 id="install-asammdf"><a href="#install-asammdf" class="headerlink" title="install asammdf"></a>install asammdf</h4><p><a href="https://github.com/danielhrisca/asammdf" target="_blank" rel="external">github: asammdf</a></p>
<p>it’s recommended to use <strong>conda</strong> env to manage this project. name this env as <code>mdf</code>. it’s recommended to install packages through <code>conda install</code>, rather than system <code>apt-get install</code>. </p>
<p>the following packages is required:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">conda install numpy</div><div class="line">conda install pandas</div><div class="line">conda install -c conda-forge dbus</div><div class="line">conda install lxml=4.5.0</div><div class="line">conda install -c conda-forge canmatrix</div><div class="line">conda install -c conda-forge asammdf</div><div class="line">conda install  pyqt5  <span class="comment">#optionally but recommended, if you need asammdf GUI tool in Linux</span></div></pre></td></tr></table></figure>
<p>take care the pkg installed path, either globally in <code>conda/pkgs/</code>  or in the special env <code>/conda/envs/mdf/lib/python3/site-packages</code>, can simplely <code>import asammdf</code> to see $PYTHONPATH found the module.</p>
<h4 id="conda-pythonpath"><a href="#conda-pythonpath" class="headerlink" title="conda pythonpath"></a>conda pythonpath</h4><p>check existing system path.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> sys</div><div class="line">sys.path </div><div class="line">[<span class="string">''</span>, <span class="string">'/usr/lib/python3/dist-packages'</span>, <span class="string">'/home/anaconda3/envs/mf4/lib/python3.8/site-packages'</span>]</div></pre></td></tr></table></figure>
<p>PYTHON loads the modules from the <code>sys.path</code> in the order, so if PYTHON find the required module in the first PATH, which however is the wrong version, then it’s an error.</p>
<p><a href="https://stackoverflow.com/questions/17386880/does-anaconda-create-a-separate-pythonpath-variable-for-each-new-environment" target="_blank" rel="external">does anaconda create a separate PYTHONPATH for each new env</a>: each environment is a completely separate installation of Python and all the packages. there’s no need to mess with PYTHONPATH because the Python binary in the environment already searches the site-packages in that environment, and the libs of the environment.</p>
<p>in one word, <strong>when using conda, don’t use system PYTHONPAH</strong></p>
<h4 id="install-asammdf-gui"><a href="#install-asammdf-gui" class="headerlink" title="install asammdf[gui]"></a>install asammdf[gui]</h4><ul>
<li>test with PyQt5 </li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">python3 </div><div class="line">import PyQt5</div></pre></td></tr></table></figure>
<p>reports <a href="https://askubuntu.com/questions/308128/failed-to-load-platform-plugin-xcb-while-launching-qt5-app-on-linux-without" target="_blank" rel="external">Could not load the Qt platform plugin “xcb” in “” even though it was found</a></p>
<p>the reason is due to <a href="https://github.com/neuropoly/spinalcordtoolbox/issues/2436" target="_blank" rel="external">libqxcb.so</a> from <code>~/anaconda3/envs/aeb/lib/python3.6/site-packages/PyQt5/Qt/plugins/platforms</code> not found <code>libxcb-xinerama.so.0</code>, fixed by <a href="https://github.com/supertriodo/Arena-Tracker/issues/52" target="_blank" rel="external">install libxcb-xinerama0</a></p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">ldd libqxcb.so </div><div class="line">$ libxcb-xinerama.so.0 =&gt; not found</div><div class="line">sudo apt-get install libxcb-xinerama0</div></pre></td></tr></table></figure>
<ul>
<li>install </li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> PYTHONPATH=<span class="string">""</span></div><div class="line">pip install asammdf[gui]</div></pre></td></tr></table></figure>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Requirement already satisfied: pyqtgraph==0.11.0rc0; extra == <span class="string">"gui"</span> <span class="keyword">in</span> /home/gwm/anaconda3/envs/aeb/lib/python3.6/site-packages (from asammdf[gui]) (0.11.0rc0)</div><div class="line">Requirement already satisfied: psutil; extra == <span class="string">"gui"</span> <span class="keyword">in</span> /home/gwm/anaconda3/envs/aeb/lib/python3.6/site-packages (from asammdf[gui]) (5.7.0)</div><div class="line">Requirement already satisfied: PyQt5&gt;=5.13.1; extra == <span class="string">"gui"</span> <span class="keyword">in</span> /home/gwm/anaconda3/envs/aeb/lib/python3.6/site-packages (from asammdf[gui]) (5.15.0)</div></pre></td></tr></table></figure>
<h4 id="numpy-utils"><a href="#numpy-utils" class="headerlink" title="numpy utils"></a>numpy utils</h4><ul>
<li>output precision</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">res = np.where(arr==roi)</div><div class="line"><span class="keyword">for</span> x <span class="keyword">in</span> np.nditer(arr):</div><div class="line">	print(x)</div><div class="line">np.set_printoptions(precision=<span class="number">3</span>)</div><div class="line">np.set_printoptions(suppress=<span class="keyword">True</span>)</div><div class="line">np.around([], decimals=<span class="number">2</span>)</div><div class="line"><span class="keyword">for</span> (k,v) <span class="keyword">in</span> dict.items():</div><div class="line">	<span class="keyword">print</span> (k, v)</div></pre></td></tr></table></figure>
<h2 id="asammdf"><a href="#asammdf" class="headerlink" title="asammdf"></a>asammdf</h2><h4 id="bypass-non-standard-msg"><a href="#bypass-non-standard-msg" class="headerlink" title="bypass non-standard msg"></a>bypass non-standard msg</h4><p>most OEM mdf4 files are collected by <code>Vector CANape</code> tools, which may include many uncommon types, such as Matlab/Simulink objects, measurement signals(multimedia) cam-stream e.t.c, which can’t be parsed by current asammdf tool.</p>
<p>so a simple fix is to bypass these uncommon data type, submit in the <a href="https://github.com/danielhrisca/asammdf/issues/343" target="_blank" rel="external">git issue</a>.</p>
<h4 id="bytes-object-to-numerical-values"><a href="#bytes-object-to-numerical-values" class="headerlink" title="bytes object to numerical values"></a>bytes object to numerical values</h4><p>bytes objects basically contain a sequence of integers in the range 0-255, but when represented, Python displays these bytes as ASCII codepoints to make it easier to read their contents.</p>
<p>Because a bytes object consist of a sequence of integers, you can construct a bytes object from any other sequence of integers with values in the 0-255 range, like a list:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">bVal = bytes([72, 101, 108, 108, 111])</div><div class="line">strVal = bVal.decode(<span class="string">'utf-8'</span>)</div></pre></td></tr></table></figure>
<p>in asammdf, the numerical ndarray can be stored as <code>uint8</code>, <code>uint32</code>, <code>uint64</code> e.t.c, but with a different range and representation. for radar/camera detected obj id, the range is in [0~255], so here need output as <code>uint8</code>.</p>
<p>sample of ObjID as asammdf.Signal: </p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="string">&lt;Signal</span> <span class="attr">MRR_ObjID_3:</span></div><div class="line">	<span class="string">samples=[b''</span> <span class="string">b''</span> <span class="string">b''</span> <span class="string">...</span> <span class="string">b''</span> <span class="string">b''</span> <span class="string">b'']</span></div><div class="line">	<span class="string">timestamps=[</span> <span class="number">0.08185676</span>  <span class="number">0.13073605</span>  <span class="number">0.18073289</span> <span class="string">...</span> <span class="number">57.5313583</span>  <span class="number">57.5813593</span></div><div class="line"> <span class="number">57.63134464</span><span class="string">]</span></div><div class="line">	<span class="string">invalidation_bits=None</span></div><div class="line">	<span class="string">unit=""</span></div><div class="line">	<span class="string">conversion=None</span></div><div class="line">	<span class="string">source=&lt;asammdf.blocks.source_utils.Source</span> <span class="string">object</span> <span class="string">at</span> <span class="number">0x7f79b91c7ae8</span><span class="string">&gt;</span></div><div class="line">	comment="&lt;CNcomment&gt;</div><div class="line">&lt;TX/&gt;</div><div class="line">&lt;address byte_count="1" byte_order="BE"&gt;0x0008&lt;/address&gt;</div><div class="line">&lt;/CNcomment&gt;"</div><div class="line">	mastermeta="('t', 1)"</div><div class="line">	raw=False</div><div class="line">	display_name=</div><div class="line">	attachment=()&gt;</div></pre></td></tr></table></figure>
<h4 id="mf4-reader"><a href="#mf4-reader" class="headerlink" title="mf4_reader"></a>mf4_reader</h4><p>first, we need define a high-level APIs to handle collected mf4 from road test. which often includes a bunch of groups for each sensor, and a few channels to record one kind of Signal in one sensor. and another dimension is <code>time</code>, as each Signal is a time serial. the sample Signal output also shows there are two np.narray: <code>samples</code> and <code>timestamps</code>.</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="bullet">-</span><span class="string">&gt; group </span></div><div class="line">----&gt; channel</div><div class="line">--------&gt; samples[timestampIndex]</div></pre></td></tr></table></figure>
<p>what we need is to repackage the signals from mf4 as structures of input(mostly like sensor packages) and output(another structure or CAN package)  to any model required, e.g. fusion/aeb.  </p>
<ul>
<li>init_multi_read(group_name, channel_nums, obj_nums, channel_list)</li>
</ul>
<p><code>channel_nums</code>, gives the number of channels/signals for this sensor</p>
<p><code>obj_nums</code>, is the number of objects can detected by a special sensor, which is given by the vendor of the sensor. e.g. Bosch 5th Radar can detect at most 32 objects.</p>
<p><code>channel_list</code>, is the name list of the channels, whose length should equal <code>channel_nums</code>. </p>
<p>this API does read all required channels raw data into memeory initially.</p>
<ul>
<li>updateCacheData(group_name, time)</li>
</ul>
<p><code>time</code> is the given timestamp, this API returns the interested samples at the given <code>time</code>.  one trick here is <code>time matching</code>, as very possiblly, the given <code>time</code> doesn’t match any of the recorded timestamp in a special channel, here always seek the most closest timestamp to <code>time</code>.</p>
<ul>
<li><p>seek_closest_timestamp_index(timestamps, time)</p>
</li>
<li><p>get_channel_data_by_name(channel_name, time)</p>
</li>
<li><p>get_channel_all_data_by_name(channel_name)</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="keyword">from</span> asammdf <span class="keyword">import</span> MDF4</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">mf4_reader</span><span class="params">()</span>:</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, mf4_file)</span>:</span></div><div class="line">		self.reader = MDF4(mf4_file)</div><div class="line">		self.channelValsCacheMap = dict()</div><div class="line"></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">init_multi_read</span><span class="params">(group_name, channel_name, obj_nums, channel_namelist)</span>:</span></div><div class="line">		channelValuesMap = dict()</div><div class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> range(obj_nums):</div><div class="line">			<span class="keyword">for</span> base_name <span class="keyword">in</span> channel_namelist:</div><div class="line">				channel_name = base_name + str(i+<span class="number">1</span>)</div><div class="line">				channel_raw_data = self.get_channel_all_data_by_name(channel_name)</div><div class="line">				<span class="keyword">if</span> channel_raw_data :</div><div class="line">					channelValuesMap[channel_name] = channel_raw_data</div><div class="line">				<span class="keyword">else</span>:</div><div class="line">					channelValuesMap[channel_name] = <span class="keyword">None</span></div><div class="line">		self.channelValsCacheMap[group_name] = channelValuesMap</div></pre></td></tr></table></figure>
<h4 id="fusion-adapter"><a href="#fusion-adapter" class="headerlink" title="fusion adapter"></a>fusion adapter</h4><p>once we can read all raw signals from mf4 files, then need to package these signals as the upper-level application requires. e.g. fusion, aeb input structs.</p>
<p>taking fusion module as example. the input includes radar structure, camera structure, e.t.c, something like:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">radar_sensor_pack</span><span class="params">()</span>:</span></div><div class="line">	self.objID, </div><div class="line">        self.objExistProb ,</div><div class="line">        self.objDistx,</div><div class="line">        self.objDisty, </div><div class="line">        self.objRelVelx,</div><div class="line">        self.objRelVely, </div><div class="line">        ...</div></pre></td></tr></table></figure>
<p>data collection is done by Vector CANape, the sensor pack is defined in <code>*.dbc</code> file, so here basically does package <code>dbc</code> signals to a Python sensor_object, and then assign this sensor_object with the values from mdf4 files.</p>
<p>we need define a bunch of fusion_adapter to package all the necessary inputs for each module, e.g. fusion, aeb e.t.c</p>
<h4 id="rosAdapter"><a href="#rosAdapter" class="headerlink" title="rosAdapter"></a>rosAdapter</h4><p>another kind of usage from mf4 file, is transfer mf4 to rosbag. due to most ADS dev/debug/verifcation tools currently are based on ros env. on the other hand, ros base data collection is not robost enough than CANape, so the data collection is in <code>*.mf4</code>. </p>
<ul>
<li>build ros message and define ros_sensor_obj</li>
</ul>
<p>as asammdf reader is in python, here can build ros message into python module, as mentioned prevously. as ros message built is with <code>catkin_make</code>, which is based on python2.7, so need add the <code>sensor_msgs</code> python module path to $PYTHONPATH in the <code>conda env fusion</code>. </p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> PYTHONPATH=/home/gitlab_/mf4io/linux/toRosbag/catkin_ws/install/lib/python2.7/dist-packages</div></pre></td></tr></table></figure>
<p>basically, we use <code>python3</code> shell, but we add the <code>catkin_ws/python2.7</code> to its PYTHONPATH.</p>
<ul>
<li>write rosbag </li>
</ul>
<p>then we can fill in <code>ros_sensor_obj</code> from mf4 structures. and write to bag.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">self.bag.write(<span class="string">'/bose_cr/radar/front_right/object'</span>, ros_sensor_obj.data)</div></pre></td></tr></table></figure>
<h4 id="rosbag-know-how"><a href="#rosbag-know-how" class="headerlink" title="rosbag know-how"></a>rosbag know-how</h4><ul>
<li><a href="http://wiki.ros.org/rosbag/Commandline" target="_blank" rel="external">rosbag filter</a></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">rosbag filter 20200619-xx.bag  only-mrr.bag <span class="string">"topic==`/bose_mrr/radar/front/object`"</span></div></pre></td></tr></table></figure>
<ul>
<li><a href="http://wiki.ros.org/ROS/Tutorials/reading%20msgs%20from%20a%20bag%20file" target="_blank" rel="external">read message from a bag file</a></li>
</ul>
<h2 id="refere"><a href="#refere" class="headerlink" title="refere"></a>refere</h2><p><a href="https://github.com/lxml/lxml" target="_blank" rel="external">lxml</a></p>
<p><a href="https://github.com/ebroecker/canmatrix" target="_blank" rel="external">canmatrix</a></p>
<p><a href="https://github.com/danielhrisca/asammdf" target="_blank" rel="external">asammdf</a></p>
<p><a href="https://stackoverflow.com/questions/2592764/what-does-a-b-prefix-before-a-python-string-mean" target="_blank" rel="external">what does a b prefix before a python string mean</a></p>
<p><a href="https://www.tutorialspoint.com/numpy/numpy_data_types.htm" target="_blank" rel="external">numpy data type</a></p>
<p><a href="http://wiki.ros.org/rosbag/Code%20API#cpp_api" target="_blank" rel="external">write rosbag api</a></p>
<p><a href="http://wiki.ros.org/ROS/Tutorials/Recording%20and%20playing%20back%20data" target="_blank" rel="external">record and play back data</a></p>
<p><a href="https://github.com/ElectricRCAircraftGuy/eRCaGuy_dotfiles/blob/master/useful_scripts/ros_readbagfile.py" target="_blank" rel="external">ros_readbagfile.py</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/20/">20</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="David Z.J. Lee" />
          <p class="site-author-name" itemprop="name">David Z.J. Lee</p>
           
              <p class="site-description motion-element" itemprop="description">what I don't know</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">192</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">51</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/ZJLi2013" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.linkedin.com/in/zhengjia13/" target="_blank" title="LinkedIn">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  LinkedIn
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">David Z.J. Lee</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
    <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://zjlee.disqus.com/count.js" async></script>
    

    

  




	





  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  

  

</body>
</html>
